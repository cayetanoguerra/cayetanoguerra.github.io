huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 12.5621, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
{'loss': 12.532, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}
{'loss': 12.494, 'learning_rate': 3e-06, 'epoch': 0.01}
{'loss': 12.434, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}
{'loss': 12.3959, 'learning_rate': 5e-06, 'epoch': 0.02}
{'loss': 12.2208, 'learning_rate': 6e-06, 'epoch': 0.02}
{'loss': 12.0261, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.03}
{'loss': 11.7139, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}
{'loss': 11.2695, 'learning_rate': 9e-06, 'epoch': 0.04}
{'loss': 10.8182, 'learning_rate': 1e-05, 'epoch': 0.04}
{'loss': 9.8953, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.04}
{'loss': 8.7168, 'learning_rate': 1.2e-05, 'epoch': 0.05}
{'loss': 7.2017, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.05}
{'loss': 5.7925, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.06}
{'loss': 4.4684, 'learning_rate': 1.5e-05, 'epoch': 0.06}
{'loss': 3.0273, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.06}
{'loss': 2.0733, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}
{'loss': 1.5537, 'learning_rate': 1.8e-05, 'epoch': 0.07}
{'loss': 1.2412, 'learning_rate': 1.9e-05, 'epoch': 0.08}
{'loss': 1.0961, 'learning_rate': 2e-05, 'epoch': 0.08}
{'loss': 0.9341, 'learning_rate': 2.1e-05, 'epoch': 0.08}
{'loss': 0.9155, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.09}
{'loss': 0.867, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.09}
{'loss': 0.809, 'learning_rate': 2.4e-05, 'epoch': 0.1}
{'loss': 0.7975, 'learning_rate': 2.5e-05, 'epoch': 0.1}
{'loss': 0.736, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.1}
{'loss': 0.7118, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.11}
{'loss': 0.6709, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.11}
{'loss': 0.6311, 'learning_rate': 2.9e-05, 'epoch': 0.12}
{'loss': 0.6243, 'learning_rate': 3e-05, 'epoch': 0.12}
{'loss': 0.6084, 'learning_rate': 3.1e-05, 'epoch': 0.12}
{'loss': 0.5831, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.13}
{'loss': 0.5522, 'learning_rate': 3.3e-05, 'epoch': 0.13}
{'loss': 0.5184, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.14}
{'loss': 0.5017, 'learning_rate': 3.5e-05, 'epoch': 0.14}
{'loss': 0.4894, 'learning_rate': 3.6e-05, 'epoch': 0.14}
{'loss': 0.4685, 'learning_rate': 3.7e-05, 'epoch': 0.15}
{'loss': 0.455, 'learning_rate': 3.8e-05, 'epoch': 0.15}
{'loss': 0.4382, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.16}
{'loss': 0.4319, 'learning_rate': 4e-05, 'epoch': 0.16}
{'loss': 0.4238, 'learning_rate': 4.1e-05, 'epoch': 0.16}
{'loss': 0.4093, 'learning_rate': 4.2e-05, 'epoch': 0.17}
{'loss': 0.3965, 'learning_rate': 4.3e-05, 'epoch': 0.17}
{'loss': 0.3974, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.18}
{'loss': 0.3882, 'learning_rate': 4.5e-05, 'epoch': 0.18}
{'loss': 0.3838, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.18}
{'loss': 0.3694, 'learning_rate': 4.7e-05, 'epoch': 0.19}
{'loss': 0.3723, 'learning_rate': 4.8e-05, 'epoch': 0.19}
{'loss': 0.3607, 'learning_rate': 4.9e-05, 'epoch': 0.2}
{'loss': 0.3633, 'learning_rate': 5e-05, 'epoch': 0.2}
{'loss': 0.3543, 'learning_rate': 4.975e-05, 'epoch': 0.2}
{'loss': 0.3595, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.21}
{'loss': 0.354, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.21}
{'loss': 0.349, 'learning_rate': 4.9e-05, 'epoch': 0.22}
{'loss': 0.347, 'learning_rate': 4.875e-05, 'epoch': 0.22}
{'loss': 0.3507, 'learning_rate': 4.85e-05, 'epoch': 0.22}
{'loss': 0.3518, 'learning_rate': 4.825e-05, 'epoch': 0.23}
{'loss': 0.3317, 'learning_rate': 4.8e-05, 'epoch': 0.23}
{'loss': 0.3406, 'learning_rate': 4.775e-05, 'epoch': 0.24}
{'loss': 0.3395, 'learning_rate': 4.75e-05, 'epoch': 0.24}
{'loss': 0.3406, 'learning_rate': 4.7249999999999997e-05, 'epoch': 0.24}
{'loss': 0.3385, 'learning_rate': 4.7e-05, 'epoch': 0.25}
{'loss': 0.3352, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.25}
{'loss': 0.3399, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.26}
{'loss': 0.345, 'learning_rate': 4.6250000000000006e-05, 'epoch': 0.26}
{'loss': 0.3336, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.26}
{'loss': 0.3277, 'learning_rate': 4.575e-05, 'epoch': 0.27}
{'loss': 0.331, 'learning_rate': 4.55e-05, 'epoch': 0.27}
{'loss': 0.326, 'learning_rate': 4.525e-05, 'epoch': 0.28}
{'loss': 0.3193, 'learning_rate': 4.5e-05, 'epoch': 0.28}
{'loss': 0.3308, 'learning_rate': 4.4750000000000004e-05, 'epoch': 0.28}
{'loss': 0.3193, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.29}
{'loss': 0.322, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.29}
{'loss': 0.3219, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.3}
{'loss': 0.3178, 'learning_rate': 4.375e-05, 'epoch': 0.3}
{'loss': 0.321, 'learning_rate': 4.35e-05, 'epoch': 0.3}
{'loss': 0.3181, 'learning_rate': 4.325e-05, 'epoch': 0.31}
{'loss': 0.3286, 'learning_rate': 4.3e-05, 'epoch': 0.31}
{'loss': 0.31, 'learning_rate': 4.275e-05, 'epoch': 0.32}
{'loss': 0.3148, 'learning_rate': 4.25e-05, 'epoch': 0.32}
{'loss': 0.3323, 'learning_rate': 4.2250000000000004e-05, 'epoch': 0.32}
{'loss': 0.3071, 'learning_rate': 4.2e-05, 'epoch': 0.33}
{'loss': 0.3131, 'learning_rate': 4.175e-05, 'epoch': 0.33}
{'loss': 0.32, 'learning_rate': 4.15e-05, 'epoch': 0.34}
{'loss': 0.3171, 'learning_rate': 4.125e-05, 'epoch': 0.34}
{'loss': 0.3081, 'learning_rate': 4.1e-05, 'epoch': 0.34}
{'loss': 0.3121, 'learning_rate': 4.075e-05, 'epoch': 0.35}
{'loss': 0.3092, 'learning_rate': 4.05e-05, 'epoch': 0.35}
{'loss': 0.314, 'learning_rate': 4.025e-05, 'epoch': 0.36}
{'loss': 0.3156, 'learning_rate': 4e-05, 'epoch': 0.36}
{'loss': 0.3059, 'learning_rate': 3.9750000000000004e-05, 'epoch': 0.36}
{'loss': 0.3044, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.37}
{'loss': 0.3137, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.37}
{'loss': 0.3077, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.38}
{'loss': 0.3126, 'learning_rate': 3.875e-05, 'epoch': 0.38}
{'loss': 0.3022, 'learning_rate': 3.85e-05, 'epoch': 0.38}
{'loss': 0.3064, 'learning_rate': 3.825e-05, 'epoch': 0.39}
{'loss': 0.3118, 'learning_rate': 3.8e-05, 'epoch': 0.39}
{'loss': 0.3045, 'learning_rate': 3.775e-05, 'epoch': 0.4}
{'loss': 0.2999, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.4}
{'loss': 0.2956, 'learning_rate': 3.7250000000000004e-05, 'epoch': 0.4}
{'loss': 0.3019, 'learning_rate': 3.7e-05, 'epoch': 0.41}
{'loss': 0.3031, 'learning_rate': 3.675e-05, 'epoch': 0.41}
{'loss': 0.3019, 'learning_rate': 3.65e-05, 'epoch': 0.42}
{'loss': 0.2885, 'learning_rate': 3.625e-05, 'epoch': 0.42}
{'loss': 0.3023, 'learning_rate': 3.6e-05, 'epoch': 0.42}
{'loss': 0.3086, 'learning_rate': 3.575e-05, 'epoch': 0.43}
{'loss': 0.305, 'learning_rate': 3.55e-05, 'epoch': 0.43}
{'loss': 0.3046, 'learning_rate': 3.525e-05, 'epoch': 0.44}
{'loss': 0.3019, 'learning_rate': 3.5e-05, 'epoch': 0.44}
{'loss': 0.3013, 'learning_rate': 3.475e-05, 'epoch': 0.44}
{'loss': 0.2897, 'learning_rate': 3.45e-05, 'epoch': 0.45}
{'loss': 0.2957, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.45}
{'loss': 0.2967, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.46}
{'loss': 0.2998, 'learning_rate': 3.375000000000001e-05, 'epoch': 0.46}
{'loss': 0.2955, 'learning_rate': 3.35e-05, 'epoch': 0.46}
{'loss': 0.2925, 'learning_rate': 3.325e-05, 'epoch': 0.47}
{'loss': 0.2981, 'learning_rate': 3.3e-05, 'epoch': 0.47}
{'loss': 0.2961, 'learning_rate': 3.275e-05, 'epoch': 0.48}
{'loss': 0.2841, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.48}
{'loss': 0.2923, 'learning_rate': 3.2250000000000005e-05, 'epoch': 0.48}
{'loss': 0.2961, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.49}
{'loss': 0.2762, 'learning_rate': 3.175e-05, 'epoch': 0.49}
{'loss': 0.2909, 'learning_rate': 3.15e-05, 'epoch': 0.5}
{'loss': 0.2917, 'learning_rate': 3.125e-05, 'epoch': 0.5}
{'loss': 0.2918, 'learning_rate': 3.1e-05, 'epoch': 0.5}
{'loss': 0.2893, 'learning_rate': 3.075e-05, 'epoch': 0.51}
{'loss': 0.2972, 'learning_rate': 3.05e-05, 'epoch': 0.51}
{'loss': 0.2974, 'learning_rate': 3.025e-05, 'epoch': 0.52}
{'loss': 0.2919, 'learning_rate': 3e-05, 'epoch': 0.52}
{'loss': 0.2963, 'learning_rate': 2.975e-05, 'epoch': 0.52}
{'loss': 0.2889, 'learning_rate': 2.95e-05, 'epoch': 0.53}
{'loss': 0.2901, 'learning_rate': 2.925e-05, 'epoch': 0.53}
{'loss': 0.2923, 'learning_rate': 2.9e-05, 'epoch': 0.54}
{'loss': 0.2965, 'learning_rate': 2.8749999999999997e-05, 'epoch': 0.54}
{'loss': 0.2926, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.54}
{'loss': 0.2958, 'learning_rate': 2.825e-05, 'epoch': 0.55}
{'loss': 0.2883, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.55}
{'loss': 0.2811, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.56}
{'loss': 0.287, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.56}
{'loss': 0.2969, 'learning_rate': 2.725e-05, 'epoch': 0.56}
{'loss': 0.2858, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.57}
{'loss': 0.2892, 'learning_rate': 2.6750000000000003e-05, 'epoch': 0.57}
{'loss': 0.284, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.58}
{'loss': 0.2777, 'learning_rate': 2.625e-05, 'epoch': 0.58}
{'loss': 0.2823, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.58}
{'loss': 0.2849, 'learning_rate': 2.5750000000000002e-05, 'epoch': 0.59}
{'loss': 0.2866, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.59}
{'loss': 0.2867, 'learning_rate': 2.525e-05, 'epoch': 0.6}
{'loss': 0.2833, 'learning_rate': 2.5e-05, 'epoch': 0.6}
{'loss': 0.2873, 'learning_rate': 2.4750000000000002e-05, 'epoch': 0.6}
{'loss': 0.2863, 'learning_rate': 2.45e-05, 'epoch': 0.61}
{'loss': 0.2801, 'learning_rate': 2.425e-05, 'epoch': 0.61}
{'loss': 0.2867, 'learning_rate': 2.4e-05, 'epoch': 0.62}
{'loss': 0.2887, 'learning_rate': 2.375e-05, 'epoch': 0.62}
{'loss': 0.2781, 'learning_rate': 2.35e-05, 'epoch': 0.62}
{'loss': 0.2912, 'learning_rate': 2.3250000000000003e-05, 'epoch': 0.63}
{'loss': 0.2874, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.63}
{'loss': 0.2897, 'learning_rate': 2.275e-05, 'epoch': 0.64}
{'loss': 0.2851, 'learning_rate': 2.25e-05, 'epoch': 0.64}
{'loss': 0.287, 'learning_rate': 2.2250000000000002e-05, 'epoch': 0.64}
{'loss': 0.2807, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.65}
{'loss': 0.2927, 'learning_rate': 2.175e-05, 'epoch': 0.65}
{'loss': 0.2921, 'learning_rate': 2.15e-05, 'epoch': 0.66}
{'loss': 0.2824, 'learning_rate': 2.125e-05, 'epoch': 0.66}
{'loss': 0.278, 'learning_rate': 2.1e-05, 'epoch': 0.66}
{'loss': 0.2838, 'learning_rate': 2.075e-05, 'epoch': 0.67}
{'loss': 0.2773, 'learning_rate': 2.05e-05, 'epoch': 0.67}
{'loss': 0.2808, 'learning_rate': 2.025e-05, 'epoch': 0.68}
{'loss': 0.278, 'learning_rate': 2e-05, 'epoch': 0.68}
{'loss': 0.2726, 'learning_rate': 1.9750000000000002e-05, 'epoch': 0.68}
{'loss': 0.2727, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.69}
{'loss': 0.2815, 'learning_rate': 1.925e-05, 'epoch': 0.69}
{'loss': 0.2783, 'learning_rate': 1.9e-05, 'epoch': 0.7}
{'loss': 0.2836, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.7}
{'loss': 0.2816, 'learning_rate': 1.85e-05, 'epoch': 0.7}
{'loss': 0.2849, 'learning_rate': 1.825e-05, 'epoch': 0.71}
{'loss': 0.2854, 'learning_rate': 1.8e-05, 'epoch': 0.71}
{'loss': 0.2723, 'learning_rate': 1.775e-05, 'epoch': 0.72}
{'loss': 0.2787, 'learning_rate': 1.75e-05, 'epoch': 0.72}
{'loss': 0.2796, 'learning_rate': 1.725e-05, 'epoch': 0.72}
{'loss': 0.2734, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.73}
{'loss': 0.2814, 'learning_rate': 1.675e-05, 'epoch': 0.73}
{'loss': 0.2806, 'learning_rate': 1.65e-05, 'epoch': 0.74}
{'loss': 0.2766, 'learning_rate': 1.6250000000000002e-05, 'epoch': 0.74}
{'loss': 0.2695, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.74}
{'loss': 0.2847, 'learning_rate': 1.575e-05, 'epoch': 0.75}
{'loss': 0.2815, 'learning_rate': 1.55e-05, 'epoch': 0.75}
{'loss': 0.269, 'learning_rate': 1.525e-05, 'epoch': 0.76}
{'loss': 0.2751, 'learning_rate': 1.5e-05, 'epoch': 0.76}
{'loss': 0.2721, 'learning_rate': 1.475e-05, 'epoch': 0.76}
{'loss': 0.2714, 'learning_rate': 1.45e-05, 'epoch': 0.77}
{'loss': 0.2837, 'learning_rate': 1.4249999999999999e-05, 'epoch': 0.77}
{'loss': 0.2808, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.78}
{'loss': 0.2836, 'learning_rate': 1.3750000000000002e-05, 'epoch': 0.78}
{'loss': 0.2753, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.78}
{'loss': 0.2705, 'learning_rate': 1.3250000000000002e-05, 'epoch': 0.79}
{'loss': 0.2653, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.79}
{'loss': 0.266, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.8}
{'loss': 0.2822, 'learning_rate': 1.25e-05, 'epoch': 0.8}
{'loss': 0.2762, 'learning_rate': 1.225e-05, 'epoch': 0.8}
{'loss': 0.2731, 'learning_rate': 1.2e-05, 'epoch': 0.81}
{'loss': 0.2666, 'learning_rate': 1.175e-05, 'epoch': 0.81}
{'loss': 0.2751, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.82}
{'loss': 0.2692, 'learning_rate': 1.125e-05, 'epoch': 0.82}
{'loss': 0.2744, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.82}
{'loss': 0.2692, 'learning_rate': 1.075e-05, 'epoch': 0.83}
{'loss': 0.278, 'learning_rate': 1.05e-05, 'epoch': 0.83}
{'loss': 0.2811, 'learning_rate': 1.025e-05, 'epoch': 0.84}
{'loss': 0.2822, 'learning_rate': 1e-05, 'epoch': 0.84}
{'loss': 0.2738, 'learning_rate': 9.750000000000002e-06, 'epoch': 0.84}
{'loss': 0.2817, 'learning_rate': 9.5e-06, 'epoch': 0.85}
{'loss': 0.278, 'learning_rate': 9.25e-06, 'epoch': 0.85}
{'loss': 0.2742, 'learning_rate': 9e-06, 'epoch': 0.86}
{'loss': 0.2762, 'learning_rate': 8.75e-06, 'epoch': 0.86}
{'loss': 0.2667, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.86}
{'loss': 0.2734, 'learning_rate': 8.25e-06, 'epoch': 0.87}
{'loss': 0.2755, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.87}
{'loss': 0.2724, 'learning_rate': 7.75e-06, 'epoch': 0.88}
{'loss': 0.2852, 'learning_rate': 7.5e-06, 'epoch': 0.88}
{'loss': 0.2779, 'learning_rate': 7.25e-06, 'epoch': 0.88}
{'loss': 0.2833, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.89}
{'loss': 0.2652, 'learning_rate': 6.750000000000001e-06, 'epoch': 0.89}
{'loss': 0.2741, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.9}
{'loss': 0.2765, 'learning_rate': 6.25e-06, 'epoch': 0.9}
{'loss': 0.2694, 'learning_rate': 6e-06, 'epoch': 0.9}
{'loss': 0.2887, 'learning_rate': 5.750000000000001e-06, 'epoch': 0.91}
{'loss': 0.2688, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.91}
{'loss': 0.2736, 'learning_rate': 5.25e-06, 'epoch': 0.92}
{'loss': 0.2772, 'learning_rate': 5e-06, 'epoch': 0.92}
{'loss': 0.2625, 'learning_rate': 4.75e-06, 'epoch': 0.92}
{'loss': 0.2778, 'learning_rate': 4.5e-06, 'epoch': 0.93}
{'loss': 0.272, 'learning_rate': 4.250000000000001e-06, 'epoch': 0.93}
{'loss': 0.2684, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.94}
{'loss': 0.2615, 'learning_rate': 3.75e-06, 'epoch': 0.94}
{'loss': 0.2717, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.94}
{'loss': 0.2791, 'learning_rate': 3.2500000000000002e-06, 'epoch': 0.95}
{'loss': 0.2712, 'learning_rate': 3e-06, 'epoch': 0.95}
{'loss': 0.2714, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.96}
{'loss': 0.2603, 'learning_rate': 2.5e-06, 'epoch': 0.96}
{'loss': 0.271, 'learning_rate': 2.25e-06, 'epoch': 0.96}
{'loss': 0.2649, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.97}
{'loss': 0.2742, 'learning_rate': 1.7500000000000002e-06, 'epoch': 0.97}
{'loss': 0.2738, 'learning_rate': 1.5e-06, 'epoch': 0.98}
{'loss': 0.2778, 'learning_rate': 1.25e-06, 'epoch': 0.98}
{'loss': 0.2763, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.98}
{'loss': 0.2727, 'learning_rate': 7.5e-07, 'epoch': 0.99}
{'loss': 0.2677, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.99}
{'loss': 0.2677, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
{'loss': 0.2732, 'learning_rate': 0.0, 'epoch': 1.0}
{'train_runtime': 851.961, 'train_samples_per_second': 11.738, 'train_steps_per_second': 2.934, 'train_loss': 0.9628114163398742, 'epoch': 1.0}
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
El número 123456789 en formato textual es: 123456789, hundred million hundred nine five eight fifty thousand hundred nine
wandb: Network error (ConnectTimeout), entering retry loop.
El modelo tiene 1179648 parámetros entrenables
El modelo tiene 125619456 parámetros totales
El modelo tiene 124439808 parámetros entrenables
