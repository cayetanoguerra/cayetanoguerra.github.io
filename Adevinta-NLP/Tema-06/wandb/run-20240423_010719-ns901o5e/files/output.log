huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
{'loss': 12.5426, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
{'loss': 12.5393, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}
{'loss': 12.4249, 'learning_rate': 3e-06, 'epoch': 0.01}
{'loss': 12.4149, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}
{'loss': 12.374, 'learning_rate': 5e-06, 'epoch': 0.02}
{'loss': 12.1925, 'learning_rate': 6e-06, 'epoch': 0.02}
{'loss': 11.9825, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.03}
{'loss': 11.7267, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}
{'loss': 11.3445, 'learning_rate': 9e-06, 'epoch': 0.04}
{'loss': 10.8153, 'learning_rate': 1e-05, 'epoch': 0.04}
{'loss': 9.8913, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.04}
{'loss': 8.6783, 'learning_rate': 1.2e-05, 'epoch': 0.05}
{'loss': 7.1401, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.05}
{'loss': 5.7939, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.06}
{'loss': 4.419, 'learning_rate': 1.5e-05, 'epoch': 0.06}
{'loss': 2.9583, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.06}
{'loss': 2.0212, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}
{'loss': 1.5076, 'learning_rate': 1.8e-05, 'epoch': 0.07}
{'loss': 1.2683, 'learning_rate': 1.9e-05, 'epoch': 0.08}
{'loss': 1.0716, 'learning_rate': 2e-05, 'epoch': 0.08}
{'loss': 0.9665, 'learning_rate': 2.1e-05, 'epoch': 0.08}
{'loss': 0.8988, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.09}
{'loss': 0.8354, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.09}
{'loss': 0.8075, 'learning_rate': 2.4e-05, 'epoch': 0.1}
{'loss': 0.7667, 'learning_rate': 2.5e-05, 'epoch': 0.1}
{'loss': 0.7492, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.1}
{'loss': 0.726, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.11}
{'loss': 0.6774, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.11}
{'loss': 0.6599, 'learning_rate': 2.9e-05, 'epoch': 0.12}
{'loss': 0.6379, 'learning_rate': 3e-05, 'epoch': 0.12}
{'loss': 0.5961, 'learning_rate': 3.1e-05, 'epoch': 0.12}
{'loss': 0.5823, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.13}
{'loss': 0.5521, 'learning_rate': 3.3e-05, 'epoch': 0.13}
{'loss': 0.5042, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.14}
{'loss': 0.5018, 'learning_rate': 3.5e-05, 'epoch': 0.14}
{'loss': 0.4778, 'learning_rate': 3.6e-05, 'epoch': 0.14}
{'loss': 0.4604, 'learning_rate': 3.7e-05, 'epoch': 0.15}
{'loss': 0.4598, 'learning_rate': 3.8e-05, 'epoch': 0.15}
{'loss': 0.44, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.16}
{'loss': 0.4311, 'learning_rate': 4e-05, 'epoch': 0.16}
{'loss': 0.4155, 'learning_rate': 4.1e-05, 'epoch': 0.16}
{'loss': 0.4113, 'learning_rate': 4.2e-05, 'epoch': 0.17}
{'loss': 0.4046, 'learning_rate': 4.3e-05, 'epoch': 0.17}
{'loss': 0.3881, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.18}
{'loss': 0.3876, 'learning_rate': 4.5e-05, 'epoch': 0.18}
{'loss': 0.3881, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.18}
{'loss': 0.376, 'learning_rate': 4.7e-05, 'epoch': 0.19}
{'loss': 0.3657, 'learning_rate': 4.8e-05, 'epoch': 0.19}
{'loss': 0.3584, 'learning_rate': 4.9e-05, 'epoch': 0.2}
{'loss': 0.3654, 'learning_rate': 5e-05, 'epoch': 0.2}
{'loss': 0.3599, 'learning_rate': 4.975012493753124e-05, 'epoch': 0.2}
{'loss': 0.3621, 'learning_rate': 4.950024987506247e-05, 'epoch': 0.21}
{'loss': 0.3538, 'learning_rate': 4.9250374812593707e-05, 'epoch': 0.21}
{'loss': 0.3566, 'learning_rate': 4.900049975012494e-05, 'epoch': 0.22}
{'loss': 0.3532, 'learning_rate': 4.8750624687656176e-05, 'epoch': 0.22}
{'loss': 0.3582, 'learning_rate': 4.850074962518741e-05, 'epoch': 0.22}
{'loss': 0.3458, 'learning_rate': 4.8250874562718645e-05, 'epoch': 0.23}
{'loss': 0.3323, 'learning_rate': 4.800099950024988e-05, 'epoch': 0.23}
{'loss': 0.3317, 'learning_rate': 4.7751124437781115e-05, 'epoch': 0.24}
{'loss': 0.3353, 'learning_rate': 4.750124937531234e-05, 'epoch': 0.24}
{'loss': 0.3277, 'learning_rate': 4.7251374312843584e-05, 'epoch': 0.24}
{'loss': 0.3333, 'learning_rate': 4.700149925037481e-05, 'epoch': 0.25}
{'loss': 0.3233, 'learning_rate': 4.6751624187906054e-05, 'epoch': 0.25}
{'loss': 0.3345, 'learning_rate': 4.650174912543728e-05, 'epoch': 0.26}
{'loss': 0.3278, 'learning_rate': 4.625187406296852e-05, 'epoch': 0.26}
{'loss': 0.3316, 'learning_rate': 4.600199900049975e-05, 'epoch': 0.26}
{'loss': 0.3291, 'learning_rate': 4.5752123938030986e-05, 'epoch': 0.27}
{'loss': 0.3333, 'learning_rate': 4.550224887556222e-05, 'epoch': 0.27}
{'loss': 0.3178, 'learning_rate': 4.5252373813093455e-05, 'epoch': 0.28}
{'loss': 0.3338, 'learning_rate': 4.500249875062469e-05, 'epoch': 0.28}
{'loss': 0.327, 'learning_rate': 4.4752623688155925e-05, 'epoch': 0.28}
{'loss': 0.3211, 'learning_rate': 4.450274862568716e-05, 'epoch': 0.29}
{'loss': 0.3188, 'learning_rate': 4.4252873563218394e-05, 'epoch': 0.29}
{'loss': 0.3311, 'learning_rate': 4.400299850074963e-05, 'epoch': 0.3}
{'loss': 0.3151, 'learning_rate': 4.3753123438280864e-05, 'epoch': 0.3}
{'loss': 0.3244, 'learning_rate': 4.350324837581209e-05, 'epoch': 0.3}
{'loss': 0.3146, 'learning_rate': 4.325337331334333e-05, 'epoch': 0.31}
{'loss': 0.3228, 'learning_rate': 4.300349825087456e-05, 'epoch': 0.31}
{'loss': 0.3135, 'learning_rate': 4.27536231884058e-05, 'epoch': 0.32}
{'loss': 0.3134, 'learning_rate': 4.250374812593703e-05, 'epoch': 0.32}
{'loss': 0.3185, 'learning_rate': 4.225387306346827e-05, 'epoch': 0.32}
{'loss': 0.323, 'learning_rate': 4.20039980009995e-05, 'epoch': 0.33}
{'loss': 0.324, 'learning_rate': 4.1754122938530734e-05, 'epoch': 0.33}
{'loss': 0.3174, 'learning_rate': 4.150424787606197e-05, 'epoch': 0.34}
{'loss': 0.3164, 'learning_rate': 4.1254372813593204e-05, 'epoch': 0.34}
{'loss': 0.305, 'learning_rate': 4.100449775112444e-05, 'epoch': 0.34}
{'loss': 0.3055, 'learning_rate': 4.075462268865567e-05, 'epoch': 0.35}
{'loss': 0.3012, 'learning_rate': 4.050474762618691e-05, 'epoch': 0.35}
{'loss': 0.3071, 'learning_rate': 4.025487256371814e-05, 'epoch': 0.36}
{'loss': 0.3011, 'learning_rate': 4.000499750124938e-05, 'epoch': 0.36}
{'loss': 0.3032, 'learning_rate': 3.975512243878061e-05, 'epoch': 0.36}
{'loss': 0.301, 'learning_rate': 3.950524737631185e-05, 'epoch': 0.37}
{'loss': 0.317, 'learning_rate': 3.925537231384308e-05, 'epoch': 0.37}
{'loss': 0.2999, 'learning_rate': 3.900549725137431e-05, 'epoch': 0.38}
{'loss': 0.302, 'learning_rate': 3.875562218890555e-05, 'epoch': 0.38}
{'loss': 0.3098, 'learning_rate': 3.850574712643678e-05, 'epoch': 0.38}
{'loss': 0.3043, 'learning_rate': 3.825587206396802e-05, 'epoch': 0.39}
{'loss': 0.3115, 'learning_rate': 3.800599700149925e-05, 'epoch': 0.39}
{'loss': 0.3032, 'learning_rate': 3.775612193903049e-05, 'epoch': 0.4}
{'loss': 0.3088, 'learning_rate': 3.7506246876561725e-05, 'epoch': 0.4}
{'loss': 0.302, 'learning_rate': 3.725637181409295e-05, 'epoch': 0.4}
{'loss': 0.3024, 'learning_rate': 3.7006496751624194e-05, 'epoch': 0.41}
{'loss': 0.3062, 'learning_rate': 3.675662168915542e-05, 'epoch': 0.41}
{'loss': 0.3038, 'learning_rate': 3.6506746626686664e-05, 'epoch': 0.42}
{'loss': 0.3012, 'learning_rate': 3.625687156421789e-05, 'epoch': 0.42}
{'loss': 0.2966, 'learning_rate': 3.6006996501749126e-05, 'epoch': 0.42}
{'loss': 0.3016, 'learning_rate': 3.575712143928036e-05, 'epoch': 0.43}
{'loss': 0.3063, 'learning_rate': 3.5507246376811596e-05, 'epoch': 0.43}
{'loss': 0.3098, 'learning_rate': 3.525737131434283e-05, 'epoch': 0.44}
{'loss': 0.3041, 'learning_rate': 3.5007496251874065e-05, 'epoch': 0.44}
{'loss': 0.3025, 'learning_rate': 3.47576211894053e-05, 'epoch': 0.44}
{'loss': 0.2934, 'learning_rate': 3.4507746126936534e-05, 'epoch': 0.45}
{'loss': 0.2956, 'learning_rate': 3.425787106446777e-05, 'epoch': 0.45}
{'loss': 0.2857, 'learning_rate': 3.4007996001999004e-05, 'epoch': 0.46}
{'loss': 0.2965, 'learning_rate': 3.375812093953024e-05, 'epoch': 0.46}
{'loss': 0.2927, 'learning_rate': 3.350824587706147e-05, 'epoch': 0.46}
{'loss': 0.2983, 'learning_rate': 3.32583708145927e-05, 'epoch': 0.47}
{'loss': 0.2967, 'learning_rate': 3.300849575212394e-05, 'epoch': 0.47}
{'loss': 0.3088, 'learning_rate': 3.275862068965517e-05, 'epoch': 0.48}
{'loss': 0.2931, 'learning_rate': 3.250874562718641e-05, 'epoch': 0.48}
{'loss': 0.3001, 'learning_rate': 3.225887056471764e-05, 'epoch': 0.48}
{'loss': 0.2993, 'learning_rate': 3.200899550224888e-05, 'epoch': 0.49}
{'loss': 0.2947, 'learning_rate': 3.175912043978011e-05, 'epoch': 0.49}
{'loss': 0.298, 'learning_rate': 3.1509245377311344e-05, 'epoch': 0.5}
{'loss': 0.3009, 'learning_rate': 3.125937031484258e-05, 'epoch': 0.5}
{'loss': 0.2828, 'learning_rate': 3.1009495252373814e-05, 'epoch': 0.5}
{'loss': 0.2871, 'learning_rate': 3.075962018990505e-05, 'epoch': 0.51}
{'loss': 0.2955, 'learning_rate': 3.0509745127436283e-05, 'epoch': 0.51}
{'loss': 0.2791, 'learning_rate': 3.0259870064967514e-05, 'epoch': 0.52}
{'loss': 0.2945, 'learning_rate': 3.0009995002498753e-05, 'epoch': 0.52}
{'loss': 0.2857, 'learning_rate': 2.9760119940029984e-05, 'epoch': 0.52}
{'loss': 0.2916, 'learning_rate': 2.9510244877561222e-05, 'epoch': 0.53}
{'loss': 0.2881, 'learning_rate': 2.9260369815092453e-05, 'epoch': 0.53}
{'loss': 0.2984, 'learning_rate': 2.901049475262369e-05, 'epoch': 0.54}
{'loss': 0.2947, 'learning_rate': 2.8760619690154923e-05, 'epoch': 0.54}
{'loss': 0.2836, 'learning_rate': 2.8510744627686158e-05, 'epoch': 0.54}
{'loss': 0.2973, 'learning_rate': 2.826086956521739e-05, 'epoch': 0.55}
{'loss': 0.3004, 'learning_rate': 2.8010994502748627e-05, 'epoch': 0.55}
{'loss': 0.2898, 'learning_rate': 2.7761119440279858e-05, 'epoch': 0.56}
{'loss': 0.2853, 'learning_rate': 2.7511244377811096e-05, 'epoch': 0.56}
{'loss': 0.2866, 'learning_rate': 2.7261369315342328e-05, 'epoch': 0.56}
{'loss': 0.2876, 'learning_rate': 2.7011494252873566e-05, 'epoch': 0.57}
{'loss': 0.2864, 'learning_rate': 2.6761619190404797e-05, 'epoch': 0.57}
{'loss': 0.2859, 'learning_rate': 2.6511744127936032e-05, 'epoch': 0.58}
{'loss': 0.2851, 'learning_rate': 2.6261869065467267e-05, 'epoch': 0.58}
{'loss': 0.2863, 'learning_rate': 2.60119940029985e-05, 'epoch': 0.58}
{'loss': 0.2871, 'learning_rate': 2.5762118940529733e-05, 'epoch': 0.59}
{'loss': 0.2903, 'learning_rate': 2.551224387806097e-05, 'epoch': 0.59}
{'loss': 0.2913, 'learning_rate': 2.526236881559221e-05, 'epoch': 0.6}
{'loss': 0.2784, 'learning_rate': 2.501249375312344e-05, 'epoch': 0.6}
{'loss': 0.2936, 'learning_rate': 2.4762618690654675e-05, 'epoch': 0.6}
{'loss': 0.294, 'learning_rate': 2.451274362818591e-05, 'epoch': 0.61}
{'loss': 0.2852, 'learning_rate': 2.426286856571714e-05, 'epoch': 0.61}
{'loss': 0.2829, 'learning_rate': 2.4012993503248376e-05, 'epoch': 0.62}
{'loss': 0.287, 'learning_rate': 2.376311844077961e-05, 'epoch': 0.62}
{'loss': 0.279, 'learning_rate': 2.3513243378310845e-05, 'epoch': 0.62}
{'loss': 0.2959, 'learning_rate': 2.326336831584208e-05, 'epoch': 0.63}
{'loss': 0.2814, 'learning_rate': 2.3013493253373314e-05, 'epoch': 0.63}
{'loss': 0.2853, 'learning_rate': 2.276361819090455e-05, 'epoch': 0.64}
{'loss': 0.286, 'learning_rate': 2.2513743128435784e-05, 'epoch': 0.64}
{'loss': 0.2871, 'learning_rate': 2.2263868065967015e-05, 'epoch': 0.64}
{'loss': 0.2891, 'learning_rate': 2.201399300349825e-05, 'epoch': 0.65}
{'loss': 0.2803, 'learning_rate': 2.1764117941029485e-05, 'epoch': 0.65}
{'loss': 0.2811, 'learning_rate': 2.151424287856072e-05, 'epoch': 0.66}
{'loss': 0.2824, 'learning_rate': 2.1264367816091954e-05, 'epoch': 0.66}
{'loss': 0.2841, 'learning_rate': 2.101449275362319e-05, 'epoch': 0.66}
{'loss': 0.2819, 'learning_rate': 2.0764617691154424e-05, 'epoch': 0.67}
{'loss': 0.2785, 'learning_rate': 2.0514742628685658e-05, 'epoch': 0.67}
{'loss': 0.2769, 'learning_rate': 2.0264867566216893e-05, 'epoch': 0.68}
{'loss': 0.2788, 'learning_rate': 2.0014992503748124e-05, 'epoch': 0.68}
{'loss': 0.2813, 'learning_rate': 1.976511744127936e-05, 'epoch': 0.68}
{'loss': 0.2848, 'learning_rate': 1.9515242378810594e-05, 'epoch': 0.69}
{'loss': 0.272, 'learning_rate': 1.9265367316341832e-05, 'epoch': 0.69}
{'loss': 0.274, 'learning_rate': 1.9015492253873067e-05, 'epoch': 0.7}
{'loss': 0.2784, 'learning_rate': 1.87656171914043e-05, 'epoch': 0.7}
{'loss': 0.2802, 'learning_rate': 1.8515742128935533e-05, 'epoch': 0.7}
{'loss': 0.2885, 'learning_rate': 1.8265867066466767e-05, 'epoch': 0.71}
{'loss': 0.28, 'learning_rate': 1.8015992003998002e-05, 'epoch': 0.71}
{'loss': 0.2728, 'learning_rate': 1.7766116941529237e-05, 'epoch': 0.72}
{'loss': 0.2769, 'learning_rate': 1.751624187906047e-05, 'epoch': 0.72}
{'loss': 0.2716, 'learning_rate': 1.7266366816591706e-05, 'epoch': 0.72}
{'loss': 0.2804, 'learning_rate': 1.701649175412294e-05, 'epoch': 0.73}
{'loss': 0.2764, 'learning_rate': 1.6766616691654176e-05, 'epoch': 0.73}
{'loss': 0.2775, 'learning_rate': 1.651674162918541e-05, 'epoch': 0.74}
{'loss': 0.2802, 'learning_rate': 1.626686656671664e-05, 'epoch': 0.74}
{'loss': 0.2819, 'learning_rate': 1.6016991504247876e-05, 'epoch': 0.74}
{'loss': 0.2673, 'learning_rate': 1.576711644177911e-05, 'epoch': 0.75}
{'loss': 0.2779, 'learning_rate': 1.5517241379310346e-05, 'epoch': 0.75}
{'loss': 0.2835, 'learning_rate': 1.526736631684158e-05, 'epoch': 0.76}
{'loss': 0.2791, 'learning_rate': 1.5017491254372815e-05, 'epoch': 0.76}
{'loss': 0.2733, 'learning_rate': 1.4767616191904048e-05, 'epoch': 0.76}
{'loss': 0.2776, 'learning_rate': 1.4517741129435283e-05, 'epoch': 0.77}
{'loss': 0.2751, 'learning_rate': 1.4267866066966518e-05, 'epoch': 0.77}
{'loss': 0.2822, 'learning_rate': 1.4017991004497752e-05, 'epoch': 0.78}
{'loss': 0.2723, 'learning_rate': 1.3768115942028985e-05, 'epoch': 0.78}
{'loss': 0.2799, 'learning_rate': 1.351824087956022e-05, 'epoch': 0.78}
{'loss': 0.2802, 'learning_rate': 1.3268365817091455e-05, 'epoch': 0.79}
{'loss': 0.2744, 'learning_rate': 1.301849075462269e-05, 'epoch': 0.79}
{'loss': 0.2816, 'learning_rate': 1.2768615692153924e-05, 'epoch': 0.8}
{'loss': 0.2744, 'learning_rate': 1.2518740629685157e-05, 'epoch': 0.8}
{'loss': 0.2736, 'learning_rate': 1.2268865567216392e-05, 'epoch': 0.8}
{'loss': 0.2729, 'learning_rate': 1.2018990504747627e-05, 'epoch': 0.81}
{'loss': 0.2674, 'learning_rate': 1.1769115442278861e-05, 'epoch': 0.81}
{'loss': 0.2868, 'learning_rate': 1.1519240379810094e-05, 'epoch': 0.82}
{'loss': 0.2761, 'learning_rate': 1.126936531734133e-05, 'epoch': 0.82}
{'loss': 0.2765, 'learning_rate': 1.1019490254872564e-05, 'epoch': 0.82}
{'loss': 0.2789, 'learning_rate': 1.0769615192403799e-05, 'epoch': 0.83}
{'loss': 0.2712, 'learning_rate': 1.0519740129935032e-05, 'epoch': 0.83}
{'loss': 0.2725, 'learning_rate': 1.0269865067466268e-05, 'epoch': 0.84}
{'loss': 0.2856, 'learning_rate': 1.0019990004997503e-05, 'epoch': 0.84}
{'loss': 0.2704, 'learning_rate': 9.770114942528738e-06, 'epoch': 0.84}
{'loss': 0.278, 'learning_rate': 9.52023988005997e-06, 'epoch': 0.85}
{'loss': 0.2727, 'learning_rate': 9.270364817591205e-06, 'epoch': 0.85}
{'loss': 0.2799, 'learning_rate': 9.02048975512244e-06, 'epoch': 0.86}
{'loss': 0.2677, 'learning_rate': 8.770614692653675e-06, 'epoch': 0.86}
{'loss': 0.2726, 'learning_rate': 8.520739630184908e-06, 'epoch': 0.86}
{'loss': 0.2709, 'learning_rate': 8.270864567716142e-06, 'epoch': 0.87}
{'loss': 0.2808, 'learning_rate': 8.020989505247377e-06, 'epoch': 0.87}
{'loss': 0.2782, 'learning_rate': 7.771114442778612e-06, 'epoch': 0.88}
{'loss': 0.2647, 'learning_rate': 7.521239380309846e-06, 'epoch': 0.88}
{'loss': 0.2882, 'learning_rate': 7.27136431784108e-06, 'epoch': 0.88}
{'loss': 0.2709, 'learning_rate': 7.021489255372314e-06, 'epoch': 0.89}
{'loss': 0.2699, 'learning_rate': 6.771614192903548e-06, 'epoch': 0.89}
{'loss': 0.2861, 'learning_rate': 6.521739130434783e-06, 'epoch': 0.9}
{'loss': 0.2747, 'learning_rate': 6.271864067966017e-06, 'epoch': 0.9}
{'loss': 0.2754, 'learning_rate': 6.0219890054972515e-06, 'epoch': 0.9}
{'loss': 0.2829, 'learning_rate': 5.772113943028486e-06, 'epoch': 0.91}
{'loss': 0.2719, 'learning_rate': 5.522238880559721e-06, 'epoch': 0.91}
{'loss': 0.2695, 'learning_rate': 5.272363818090955e-06, 'epoch': 0.92}
{'loss': 0.2747, 'learning_rate': 5.0224887556221895e-06, 'epoch': 0.92}
{'loss': 0.2743, 'learning_rate': 4.772613693153423e-06, 'epoch': 0.92}
{'loss': 0.2724, 'learning_rate': 4.522738630684658e-06, 'epoch': 0.93}
{'loss': 0.2649, 'learning_rate': 4.272863568215892e-06, 'epoch': 0.93}
{'loss': 0.2726, 'learning_rate': 4.022988505747127e-06, 'epoch': 0.94}
{'loss': 0.2716, 'learning_rate': 3.773113443278361e-06, 'epoch': 0.94}
{'loss': 0.2675, 'learning_rate': 3.5232383808095952e-06, 'epoch': 0.94}
{'loss': 0.2819, 'learning_rate': 3.2733633183408295e-06, 'epoch': 0.95}
{'loss': 0.2814, 'learning_rate': 3.0234882558720643e-06, 'epoch': 0.95}
{'loss': 0.2729, 'learning_rate': 2.7736131934032985e-06, 'epoch': 0.96}
{'loss': 0.27, 'learning_rate': 2.523738130934533e-06, 'epoch': 0.96}
{'loss': 0.275, 'learning_rate': 2.273863068465767e-06, 'epoch': 0.96}
{'loss': 0.2724, 'learning_rate': 2.0239880059970014e-06, 'epoch': 0.97}
{'loss': 0.2588, 'learning_rate': 1.7741129435282361e-06, 'epoch': 0.97}
{'loss': 0.2654, 'learning_rate': 1.5242378810594704e-06, 'epoch': 0.98}
{'loss': 0.277, 'learning_rate': 1.2743628185907047e-06, 'epoch': 0.98}
{'loss': 0.2659, 'learning_rate': 1.024487756121939e-06, 'epoch': 0.98}
{'loss': 0.272, 'learning_rate': 7.746126936531734e-07, 'epoch': 0.99}
{'loss': 0.2715, 'learning_rate': 5.247376311844078e-07, 'epoch': 0.99}
{'loss': 0.2641, 'learning_rate': 2.748625687156422e-07, 'epoch': 1.0}
{'loss': 0.2718, 'learning_rate': 2.4987506246876563e-08, 'epoch': 1.0}
{'train_runtime': 870.744, 'train_samples_per_second': 11.486, 'train_steps_per_second': 2.872, 'train_loss': 0.9608405693525411, 'epoch': 1.0}
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
El número 123456789 en formato textual es: 123456789 nine forty million hundred five nine nine nine ninety
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
El número 123456789 en formato textual es: 123456789 three forty million hundred seven three fifty thousand hundred nine
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
El número 111111111 en formato textual es: 111111111, hundred million hundred one one eleven one eleven one nine one eleven
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
El número 888888888 en formato textual es: 888888888 three eighty million hundred eight eight eight eight eight eight eight eight eight eight eight
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
El número 222222222 en formato textual es: 222222222 eight twenty million hundred two two two two two two two two two two twenty
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
El número 123456789 en formato textual es: 123456789, hundred million hundred thousand hundred nine seventy
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
5dc3a68c-e34e-4080-9c3e-2a532b2ccb4d6.25.15dc3a68c-e34e-4080-9c3e-2a532b2ccb4d
5dc3a68c-e34e-4080-9c3e-2a532b2ccb4d6.25.15dc3a68c-e34e-4080-9c3e-2a532b2ccb4d
/Users/cayetano/Propio/Notebooks/Machine Learning/RL/env/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.
  warnings.warn(
{'loss': 12.5621, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
{'loss': 12.5325, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}
{'loss': 12.4954, 'learning_rate': 3e-06, 'epoch': 0.01}
{'loss': 12.4369, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}
{'loss': 12.4006, 'learning_rate': 5e-06, 'epoch': 0.02}
{'loss': 12.2285, 'learning_rate': 6e-06, 'epoch': 0.02}
{'loss': 12.0367, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.03}
{'loss': 11.7282, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}
{'loss': 11.2882, 'learning_rate': 9e-06, 'epoch': 0.04}
{'loss': 10.8467, 'learning_rate': 1e-05, 'epoch': 0.04}
{'loss': 9.9323, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.04}
{'loss': 8.7742, 'learning_rate': 1.2e-05, 'epoch': 0.05}
{'loss': 7.2724, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.05}
{'loss': 5.8692, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.06}
{'loss': 4.5304, 'learning_rate': 1.5e-05, 'epoch': 0.06}
{'loss': 3.0718, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.06}
{'loss': 2.1052, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}
{'loss': 1.5777, 'learning_rate': 1.8e-05, 'epoch': 0.07}
{'loss': 1.26, 'learning_rate': 1.9e-05, 'epoch': 0.08}
{'loss': 1.1114, 'learning_rate': 2e-05, 'epoch': 0.08}
{'loss': 0.9424, 'learning_rate': 2.1e-05, 'epoch': 0.08}
{'loss': 0.9186, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.09}
{'loss': 0.8676, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.09}
{'loss': 12.5621, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
{'loss': 12.5325, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}
{'loss': 12.4954, 'learning_rate': 3e-06, 'epoch': 0.01}
{'loss': 12.4369, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}
{'loss': 12.4006, 'learning_rate': 5e-06, 'epoch': 0.02}
{'loss': 12.2285, 'learning_rate': 6e-06, 'epoch': 0.02}
wandb: Network error (ReadTimeout), entering retry loop.
{'loss': 12.0367, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.03}
{'loss': 11.7282, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}
{'loss': 11.2882, 'learning_rate': 9e-06, 'epoch': 0.04}
{'loss': 10.8467, 'learning_rate': 1e-05, 'epoch': 0.04}
{'loss': 9.9323, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.04}
{'loss': 8.7742, 'learning_rate': 1.2e-05, 'epoch': 0.05}
{'loss': 7.2724, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.05}
{'loss': 5.8692, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.06}
{'loss': 4.5304, 'learning_rate': 1.5e-05, 'epoch': 0.06}
{'loss': 3.0718, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.06}
{'loss': 2.1052, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}
{'loss': 1.5777, 'learning_rate': 1.8e-05, 'epoch': 0.07}
{'loss': 1.26, 'learning_rate': 1.9e-05, 'epoch': 0.08}
{'loss': 1.1114, 'learning_rate': 2e-05, 'epoch': 0.08}
{'loss': 0.9424, 'learning_rate': 2.1e-05, 'epoch': 0.08}
{'loss': 0.9186, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.09}
{'loss': 0.8676, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.09}
{'loss': 0.8084, 'learning_rate': 2.4e-05, 'epoch': 0.1}
{'loss': 0.7962, 'learning_rate': 2.5e-05, 'epoch': 0.1}
{'loss': 0.7337, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.1}
{'loss': 0.709, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.11}
{'loss': 0.668, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.11}
{'loss': 0.6279, 'learning_rate': 2.9e-05, 'epoch': 0.12}
{'loss': 0.6209, 'learning_rate': 3e-05, 'epoch': 0.12}
{'loss': 0.6053, 'learning_rate': 3.1e-05, 'epoch': 0.12}
{'loss': 0.5798, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.13}
{'loss': 0.5484, 'learning_rate': 3.3e-05, 'epoch': 0.13}
{'loss': 0.5154, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.14}
{'loss': 0.4985, 'learning_rate': 3.5e-05, 'epoch': 0.14}
{'loss': 0.4869, 'learning_rate': 3.6e-05, 'epoch': 0.14}
{'loss': 0.4656, 'learning_rate': 3.7e-05, 'epoch': 0.15}
{'loss': 0.4526, 'learning_rate': 3.8e-05, 'epoch': 0.15}
{'loss': 0.4361, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.16}
{'loss': 0.4294, 'learning_rate': 4e-05, 'epoch': 0.16}
{'loss': 0.4208, 'learning_rate': 4.1e-05, 'epoch': 0.16}
{'loss': 0.407, 'learning_rate': 4.2e-05, 'epoch': 0.17}
{'loss': 0.3934, 'learning_rate': 4.3e-05, 'epoch': 0.17}
{'loss': 0.3951, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.18}
{'loss': 0.3856, 'learning_rate': 4.5e-05, 'epoch': 0.18}
{'loss': 0.3821, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.18}
{'loss': 0.3678, 'learning_rate': 4.7e-05, 'epoch': 0.19}
{'loss': 0.3705, 'learning_rate': 4.8e-05, 'epoch': 0.19}
{'loss': 0.3585, 'learning_rate': 4.9e-05, 'epoch': 0.2}
{'loss': 0.362, 'learning_rate': 5e-05, 'epoch': 0.2}
{'loss': 0.3522, 'learning_rate': 4.975e-05, 'epoch': 0.2}
{'loss': 0.3591, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.21}
{'loss': 0.3524, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.21}
{'loss': 0.3494, 'learning_rate': 4.9e-05, 'epoch': 0.22}
{'loss': 0.3469, 'learning_rate': 4.875e-05, 'epoch': 0.22}
{'loss': 0.3502, 'learning_rate': 4.85e-05, 'epoch': 0.22}
{'loss': 0.3509, 'learning_rate': 4.825e-05, 'epoch': 0.23}
{'loss': 0.3302, 'learning_rate': 4.8e-05, 'epoch': 0.23}
{'loss': 0.3396, 'learning_rate': 4.775e-05, 'epoch': 0.24}
{'loss': 0.3391, 'learning_rate': 4.75e-05, 'epoch': 0.24}
{'loss': 0.3398, 'learning_rate': 4.7249999999999997e-05, 'epoch': 0.24}
{'loss': 0.3384, 'learning_rate': 4.7e-05, 'epoch': 0.25}
{'loss': 0.335, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.25}
{'loss': 0.3395, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.26}
{'loss': 0.3446, 'learning_rate': 4.6250000000000006e-05, 'epoch': 0.26}
{'loss': 0.3342, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.26}
{'loss': 0.3267, 'learning_rate': 4.575e-05, 'epoch': 0.27}
{'loss': 0.3301, 'learning_rate': 4.55e-05, 'epoch': 0.27}
{'loss': 0.3249, 'learning_rate': 4.525e-05, 'epoch': 0.28}
{'loss': 0.3186, 'learning_rate': 4.5e-05, 'epoch': 0.28}
{'loss': 0.3304, 'learning_rate': 4.4750000000000004e-05, 'epoch': 0.28}
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
El número 123456789 en formato textual es: 123456789, hundred million hundred nine nine nine sixty thousand hundred thousand hundred
{'loss': 12.3886, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
{'loss': 10.7981, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}
{'loss': 6.6228, 'learning_rate': 3e-06, 'epoch': 0.01}
{'loss': 2.6777, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}
{'loss': 1.1976, 'learning_rate': 5e-06, 'epoch': 0.02}
{'loss': 0.8248, 'learning_rate': 6e-06, 'epoch': 0.02}
{'loss': 0.6681, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.03}
{'loss': 0.5697, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}
{'loss': 0.4719, 'learning_rate': 9e-06, 'epoch': 0.04}
{'loss': 0.4045, 'learning_rate': 1e-05, 'epoch': 0.04}
{'loss': 0.3804, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.04}
{'loss': 0.3572, 'learning_rate': 1.2e-05, 'epoch': 0.05}
{'loss': 0.3582, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.05}
{'loss': 0.341, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.06}
{'loss': 0.3247, 'learning_rate': 1.5e-05, 'epoch': 0.06}
{'loss': 0.3318, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.06}
{'loss': 0.3322, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}
{'loss': 0.3224, 'learning_rate': 1.8e-05, 'epoch': 0.07}
{'loss': 0.3196, 'learning_rate': 1.9e-05, 'epoch': 0.08}
{'loss': 0.306, 'learning_rate': 2e-05, 'epoch': 0.08}
{'loss': 0.3066, 'learning_rate': 2.1e-05, 'epoch': 0.08}
{'loss': 0.3034, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.09}
{'loss': 0.3059, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.09}
{'loss': 0.3047, 'learning_rate': 2.4e-05, 'epoch': 0.1}
{'loss': 0.2946, 'learning_rate': 2.5e-05, 'epoch': 0.1}
{'loss': 0.2919, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.1}
{'loss': 0.2935, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.11}
{'loss': 0.2858, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.11}
{'loss': 0.2888, 'learning_rate': 2.9e-05, 'epoch': 0.12}
{'loss': 0.2962, 'learning_rate': 3e-05, 'epoch': 0.12}
{'loss': 0.2796, 'learning_rate': 3.1e-05, 'epoch': 0.12}
{'loss': 0.2651, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.13}
{'loss': 0.26, 'learning_rate': 3.3e-05, 'epoch': 0.13}
{'loss': 0.273, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.14}
{'loss': 0.2691, 'learning_rate': 3.5e-05, 'epoch': 0.14}
{'loss': 0.2669, 'learning_rate': 3.6e-05, 'epoch': 0.14}
{'loss': 0.2618, 'learning_rate': 3.7e-05, 'epoch': 0.15}
{'loss': 0.2592, 'learning_rate': 3.8e-05, 'epoch': 0.15}
{'loss': 0.2576, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.16}
{'loss': 0.2612, 'learning_rate': 4e-05, 'epoch': 0.16}
{'loss': 0.2505, 'learning_rate': 4.1e-05, 'epoch': 0.16}
{'loss': 0.2502, 'learning_rate': 4.2e-05, 'epoch': 0.17}
{'loss': 0.2489, 'learning_rate': 4.3e-05, 'epoch': 0.17}
{'loss': 0.2452, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.18}
{'loss': 0.233, 'learning_rate': 4.5e-05, 'epoch': 0.18}
{'loss': 0.2424, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.18}
{'loss': 0.2404, 'learning_rate': 4.7e-05, 'epoch': 0.19}
{'loss': 0.238, 'learning_rate': 4.8e-05, 'epoch': 0.19}
{'loss': 0.2402, 'learning_rate': 4.9e-05, 'epoch': 0.2}
{'loss': 0.2466, 'learning_rate': 5e-05, 'epoch': 0.2}
{'loss': 0.2322, 'learning_rate': 4.975e-05, 'epoch': 0.2}
{'loss': 0.2377, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.21}
{'loss': 0.2249, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.21}
{'loss': 0.2225, 'learning_rate': 4.9e-05, 'epoch': 0.22}
{'loss': 0.2401, 'learning_rate': 4.875e-05, 'epoch': 0.22}
{'loss': 0.2337, 'learning_rate': 4.85e-05, 'epoch': 0.22}
{'loss': 0.2278, 'learning_rate': 4.825e-05, 'epoch': 0.23}
{'loss': 0.2226, 'learning_rate': 4.8e-05, 'epoch': 0.23}
{'loss': 0.2305, 'learning_rate': 4.775e-05, 'epoch': 0.24}
{'loss': 0.2195, 'learning_rate': 4.75e-05, 'epoch': 0.24}
{'loss': 0.2227, 'learning_rate': 4.7249999999999997e-05, 'epoch': 0.24}
{'loss': 0.2159, 'learning_rate': 4.7e-05, 'epoch': 0.25}
{'loss': 0.2203, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.25}
{'loss': 0.2205, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.26}
{'loss': 0.2136, 'learning_rate': 4.6250000000000006e-05, 'epoch': 0.26}
{'loss': 0.2078, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.26}
{'loss': 0.2084, 'learning_rate': 4.575e-05, 'epoch': 0.27}
{'loss': 0.2103, 'learning_rate': 4.55e-05, 'epoch': 0.27}
{'loss': 0.2139, 'learning_rate': 4.525e-05, 'epoch': 0.28}
{'loss': 0.2001, 'learning_rate': 4.5e-05, 'epoch': 0.28}
{'loss': 0.2031, 'learning_rate': 4.4750000000000004e-05, 'epoch': 0.28}
{'loss': 0.208, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.29}
{'loss': 0.1998, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.29}
{'loss': 0.2007, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.3}
{'loss': 0.2072, 'learning_rate': 4.375e-05, 'epoch': 0.3}
{'loss': 0.1982, 'learning_rate': 4.35e-05, 'epoch': 0.3}
{'loss': 0.1985, 'learning_rate': 4.325e-05, 'epoch': 0.31}
{'loss': 0.2068, 'learning_rate': 4.3e-05, 'epoch': 0.31}
{'loss': 0.2004, 'learning_rate': 4.275e-05, 'epoch': 0.32}
{'loss': 0.2027, 'learning_rate': 4.25e-05, 'epoch': 0.32}
{'loss': 0.1939, 'learning_rate': 4.2250000000000004e-05, 'epoch': 0.32}
{'loss': 0.181, 'learning_rate': 4.2e-05, 'epoch': 0.33}
{'loss': 0.1947, 'learning_rate': 4.175e-05, 'epoch': 0.33}
{'loss': 0.1911, 'learning_rate': 4.15e-05, 'epoch': 0.34}
{'loss': 0.1833, 'learning_rate': 4.125e-05, 'epoch': 0.34}
{'loss': 0.1922, 'learning_rate': 4.1e-05, 'epoch': 0.34}
{'loss': 0.188, 'learning_rate': 4.075e-05, 'epoch': 0.35}
{'loss': 0.1928, 'learning_rate': 4.05e-05, 'epoch': 0.35}
{'loss': 0.1844, 'learning_rate': 4.025e-05, 'epoch': 0.36}
{'loss': 0.1793, 'learning_rate': 4e-05, 'epoch': 0.36}
{'loss': 0.178, 'learning_rate': 3.9750000000000004e-05, 'epoch': 0.36}
{'loss': 0.1735, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.37}
{'loss': 0.1838, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.37}
{'loss': 0.1852, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.38}
{'loss': 0.1758, 'learning_rate': 3.875e-05, 'epoch': 0.38}
{'loss': 0.1758, 'learning_rate': 3.85e-05, 'epoch': 0.38}
{'loss': 0.1789, 'learning_rate': 3.825e-05, 'epoch': 0.39}
{'loss': 0.172, 'learning_rate': 3.8e-05, 'epoch': 0.39}
{'loss': 0.1708, 'learning_rate': 3.775e-05, 'epoch': 0.4}
{'loss': 0.1705, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.4}
{'loss': 0.1807, 'learning_rate': 3.7250000000000004e-05, 'epoch': 0.4}
{'loss': 0.1706, 'learning_rate': 3.7e-05, 'epoch': 0.41}
{'loss': 0.1706, 'learning_rate': 3.675e-05, 'epoch': 0.41}
{'loss': 0.1744, 'learning_rate': 3.65e-05, 'epoch': 0.42}
{'loss': 0.1575, 'learning_rate': 3.625e-05, 'epoch': 0.42}
{'loss': 0.1637, 'learning_rate': 3.6e-05, 'epoch': 0.42}
{'loss': 0.1717, 'learning_rate': 3.575e-05, 'epoch': 0.43}
{'loss': 0.1698, 'learning_rate': 3.55e-05, 'epoch': 0.43}
{'loss': 0.1719, 'learning_rate': 3.525e-05, 'epoch': 0.44}
{'loss': 0.1576, 'learning_rate': 3.5e-05, 'epoch': 0.44}
{'loss': 0.1636, 'learning_rate': 3.475e-05, 'epoch': 0.44}
{'loss': 0.1585, 'learning_rate': 3.45e-05, 'epoch': 0.45}
{'loss': 0.1631, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.45}
{'loss': 0.148, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.46}
{'loss': 0.169, 'learning_rate': 3.375000000000001e-05, 'epoch': 0.46}
{'loss': 0.1612, 'learning_rate': 3.35e-05, 'epoch': 0.46}
{'loss': 0.163, 'learning_rate': 3.325e-05, 'epoch': 0.47}
{'loss': 0.1548, 'learning_rate': 3.3e-05, 'epoch': 0.47}
{'loss': 0.1632, 'learning_rate': 3.275e-05, 'epoch': 0.48}
{'loss': 0.1511, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.48}
{'loss': 0.1524, 'learning_rate': 3.2250000000000005e-05, 'epoch': 0.48}
{'loss': 0.1558, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.49}
{'loss': 0.1379, 'learning_rate': 3.175e-05, 'epoch': 0.49}
{'loss': 0.1593, 'learning_rate': 3.15e-05, 'epoch': 0.5}
{'loss': 0.1474, 'learning_rate': 3.125e-05, 'epoch': 0.5}
{'loss': 0.1513, 'learning_rate': 3.1e-05, 'epoch': 0.5}
{'loss': 0.1458, 'learning_rate': 3.075e-05, 'epoch': 0.51}
{'loss': 0.1551, 'learning_rate': 3.05e-05, 'epoch': 0.51}
{'loss': 0.1561, 'learning_rate': 3.025e-05, 'epoch': 0.52}
{'loss': 0.1509, 'learning_rate': 3e-05, 'epoch': 0.52}
{'loss': 0.1519, 'learning_rate': 2.975e-05, 'epoch': 0.52}
{'loss': 0.1503, 'learning_rate': 2.95e-05, 'epoch': 0.53}
{'loss': 0.1379, 'learning_rate': 2.925e-05, 'epoch': 0.53}
{'loss': 0.14, 'learning_rate': 2.9e-05, 'epoch': 0.54}
{'loss': 0.1491, 'learning_rate': 2.8749999999999997e-05, 'epoch': 0.54}
{'loss': 0.1492, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.54}
{'loss': 0.1415, 'learning_rate': 2.825e-05, 'epoch': 0.55}
{'loss': 0.1444, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.55}
{'loss': 0.135, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.56}
{'loss': 0.1475, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.56}
{'loss': 0.1556, 'learning_rate': 2.725e-05, 'epoch': 0.56}
{'loss': 0.1392, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.57}
{'loss': 0.1415, 'learning_rate': 2.6750000000000003e-05, 'epoch': 0.57}
{'loss': 0.146, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.58}
{'loss': 0.1415, 'learning_rate': 2.625e-05, 'epoch': 0.58}
{'loss': 0.1357, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.58}
{'loss': 0.149, 'learning_rate': 2.5750000000000002e-05, 'epoch': 0.59}
{'loss': 0.1504, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.59}
{'loss': 0.1481, 'learning_rate': 2.525e-05, 'epoch': 0.6}
{'loss': 0.1464, 'learning_rate': 2.5e-05, 'epoch': 0.6}
{'loss': 0.1345, 'learning_rate': 2.4750000000000002e-05, 'epoch': 0.6}
{'loss': 0.1375, 'learning_rate': 2.45e-05, 'epoch': 0.61}
{'loss': 0.1405, 'learning_rate': 2.425e-05, 'epoch': 0.61}
{'loss': 0.1603, 'learning_rate': 2.4e-05, 'epoch': 0.62}
{'loss': 0.1418, 'learning_rate': 2.375e-05, 'epoch': 0.62}
{'loss': 0.1355, 'learning_rate': 2.35e-05, 'epoch': 0.62}
{'loss': 0.1418, 'learning_rate': 2.3250000000000003e-05, 'epoch': 0.63}
{'loss': 0.1378, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.63}
{'loss': 0.1401, 'learning_rate': 2.275e-05, 'epoch': 0.64}
{'loss': 0.13, 'learning_rate': 2.25e-05, 'epoch': 0.64}
{'loss': 0.1463, 'learning_rate': 2.2250000000000002e-05, 'epoch': 0.64}
{'loss': 0.1329, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.65}
{'loss': 0.143, 'learning_rate': 2.175e-05, 'epoch': 0.65}
{'loss': 0.1485, 'learning_rate': 2.15e-05, 'epoch': 0.66}
{'loss': 0.1267, 'learning_rate': 2.125e-05, 'epoch': 0.66}
{'loss': 0.1329, 'learning_rate': 2.1e-05, 'epoch': 0.66}
{'loss': 0.1364, 'learning_rate': 2.075e-05, 'epoch': 0.67}
{'loss': 0.1274, 'learning_rate': 2.05e-05, 'epoch': 0.67}
{'loss': 0.1358, 'learning_rate': 2.025e-05, 'epoch': 0.68}
{'loss': 0.1355, 'learning_rate': 2e-05, 'epoch': 0.68}
{'loss': 0.1256, 'learning_rate': 1.9750000000000002e-05, 'epoch': 0.68}
{'loss': 0.1297, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.69}
{'loss': 0.1347, 'learning_rate': 1.925e-05, 'epoch': 0.69}
{'loss': 0.1338, 'learning_rate': 1.9e-05, 'epoch': 0.7}
{'loss': 0.1338, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.7}
{'loss': 0.1378, 'learning_rate': 1.85e-05, 'epoch': 0.7}
{'loss': 0.1394, 'learning_rate': 1.825e-05, 'epoch': 0.71}
{'loss': 0.1333, 'learning_rate': 1.8e-05, 'epoch': 0.71}
{'loss': 0.13, 'learning_rate': 1.775e-05, 'epoch': 0.72}
{'loss': 0.1275, 'learning_rate': 1.75e-05, 'epoch': 0.72}
{'loss': 0.1323, 'learning_rate': 1.725e-05, 'epoch': 0.72}
{'loss': 0.1262, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.73}
{'loss': 0.1299, 'learning_rate': 1.675e-05, 'epoch': 0.73}
{'loss': 0.1403, 'learning_rate': 1.65e-05, 'epoch': 0.74}
{'loss': 0.1327, 'learning_rate': 1.6250000000000002e-05, 'epoch': 0.74}
{'loss': 0.1234, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.74}
{'loss': 0.1269, 'learning_rate': 1.575e-05, 'epoch': 0.75}
{'loss': 0.1306, 'learning_rate': 1.55e-05, 'epoch': 0.75}
{'loss': 0.1312, 'learning_rate': 1.525e-05, 'epoch': 0.76}
{'loss': 0.1293, 'learning_rate': 1.5e-05, 'epoch': 0.76}
{'loss': 0.1343, 'learning_rate': 1.475e-05, 'epoch': 0.76}
{'loss': 0.1208, 'learning_rate': 1.45e-05, 'epoch': 0.77}
{'loss': 0.138, 'learning_rate': 1.4249999999999999e-05, 'epoch': 0.77}
{'loss': 0.133, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.78}
{'loss': 0.1274, 'learning_rate': 1.3750000000000002e-05, 'epoch': 0.78}
{'loss': 0.1334, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.78}
{'loss': 0.1261, 'learning_rate': 1.3250000000000002e-05, 'epoch': 0.79}
{'loss': 0.1178, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.79}
{'loss': 0.1313, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.8}
{'loss': 0.1368, 'learning_rate': 1.25e-05, 'epoch': 0.8}
{'loss': 0.1248, 'learning_rate': 1.225e-05, 'epoch': 0.8}
{'loss': 0.1193, 'learning_rate': 1.2e-05, 'epoch': 0.81}
{'loss': 0.1209, 'learning_rate': 1.175e-05, 'epoch': 0.81}
{'loss': 0.1327, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.82}
{'loss': 0.1218, 'learning_rate': 1.125e-05, 'epoch': 0.82}
{'loss': 0.1269, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.82}
{'loss': 0.1329, 'learning_rate': 1.075e-05, 'epoch': 0.83}
{'loss': 0.1301, 'learning_rate': 1.05e-05, 'epoch': 0.83}
{'loss': 0.1246, 'learning_rate': 1.025e-05, 'epoch': 0.84}
{'loss': 0.1361, 'learning_rate': 1e-05, 'epoch': 0.84}
{'loss': 0.1181, 'learning_rate': 9.750000000000002e-06, 'epoch': 0.84}
{'loss': 0.1281, 'learning_rate': 9.5e-06, 'epoch': 0.85}
{'loss': 0.1331, 'learning_rate': 9.25e-06, 'epoch': 0.85}
{'loss': 0.1234, 'learning_rate': 9e-06, 'epoch': 0.86}
{'loss': 0.1229, 'learning_rate': 8.75e-06, 'epoch': 0.86}
{'loss': 0.1175, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.86}
{'loss': 0.1239, 'learning_rate': 8.25e-06, 'epoch': 0.87}
{'loss': 0.1248, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.87}
{'loss': 0.1136, 'learning_rate': 7.75e-06, 'epoch': 0.88}
{'loss': 0.1302, 'learning_rate': 7.5e-06, 'epoch': 0.88}
{'loss': 0.1208, 'learning_rate': 7.25e-06, 'epoch': 0.88}
{'loss': 0.1315, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.89}
{'loss': 0.1192, 'learning_rate': 6.750000000000001e-06, 'epoch': 0.89}
{'loss': 0.1189, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.9}
{'loss': 0.1236, 'learning_rate': 6.25e-06, 'epoch': 0.9}
{'loss': 0.126, 'learning_rate': 6e-06, 'epoch': 0.9}
{'loss': 0.1368, 'learning_rate': 5.750000000000001e-06, 'epoch': 0.91}
{'loss': 0.1253, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.91}
{'loss': 0.1257, 'learning_rate': 5.25e-06, 'epoch': 0.92}
{'loss': 0.129, 'learning_rate': 5e-06, 'epoch': 0.92}
{'loss': 0.1319, 'learning_rate': 4.75e-06, 'epoch': 0.92}
{'loss': 0.1181, 'learning_rate': 4.5e-06, 'epoch': 0.93}
{'loss': 0.13, 'learning_rate': 4.250000000000001e-06, 'epoch': 0.93}
{'loss': 0.1222, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.94}
{'loss': 0.1254, 'learning_rate': 3.75e-06, 'epoch': 0.94}
{'loss': 0.1209, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.94}
{'loss': 0.1197, 'learning_rate': 3.2500000000000002e-06, 'epoch': 0.95}
{'loss': 0.126, 'learning_rate': 3e-06, 'epoch': 0.95}
{'loss': 0.1221, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.96}
{'loss': 0.1179, 'learning_rate': 2.5e-06, 'epoch': 0.96}
{'loss': 0.1318, 'learning_rate': 2.25e-06, 'epoch': 0.96}
{'loss': 0.125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.97}
{'loss': 0.1287, 'learning_rate': 1.7500000000000002e-06, 'epoch': 0.97}
{'loss': 0.1258, 'learning_rate': 1.5e-06, 'epoch': 0.98}
{'loss': 0.1266, 'learning_rate': 1.25e-06, 'epoch': 0.98}
{'loss': 0.1221, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.98}
{'loss': 0.1246, 'learning_rate': 7.5e-07, 'epoch': 0.99}
{'loss': 0.1218, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.99}
{'loss': 0.1182, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
{'loss': 0.1226, 'learning_rate': 0.0, 'epoch': 1.0}
{'train_runtime': 978.083, 'train_samples_per_second': 10.224, 'train_steps_per_second': 2.556, 'train_loss': 0.3151447108268738, 'epoch': 1.0}
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
