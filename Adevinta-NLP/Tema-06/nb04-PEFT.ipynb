{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/Adevinta-ULPGC-logo.jpg\" width=\"530px\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parameter-Efficient Fine-Tuning (PEFT)**\n",
    "\n",
    "https://huggingface.co/docs/peft/index  <-- Empezar por aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Parameter-Efficient Fine-Tuning (PEFT) se refiere a técnicas de ajuste fino que buscan mejorar o adaptar modelos de aprendizaje profundo preentrenados, especialmente modelos de lenguaje de gran escala, a tareas específicas sin necesidad de reentrenar completamente todos los parámetros del modelo. Este enfoque es particularmente valioso dada la creciente escala de los modelos de lenguaje natural (como GPT, BERT, y similares), cuyo entrenamiento completo requiere una cantidad significativa de recursos computacionales y energéticos.\n",
    "\n",
    "PEFT aborda el desafío de cómo hacer que el ajuste fino de estos modelos sea más accesible y práctico, permitiendo personalizar los modelos a tareas específicas con menos recursos. Algunas de las técnicas dentro de este enfoque incluyen:\n",
    "\n",
    "### 1. **Low-Rank Adaptation**\n",
    "\n",
    "<a href=\"https://arxiv.org/pdf/2106.09685.pdf\">LoRA: Low-Rank Adaptation of Large Language Models</a>\n",
    "\n",
    "Esta técnica se basa en la adición de matrices de bajo rango que modifican las representaciones intermedias del modelo. Al ajustar estas matrices de bajo rango, se puede influir en el comportamiento del modelo con un costo computacional relativamente bajo.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./imgs/LoRA.png\" width=\"350px\">\n",
    "</div>\n",
    "\n",
    "Estas matrices de bajo rango se insertan en los parámetros de un modelo preentrenado, específicamente en los puntos de interacción clave como las matrices de transformación en capas de atención y capas feed-forward. \n",
    "\n",
    "Matemáticamente, esto se logra ya que la matriz de adaptación es el producto de dos matrices más pequeñas, facilitando así una modificación eficiente del comportamiento del modelo con una cantidad mínima de parámetros adicionales.\n",
    "\n",
    "Consideremos una capa específica en un modelo, donde la operación lineal original es $ W $, una matriz que transforma la entrada $ x $ en la salida $ y $, es decir, $ y = Wx $.\n",
    "\n",
    "1. **Introducción del Adaptador de Bajo Rango:**\n",
    "   En LoRA, en lugar de modificar $ W $ directamente, se introduce una adaptación $ \\Delta W $ que es de bajo rango. Matemáticamente, $ \\Delta W $ se expresa como el producto de dos matrices de menor dimensión $ A $ y $ B $, es decir,\n",
    "   $$\n",
    "   \\Delta W = AB\n",
    "   $$\n",
    "   donde $ A $ es una matriz de $ d \\times r $ y $ B $ es una matriz de $ r \\times d $. Aquí, $ r $ es el rango de la adaptación y es mucho menor que $ d $, la dimensión de la entrada y salida.\n",
    "\n",
    "2. **Modificación de la Transformación Lineal:**\n",
    "   La nueva transformación lineal del modelo con la adaptación de bajo rango se convierte en:\n",
    "   $$\n",
    "   y = (W + \\Delta W)x = (W + AB)x\n",
    "   $$\n",
    "   Aquí, $ W $ es la matriz original y $ AB $ es la adaptación de bajo rango que ajusta la transformación de $ W $ para adaptarse mejor a una tarea específica.\n",
    "\n",
    "3. **Cálculo de la Salida Modificada:**\n",
    "   Al descomponer $ \\Delta W $ en el producto de $ A $ y $ B $, reducimos el número de parámetros a entrenar desde $ d^2 $ (si se modificara $ W $ completamente) a $ d \\times r + r \\times d $, lo cual es significativamente menor si $ r $ es pequeño.\n",
    "\n",
    "##### **Ejemplo en un Transformer**\n",
    "\n",
    "Consideremos la capa de atención donde $ Q, K, V $ (consultas, claves y valores) son transformados por las matrices $ W^Q, W^K, W^V $. Con LoRA, se introducirían adaptaciones $ \\Delta W^Q, \\Delta W^K, \\Delta W^V $ tal que:\n",
    "   $$\n",
    "   Q = (W^Q + \\Delta W^Q)X, \\quad K = (W^K + \\Delta W^K)X, \\quad V = (W^V + \\Delta W^V)X\n",
    "   $$\n",
    "donde $ X $ es la entrada a la capa de atención y cada $ \\Delta W $ es una adaptación de bajo rango específica para $ Q, K, $ o $ V $.\n",
    "\n",
    "Este enfoque permite una flexibilidad considerable en la adaptación del modelo a nuevas tareas, permitiendo ajustes finos donde es más necesario con un mínimo impacto en el tamaño y la complejidad del modelo.\n",
    "\n",
    "\n",
    "#### **QLoRA: Quantized Low-Rank Adaptation for Efficient Fine-Tuning of Pretrained Transformers**\n",
    "\n",
    "QLoRA y LoRA son técnicas de adaptación para modelos de lenguaje de gran escala, pero QLoRA presenta cuantización, lo que significa que utiliza versiones de menor precisión de los números para reducir los requisitos de memoria y computación. Esto es especialmente útil para despliegues en dispositivos con recursos limitados.\n",
    "\n",
    "### 2. **Adapters**\n",
    "\n",
    "<a href=\"https://arxiv.org/pdf/1902.00751.pdf\">Parameter-Efficient Transfer Learning for NLP</a>\n",
    "\n",
    "Un \"adapter\" es esencialmente un módulo pequeño y entrenable que se inserta entre las capas preexistentes de un modelo de lenguaje grande. Estos módulos tienen una estructura específica, generalmente consistiendo en una capa de reducción de dimensionalidad, una transformación no lineal, y una capa de expansión de dimensionalidad. La idea es que estos adapters aprendan ajustes específicos para la tarea en cuestión, mientras que los parámetros originales del modelo (los de las grandes capas preentrenadas) permanecen congelados.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./imgs/adapters.webp\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./imgs/adapters.png\" width=\"250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejemplo: GPT2 - PEFT**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cayetano/Propio/Notebooks/Machine Learning/RL/env/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, file_path, block_size=128):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "        self.examples = []\n",
    "        for line in lines:\n",
    "            tokens = tokenizer.encode(line, add_special_tokens=True)\n",
    "            if len(tokens) > block_size:\n",
    "                tokens = tokens[:block_size]\n",
    "            tokens += [tokenizer.eos_token_id]\n",
    "            tokens += [tokenizer.pad_token_id] * (block_size - len(tokens))\n",
    "            self.examples.append(torch.tensor(tokens))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        res = {\"input_ids\": self.examples[i][:-1], \"labels\": self.examples[i][1:]}\n",
    "        # res = {\"input_ids\": self.examples[i]}\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones\n",
    "file_path = 'data/numbers_gpt.csv'  # Ajusta esto al path de tu archivo de texto\n",
    "block_size = 128  # Longitud máxima de las secuencias de tokens\n",
    "\n",
    "# Cargar tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Preparar el dataset\n",
    "dataset = TextDataset(tokenizer, file_path, block_size)\n",
    "\n",
    "# Crear DataLoader para iterar sobre el dataset durante el entrenamiento\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene 124439808 parámetros entrenables\n",
      "El modelo tiene 124439808 parámetros totales\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Número de parámetros entrenables del modelo\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"El modelo tiene {num_params} parámetros entrenables\")\n",
    "\n",
    "# Número de parámetros del modelo\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"El modelo tiene {num_params} parámetros totales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar LoRA\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\", \"c_proj\", \"c_fc\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    fan_in_fan_out=True,\n",
    ")\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene 1179648 parámetros entrenables\n",
      "El modelo tiene 125619456 parámetros\n"
     ]
    }
   ],
   "source": [
    "# Número de parámetros entrenables del modelo\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"El modelo tiene {num_params} parámetros entrenables\")\n",
    "\n",
    "# Número de parámetros del modelo\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"El modelo tiene {num_params} parámetros totales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcayetano\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/cayetano/Propio/Docencia/cayetanoguerra.github.io/Adevinta-NLP/Tema-06/wandb/run-20240423_112608-np5adajy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cayetano/huggingface/runs/np5adajy' target=\"_blank\">earnest-voice-38</a></strong> to <a href='https://wandb.ai/cayetano/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cayetano/huggingface' target=\"_blank\">https://wandb.ai/cayetano/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cayetano/huggingface/runs/np5adajy' target=\"_blank\">https://wandb.ai/cayetano/huggingface/runs/np5adajy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8013bb5aaf39448c8fecbbb63aaa60e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.5621, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 12.532, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 12.494, 'learning_rate': 3e-06, 'epoch': 0.01}\n",
      "{'loss': 12.434, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 12.3959, 'learning_rate': 5e-06, 'epoch': 0.02}\n",
      "{'loss': 12.2208, 'learning_rate': 6e-06, 'epoch': 0.02}\n",
      "{'loss': 12.0261, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 11.7139, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 11.2695, 'learning_rate': 9e-06, 'epoch': 0.04}\n",
      "{'loss': 10.8182, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 9.8953, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 8.7168, 'learning_rate': 1.2e-05, 'epoch': 0.05}\n",
      "{'loss': 7.2017, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.05}\n",
      "{'loss': 5.7925, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.06}\n",
      "{'loss': 4.4684, 'learning_rate': 1.5e-05, 'epoch': 0.06}\n",
      "{'loss': 3.0273, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0733, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 1.5537, 'learning_rate': 1.8e-05, 'epoch': 0.07}\n",
      "{'loss': 1.2412, 'learning_rate': 1.9e-05, 'epoch': 0.08}\n",
      "{'loss': 1.0961, 'learning_rate': 2e-05, 'epoch': 0.08}\n",
      "{'loss': 0.9341, 'learning_rate': 2.1e-05, 'epoch': 0.08}\n",
      "{'loss': 0.9155, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 0.867, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 0.809, 'learning_rate': 2.4e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7975, 'learning_rate': 2.5e-05, 'epoch': 0.1}\n",
      "{'loss': 0.736, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7118, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6709, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6311, 'learning_rate': 2.9e-05, 'epoch': 0.12}\n",
      "{'loss': 0.6243, 'learning_rate': 3e-05, 'epoch': 0.12}\n",
      "{'loss': 0.6084, 'learning_rate': 3.1e-05, 'epoch': 0.12}\n",
      "{'loss': 0.5831, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.13}\n",
      "{'loss': 0.5522, 'learning_rate': 3.3e-05, 'epoch': 0.13}\n",
      "{'loss': 0.5184, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.14}\n",
      "{'loss': 0.5017, 'learning_rate': 3.5e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4894, 'learning_rate': 3.6e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4685, 'learning_rate': 3.7e-05, 'epoch': 0.15}\n",
      "{'loss': 0.455, 'learning_rate': 3.8e-05, 'epoch': 0.15}\n",
      "{'loss': 0.4382, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4319, 'learning_rate': 4e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4238, 'learning_rate': 4.1e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4093, 'learning_rate': 4.2e-05, 'epoch': 0.17}\n",
      "{'loss': 0.3965, 'learning_rate': 4.3e-05, 'epoch': 0.17}\n",
      "{'loss': 0.3974, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3882, 'learning_rate': 4.5e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3838, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3694, 'learning_rate': 4.7e-05, 'epoch': 0.19}\n",
      "{'loss': 0.3723, 'learning_rate': 4.8e-05, 'epoch': 0.19}\n",
      "{'loss': 0.3607, 'learning_rate': 4.9e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3633, 'learning_rate': 5e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3543, 'learning_rate': 4.975e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3595, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.21}\n",
      "{'loss': 0.354, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.21}\n",
      "{'loss': 0.349, 'learning_rate': 4.9e-05, 'epoch': 0.22}\n",
      "{'loss': 0.347, 'learning_rate': 4.875e-05, 'epoch': 0.22}\n",
      "{'loss': 0.3507, 'learning_rate': 4.85e-05, 'epoch': 0.22}\n",
      "{'loss': 0.3518, 'learning_rate': 4.825e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3317, 'learning_rate': 4.8e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3406, 'learning_rate': 4.775e-05, 'epoch': 0.24}\n",
      "{'loss': 0.3395, 'learning_rate': 4.75e-05, 'epoch': 0.24}\n",
      "{'loss': 0.3406, 'learning_rate': 4.7249999999999997e-05, 'epoch': 0.24}\n",
      "{'loss': 0.3385, 'learning_rate': 4.7e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3352, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3399, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.26}\n",
      "{'loss': 0.345, 'learning_rate': 4.6250000000000006e-05, 'epoch': 0.26}\n",
      "{'loss': 0.3336, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.26}\n",
      "{'loss': 0.3277, 'learning_rate': 4.575e-05, 'epoch': 0.27}\n",
      "{'loss': 0.331, 'learning_rate': 4.55e-05, 'epoch': 0.27}\n",
      "{'loss': 0.326, 'learning_rate': 4.525e-05, 'epoch': 0.28}\n",
      "{'loss': 0.3193, 'learning_rate': 4.5e-05, 'epoch': 0.28}\n",
      "{'loss': 0.3308, 'learning_rate': 4.4750000000000004e-05, 'epoch': 0.28}\n",
      "{'loss': 0.3193, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.29}\n",
      "{'loss': 0.322, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3219, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3178, 'learning_rate': 4.375e-05, 'epoch': 0.3}\n",
      "{'loss': 0.321, 'learning_rate': 4.35e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3181, 'learning_rate': 4.325e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3286, 'learning_rate': 4.3e-05, 'epoch': 0.31}\n",
      "{'loss': 0.31, 'learning_rate': 4.275e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3148, 'learning_rate': 4.25e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3323, 'learning_rate': 4.2250000000000004e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3071, 'learning_rate': 4.2e-05, 'epoch': 0.33}\n",
      "{'loss': 0.3131, 'learning_rate': 4.175e-05, 'epoch': 0.33}\n",
      "{'loss': 0.32, 'learning_rate': 4.15e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3171, 'learning_rate': 4.125e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3081, 'learning_rate': 4.1e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3121, 'learning_rate': 4.075e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3092, 'learning_rate': 4.05e-05, 'epoch': 0.35}\n",
      "{'loss': 0.314, 'learning_rate': 4.025e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3156, 'learning_rate': 4e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3059, 'learning_rate': 3.9750000000000004e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3044, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3137, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3077, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3126, 'learning_rate': 3.875e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3022, 'learning_rate': 3.85e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3064, 'learning_rate': 3.825e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3118, 'learning_rate': 3.8e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3045, 'learning_rate': 3.775e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2999, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2956, 'learning_rate': 3.7250000000000004e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3019, 'learning_rate': 3.7e-05, 'epoch': 0.41}\n",
      "{'loss': 0.3031, 'learning_rate': 3.675e-05, 'epoch': 0.41}\n",
      "{'loss': 0.3019, 'learning_rate': 3.65e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2885, 'learning_rate': 3.625e-05, 'epoch': 0.42}\n",
      "{'loss': 0.3023, 'learning_rate': 3.6e-05, 'epoch': 0.42}\n",
      "{'loss': 0.3086, 'learning_rate': 3.575e-05, 'epoch': 0.43}\n",
      "{'loss': 0.305, 'learning_rate': 3.55e-05, 'epoch': 0.43}\n",
      "{'loss': 0.3046, 'learning_rate': 3.525e-05, 'epoch': 0.44}\n",
      "{'loss': 0.3019, 'learning_rate': 3.5e-05, 'epoch': 0.44}\n",
      "{'loss': 0.3013, 'learning_rate': 3.475e-05, 'epoch': 0.44}\n",
      "{'loss': 0.2897, 'learning_rate': 3.45e-05, 'epoch': 0.45}\n",
      "{'loss': 0.2957, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.45}\n",
      "{'loss': 0.2967, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2998, 'learning_rate': 3.375000000000001e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2955, 'learning_rate': 3.35e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2925, 'learning_rate': 3.325e-05, 'epoch': 0.47}\n",
      "{'loss': 0.2981, 'learning_rate': 3.3e-05, 'epoch': 0.47}\n",
      "{'loss': 0.2961, 'learning_rate': 3.275e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2841, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2923, 'learning_rate': 3.2250000000000005e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2961, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.49}\n",
      "{'loss': 0.2762, 'learning_rate': 3.175e-05, 'epoch': 0.49}\n",
      "{'loss': 0.2909, 'learning_rate': 3.15e-05, 'epoch': 0.5}\n",
      "{'loss': 0.2917, 'learning_rate': 3.125e-05, 'epoch': 0.5}\n",
      "{'loss': 0.2918, 'learning_rate': 3.1e-05, 'epoch': 0.5}\n",
      "{'loss': 0.2893, 'learning_rate': 3.075e-05, 'epoch': 0.51}\n",
      "{'loss': 0.2972, 'learning_rate': 3.05e-05, 'epoch': 0.51}\n",
      "{'loss': 0.2974, 'learning_rate': 3.025e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2919, 'learning_rate': 3e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2963, 'learning_rate': 2.975e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2889, 'learning_rate': 2.95e-05, 'epoch': 0.53}\n",
      "{'loss': 0.2901, 'learning_rate': 2.925e-05, 'epoch': 0.53}\n",
      "{'loss': 0.2923, 'learning_rate': 2.9e-05, 'epoch': 0.54}\n",
      "{'loss': 0.2965, 'learning_rate': 2.8749999999999997e-05, 'epoch': 0.54}\n",
      "{'loss': 0.2926, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.54}\n",
      "{'loss': 0.2958, 'learning_rate': 2.825e-05, 'epoch': 0.55}\n",
      "{'loss': 0.2883, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.55}\n",
      "{'loss': 0.2811, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.56}\n",
      "{'loss': 0.287, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.56}\n",
      "{'loss': 0.2969, 'learning_rate': 2.725e-05, 'epoch': 0.56}\n",
      "{'loss': 0.2858, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.57}\n",
      "{'loss': 0.2892, 'learning_rate': 2.6750000000000003e-05, 'epoch': 0.57}\n",
      "{'loss': 0.284, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.58}\n",
      "{'loss': 0.2777, 'learning_rate': 2.625e-05, 'epoch': 0.58}\n",
      "{'loss': 0.2823, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.58}\n",
      "{'loss': 0.2849, 'learning_rate': 2.5750000000000002e-05, 'epoch': 0.59}\n",
      "{'loss': 0.2866, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.59}\n",
      "{'loss': 0.2867, 'learning_rate': 2.525e-05, 'epoch': 0.6}\n",
      "{'loss': 0.2833, 'learning_rate': 2.5e-05, 'epoch': 0.6}\n",
      "{'loss': 0.2873, 'learning_rate': 2.4750000000000002e-05, 'epoch': 0.6}\n",
      "{'loss': 0.2863, 'learning_rate': 2.45e-05, 'epoch': 0.61}\n",
      "{'loss': 0.2801, 'learning_rate': 2.425e-05, 'epoch': 0.61}\n",
      "{'loss': 0.2867, 'learning_rate': 2.4e-05, 'epoch': 0.62}\n",
      "{'loss': 0.2887, 'learning_rate': 2.375e-05, 'epoch': 0.62}\n",
      "{'loss': 0.2781, 'learning_rate': 2.35e-05, 'epoch': 0.62}\n",
      "{'loss': 0.2912, 'learning_rate': 2.3250000000000003e-05, 'epoch': 0.63}\n",
      "{'loss': 0.2874, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.63}\n",
      "{'loss': 0.2897, 'learning_rate': 2.275e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2851, 'learning_rate': 2.25e-05, 'epoch': 0.64}\n",
      "{'loss': 0.287, 'learning_rate': 2.2250000000000002e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2807, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.65}\n",
      "{'loss': 0.2927, 'learning_rate': 2.175e-05, 'epoch': 0.65}\n",
      "{'loss': 0.2921, 'learning_rate': 2.15e-05, 'epoch': 0.66}\n",
      "{'loss': 0.2824, 'learning_rate': 2.125e-05, 'epoch': 0.66}\n",
      "{'loss': 0.278, 'learning_rate': 2.1e-05, 'epoch': 0.66}\n",
      "{'loss': 0.2838, 'learning_rate': 2.075e-05, 'epoch': 0.67}\n",
      "{'loss': 0.2773, 'learning_rate': 2.05e-05, 'epoch': 0.67}\n",
      "{'loss': 0.2808, 'learning_rate': 2.025e-05, 'epoch': 0.68}\n",
      "{'loss': 0.278, 'learning_rate': 2e-05, 'epoch': 0.68}\n",
      "{'loss': 0.2726, 'learning_rate': 1.9750000000000002e-05, 'epoch': 0.68}\n",
      "{'loss': 0.2727, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.69}\n",
      "{'loss': 0.2815, 'learning_rate': 1.925e-05, 'epoch': 0.69}\n",
      "{'loss': 0.2783, 'learning_rate': 1.9e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2836, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2816, 'learning_rate': 1.85e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2849, 'learning_rate': 1.825e-05, 'epoch': 0.71}\n",
      "{'loss': 0.2854, 'learning_rate': 1.8e-05, 'epoch': 0.71}\n",
      "{'loss': 0.2723, 'learning_rate': 1.775e-05, 'epoch': 0.72}\n",
      "{'loss': 0.2787, 'learning_rate': 1.75e-05, 'epoch': 0.72}\n",
      "{'loss': 0.2796, 'learning_rate': 1.725e-05, 'epoch': 0.72}\n",
      "{'loss': 0.2734, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.73}\n",
      "{'loss': 0.2814, 'learning_rate': 1.675e-05, 'epoch': 0.73}\n",
      "{'loss': 0.2806, 'learning_rate': 1.65e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2766, 'learning_rate': 1.6250000000000002e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2695, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2847, 'learning_rate': 1.575e-05, 'epoch': 0.75}\n",
      "{'loss': 0.2815, 'learning_rate': 1.55e-05, 'epoch': 0.75}\n",
      "{'loss': 0.269, 'learning_rate': 1.525e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2751, 'learning_rate': 1.5e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2721, 'learning_rate': 1.475e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2714, 'learning_rate': 1.45e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2837, 'learning_rate': 1.4249999999999999e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2808, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.78}\n",
      "{'loss': 0.2836, 'learning_rate': 1.3750000000000002e-05, 'epoch': 0.78}\n",
      "{'loss': 0.2753, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.78}\n",
      "{'loss': 0.2705, 'learning_rate': 1.3250000000000002e-05, 'epoch': 0.79}\n",
      "{'loss': 0.2653, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.79}\n",
      "{'loss': 0.266, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2822, 'learning_rate': 1.25e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2762, 'learning_rate': 1.225e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2731, 'learning_rate': 1.2e-05, 'epoch': 0.81}\n",
      "{'loss': 0.2666, 'learning_rate': 1.175e-05, 'epoch': 0.81}\n",
      "{'loss': 0.2751, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.82}\n",
      "{'loss': 0.2692, 'learning_rate': 1.125e-05, 'epoch': 0.82}\n",
      "{'loss': 0.2744, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.82}\n",
      "{'loss': 0.2692, 'learning_rate': 1.075e-05, 'epoch': 0.83}\n",
      "{'loss': 0.278, 'learning_rate': 1.05e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2811, 'learning_rate': 1.025e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2822, 'learning_rate': 1e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2738, 'learning_rate': 9.750000000000002e-06, 'epoch': 0.84}\n",
      "{'loss': 0.2817, 'learning_rate': 9.5e-06, 'epoch': 0.85}\n",
      "{'loss': 0.278, 'learning_rate': 9.25e-06, 'epoch': 0.85}\n",
      "{'loss': 0.2742, 'learning_rate': 9e-06, 'epoch': 0.86}\n",
      "{'loss': 0.2762, 'learning_rate': 8.75e-06, 'epoch': 0.86}\n",
      "{'loss': 0.2667, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.86}\n",
      "{'loss': 0.2734, 'learning_rate': 8.25e-06, 'epoch': 0.87}\n",
      "{'loss': 0.2755, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.87}\n",
      "{'loss': 0.2724, 'learning_rate': 7.75e-06, 'epoch': 0.88}\n",
      "{'loss': 0.2852, 'learning_rate': 7.5e-06, 'epoch': 0.88}\n",
      "{'loss': 0.2779, 'learning_rate': 7.25e-06, 'epoch': 0.88}\n",
      "{'loss': 0.2833, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 0.2652, 'learning_rate': 6.750000000000001e-06, 'epoch': 0.89}\n",
      "{'loss': 0.2741, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.9}\n",
      "{'loss': 0.2765, 'learning_rate': 6.25e-06, 'epoch': 0.9}\n",
      "{'loss': 0.2694, 'learning_rate': 6e-06, 'epoch': 0.9}\n",
      "{'loss': 0.2887, 'learning_rate': 5.750000000000001e-06, 'epoch': 0.91}\n",
      "{'loss': 0.2688, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.91}\n",
      "{'loss': 0.2736, 'learning_rate': 5.25e-06, 'epoch': 0.92}\n",
      "{'loss': 0.2772, 'learning_rate': 5e-06, 'epoch': 0.92}\n",
      "{'loss': 0.2625, 'learning_rate': 4.75e-06, 'epoch': 0.92}\n",
      "{'loss': 0.2778, 'learning_rate': 4.5e-06, 'epoch': 0.93}\n",
      "{'loss': 0.272, 'learning_rate': 4.250000000000001e-06, 'epoch': 0.93}\n",
      "{'loss': 0.2684, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.94}\n",
      "{'loss': 0.2615, 'learning_rate': 3.75e-06, 'epoch': 0.94}\n",
      "{'loss': 0.2717, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.94}\n",
      "{'loss': 0.2791, 'learning_rate': 3.2500000000000002e-06, 'epoch': 0.95}\n",
      "{'loss': 0.2712, 'learning_rate': 3e-06, 'epoch': 0.95}\n",
      "{'loss': 0.2714, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.96}\n",
      "{'loss': 0.2603, 'learning_rate': 2.5e-06, 'epoch': 0.96}\n",
      "{'loss': 0.271, 'learning_rate': 2.25e-06, 'epoch': 0.96}\n",
      "{'loss': 0.2649, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.97}\n",
      "{'loss': 0.2742, 'learning_rate': 1.7500000000000002e-06, 'epoch': 0.97}\n",
      "{'loss': 0.2738, 'learning_rate': 1.5e-06, 'epoch': 0.98}\n",
      "{'loss': 0.2778, 'learning_rate': 1.25e-06, 'epoch': 0.98}\n",
      "{'loss': 0.2763, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.98}\n",
      "{'loss': 0.2727, 'learning_rate': 7.5e-07, 'epoch': 0.99}\n",
      "{'loss': 0.2677, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.99}\n",
      "{'loss': 0.2677, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}\n",
      "{'loss': 0.2732, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 851.961, 'train_samples_per_second': 11.738, 'train_steps_per_second': 2.934, 'train_loss': 0.9628114163398742, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('modelo_entrenado/tokenizer_config.json',\n",
       " 'modelo_entrenado/special_tokens_map.json',\n",
       " 'modelo_entrenado/vocab.json',\n",
       " 'modelo_entrenado/merges.txt',\n",
       " 'modelo_entrenado/added_tokens.json',\n",
       " 'modelo_entrenado/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_save_function(output_dir):\n",
    "    model.save_pretrained(output_dir)\n",
    "\n",
    "# Configurar los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"modelo_entrenado\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "# Crear el objeto Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    # eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "trainer.train()\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save_pretrained(\"modelo_entrenado\")\n",
    "tokenizer.save_pretrained(\"modelo_entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generación del texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número 123456789 en formato textual es: 123456789, hundred million hundred nine five eight fifty thousand hundred nine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Cargar el modelo y el tokenizador entrenados\n",
    "model_path = \"modelo_entrenado\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Generar número en formato textual\n",
    "def generate_textual_number(numeric_number):\n",
    "    input_text = str(numeric_number)\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(\"mps\")\n",
    "    output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "    textual_number = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return textual_number\n",
    "\n",
    "# Ejemplo de uso\n",
    "numeric_number = 123456789\n",
    "textual_number = generate_textual_number(numeric_number)\n",
    "print(f\"El número {numeric_number} en formato textual es: {textual_number}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
