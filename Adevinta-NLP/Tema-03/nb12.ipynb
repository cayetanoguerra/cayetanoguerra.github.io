{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/Adevinta-ULPGC-logo.jpg\" width=\"530px\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Redes neuronales 5**\n",
    "\n",
    "\n",
    "## **Funciones de pérdida**\n",
    "\n",
    "las funciones de pérdida juegan un papel crucial, ya que miden la discrepancia entre las predicciones del modelo y los valores reales de los datos. Elegir una función de pérdida adecuada es fundamental para guiar al modelo durante el proceso de aprendizaje. Existen varias funciones de pérdida (*loss*) que se usan comúnmente en redes.\n",
    "\n",
    "#### **MSE** \n",
    "\n",
    "Mean Squared Error, calcula el promedio de los cuadrados de los errores entre las predicciones y los valores reales. Su formulación es:\n",
    "\n",
    "$$ \\text{MSE} = \\frac{\\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2}{m}  $$\n",
    "\n",
    "\n",
    "#### **Entropía cruzada**\n",
    "\n",
    "**Entropía cruzada binaria** o **Binary Cross Entropy**. Mide el desempeño de un modelo de clasificación cuyo output es un valor de probabilidad entre 0 y 1. Es ideal para problemas de clasificación binaria.\n",
    "\n",
    "$$ \\text{CE} = - \\sum_{i=1}^{m} y_i log(\\hat{y}_i) + (1-y_i) log(1-\\hat{y}_i) $$\n",
    "\n",
    "**Entropía cruzada categórica** o **Categorical Cross Entropy**. Es una extensión de la entropía cruzada binaria para problemas de clasificación con más de dos clases. Requiere que las etiquetas sean codificadas en **one-hot**.\n",
    "\n",
    "$$ \\text{CE} = - \\sum_{c=1}^{C} y_c log(\\hat{y}_c)$$\n",
    "\n",
    "#### **Divergencia de Kullback-Leibler**\n",
    "\n",
    "Mide cuánto se diferencia una distribución de probabilidad de otra. Se utiliza en problemas donde se quiere que las predicciones se acerquen a una distribución de probabilidad específica.\n",
    "\n",
    "$$ \\text{KL} = \\sum_{i=1}^{m} p(x_i) log(\\frac{p(x_i)}{q(x_i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Progreso de la función de pérdida**\n",
    "\n",
    "El progreso de la función de pérdida durante el entrenamiento de una red neuronal ofrece una visión valiosa del proceso de aprendizaje del modelo. Monitorear este progreso es fundamental por varias razones:\n",
    "\n",
    "1. **Diagnóstico de Aprendizaje**\n",
    "Convergencia: Una disminución constante en la función de pérdida indica que el modelo está aprendiendo y mejorando su capacidad de hacer predicciones precisas. Si la función de pérdida converge hacia un valor bajo, sugiere que el modelo está ajustándose bien a los datos de entrenamiento.\n",
    "Divergencia: Por otro lado, si la función de pérdida aumenta o fluctúa ampliamente, puede ser una señal de que el modelo no está aprendiendo correctamente. Esto podría deberse a un tamaño de paso de aprendizaje (learning rate) demasiado alto, problemas en la preparación de los datos, o una arquitectura de modelo inapropiada.\n",
    "\n",
    "2. **Detección de Sobreajuste y Subajuste**\n",
    "Sobreajuste (Overfitting): Ocurre cuando el modelo aprende demasiado bien los datos de entrenamiento, incluyendo el ruido y las anomalías, lo que resulta en un rendimiento pobre en datos no vistos (datos de validación o prueba). Si la pérdida de entrenamiento disminuye mientras que la pérdida de validación aumenta, es una clara indicación de sobreajuste. Subajuste (Underfitting): Se da cuando el modelo no puede capturar la estructura subyacente de los datos, resultando en una mala actuación tanto en el conjunto de entrenamiento como en el de validación. Esto puede ser indicativo de un modelo demasiado simple, una regularización excesiva, o un entrenamiento insuficiente.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"imgs/overfitting.png\" width=\"500px\">\n",
    "</div>\n",
    "\n",
    "\n",
    "3. **Ajuste de Hiperparámetros**\n",
    "La observación del progreso de la función de pérdida ayuda a ajustar los hiperparámetros del modelo, como la tasa de aprendizaje, el tamaño del lote (batch size), o la cantidad de épocas de entrenamiento. Encontrar el equilibrio correcto de estos hiperparámetros es crucial para optimizar el rendimiento del modelo.\n",
    "\n",
    "\n",
    "4. **Selección de Modelos**\n",
    "Comparar el progreso de la función de pérdida entre diferentes arquitecturas de modelos o configuraciones de hiperparámetros puede ayudar a seleccionar el mejor modelo para un problema dado. La elección se puede basar en cuál modelo muestra una mejor convergencia y un menor grado de sobreajuste.\n",
    "\n",
    "\n",
    "5. **Estrategias de Parada Temprana (Early Stopping)**\n",
    "El monitoreo de la función de pérdida permite implementar estrategias de parada temprana, donde el entrenamiento se detiene cuando la pérdida de validación comienza a aumentar, evitando así el sobreajuste y reduciendo el tiempo de entrenamiento.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"imgs/early-stopping.png\" width=\"500px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El momento de Nesterov, también conocido como Nesterov Accelerated Gradient (NAG), es una variante refinada del método de optimización conocido como Momentum, diseñado específicamente para acelerar la convergencia de los algoritmos de gradiente en problemas de optimización, incluyendo el entrenamiento de redes neuronales. Mientras que el método de Momentum busca acelerar el gradiente descendente agregando una fracción del vector de actualización previo al vector de actualización actual, el momento de Nesterov ajusta este enfoque para ganar una mayor precisión en la dirección de la actualización.\n",
    "\n",
    "## **Cálculo del gradiente**\n",
    "\n",
    "#### **Funcionamiento Básico**\n",
    "\n",
    "El gradiente descendente básico actualiza los parámetros $\\omega$ de un modelo basándose en el gradiente de la función de pérdida $L$ con respecto a esos parámetros, ajustándolos en la dirección que minimiza la pérdida. La fórmula básica de actualización es:\n",
    "\n",
    "$$\n",
    "\\omega = \\omega - \\lambda \\nabla_\\omega L(\\omega)\n",
    "$$\n",
    "\n",
    "donde $\\lambda$ es la tasa de aprendizaje.\n",
    "\n",
    "#### **Momentum**\n",
    "\n",
    "El Momentum mejora este proceso añadiendo un componente de \"inercia\" a las actualizaciones, que ayuda a acelerar el gradiente descendente en la dirección correcta y amortiguar las oscilaciones. Se introduce una variable $v$ (inicializada a $0$) que representa la velocidad de los parámetros, que acumula el gradiente $\\nabla_\\omega L(\\omega)$ en cada paso:\n",
    "\n",
    "$$\n",
    "v = \\gamma v - \\lambda \\nabla_\\omega L(\\omega)\n",
    "$$\n",
    "$$\n",
    "\\omega = \\omega + v\n",
    "$$\n",
    "\n",
    "Aquí, $\\gamma$ es el factor de momentum, actúa como una especie de \"fricción\" al movimiento, y típicamente se establece a un valor cercano a 1 (e.g., 0.9).\n",
    "\n",
    "#### **Momento de Nesterov**\n",
    "\n",
    "El momento de Nesterov (Nesterov Accelerated Gradient - NAG) ajusta este proceso anticipándose a la posición futura de los parámetros y calculando el gradiente en esa posición anticipada en lugar de en la posición actual. Esto permite hacer correcciones más informadas y eficientes. La actualización de parámetros en NAG se realiza en dos pasos:\n",
    "\n",
    "1. Se calcula una \"mirada hacia adelante\" de los parámetros usando el valor actual de $v$:\n",
    "\n",
    "$$\n",
    "\\omega_{\\text{temp}} = \\omega + \\gamma v\n",
    "$$\n",
    "\n",
    "2. Luego, se utiliza $\\omega_{\\text{temp}}$ para calcular el gradiente y actualizar $v$ y $\\omega$:\n",
    "\n",
    "$$\n",
    "v = \\gamma v - \\lambda \\nabla_\\omega L(\\omega_{\\text{temp}})\n",
    "$$\n",
    "$$\n",
    "\\omega = \\omega + v\n",
    "$$\n",
    "\n",
    "El efecto de \"mirar hacia adelante\" permite a Nesterov corregir su curso más rápidamente que el Momentum tradicional, lo que puede llevar a una convergencia más rápida y estable hacia mínimos de la función de pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Actualización de la tasa de aprendizaje**\n",
    "\n",
    "\n",
    "#### **Paso de decaimiento**\n",
    "\n",
    "Reducir la tasa de aprendizaje por algún factor cada pocas épocas. Los valores típicos pueden reducir la velocidad de aprendizaje a la mitad cada 5 épocas, o 0.1 cada 20 épocas. Estos números dependen en gran medida del tipo de problema y del modelo. Una heurística que se puede ver en la práctica es observar el error de validación mientras se entrena con una velocidad de aprendizaje fija, y reducir la velocidad de aprendizaje en una constante (por ejemplo, 0.5) cada vez que el error de validación deje de mejorar.\n",
    "\n",
    "#### **Decaimiento exponencial**\n",
    "\n",
    "Se trata de ir rebajando la tasa de aprendizaje de forma exponencial. $\\lambda_{0}$ y $k$ son hiperparámetros.\n",
    "\n",
    "$\\lambda = \\lambda_0  e^{-kt} $\n",
    "\n",
    "#### **Decaimiento 1/t**\n",
    "\n",
    "$\\lambda_{0}$ y $k$ son hiperparámetros.\n",
    "\n",
    "$\\lambda = \\frac{\\lambda_0}{1 + kt} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Actualización de la tasa de aprendizaje por parámetros**\n",
    "\n",
    "Estas técnicas ajustan adaptativamente la tasa de aprendizaje para cada parámetro individual del modelo, en lugar de aplicar una tasa de aprendizaje única y fija para todos los parámetros a través de todas las iteraciones del proceso de entrenamiento. El objetivo es mejorar la eficiencia y la eficacia del entrenamiento, permitiendo que el modelo converja más rápidamente a un mínimo de la función de pérdida y potencialmente alcanzar un mejor rendimiento en los datos no vistos.\n",
    "\n",
    "#### **Adagrad (Adaptive Gradient Algorithm)**\n",
    "\n",
    "Adagrad es un algoritmo que adapta las tasas de aprendizaje de todos los parámetros ajustando estos de manera que tengan tasas de aprendizaje individuales. La idea clave detrás de Adagrad es acumular los cuadrados de los gradientes pasados en un término de acumulación y luego normalizar la actualización de cada parámetro. Esto permite que parámetros con gradientes frecuentes tengan tasas de aprendizaje menores, mientras que parámetros con gradientes infrecuentes tengan tasas de aprendizaje mayores. Adagrad mejora la eficiencia en problemas con datos esparcidos y es particularmente útil en escenarios donde la distribución de los datos varía mucho.\n",
    "\n",
    "Dado un parámetro $\\omega_i$ del modelo, el gradiente de la función de pérdida $L$ con respecto a $\\omega_i$ en el tiempo $t$ es $\\nabla_\\omega L(\\omega_i)_t$. En Adagrad, la actualización del parámetro $\\omega_i$ en el tiempo $t+1$ se define como:\n",
    "\n",
    "$$\n",
    "\\omega_{i, t+1} = \\omega_{i, t} - \\frac{\\lambda}{\\sqrt{G_{i, t} + \\epsilon}} \\cdot \\nabla_\\omega L(\\omega_i)_t\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\lambda$ es la tasa de aprendizaje inicial (un hiperparámetro).\n",
    "- $G_{i, t}$ es la suma de los cuadrados de los gradientes para el parámetro $\\omega_i$ hasta el tiempo $t$, es decir, $G_{i, t} = \\sum_{\\tau=1}^{t} (\\nabla_\\omega L(\\omega_i)_\\tau)^2$.\n",
    "- $\\epsilon$ es un término de suavizado pequeño para evitar la división por cero, típicamente en el orden de $1e-8$.\n",
    "\n",
    "\n",
    "#### **RMSProp (Root Mean Square Propagation)**\n",
    "\n",
    "\n",
    "RMSProp modifica Adagrad para mejorar su rendimiento en contextos donde el gradiente decreciente es muy agudo. RMSProp ajusta la tasa de aprendizaje de manera adaptativa para cada parámetro dividiendo la tasa de aprendizaje por una media móvil del cuadrado de los gradientes. A diferencia de Adagrad, RMSProp no acumula todos los cuadrados de gradientes pasados, lo que resuelve el problema de la rápida disminución de la tasa de aprendizaje en Adagrad, haciendo a RMSProp adecuado para entrenar en problemas más difíciles y no estacionarios, como en muchas tareas de redes neuronales recurrentes.\n",
    "\n",
    "El algoritmo RMSProp (Root Mean Square Propagation) es una técnica de optimización que ajusta la tasa de aprendizaje de manera adaptativa para cada parámetro, tratando de resolver el problema de la disminución rápida de la tasa de aprendizaje que se presenta en Adagrad. RMSProp modifica la acumulación del gradiente cuadrático mediante el uso de una media móvil exponencial, lo que evita el crecimiento sin restricciones del denominador en Adagrad y permite un ajuste más efectivo y sostenido de las tasas de aprendizaje a lo largo del tiempo.\n",
    "\n",
    "Para un parámetro $\\omega$ del modelo, el algoritmo RMSProp actualiza este parámetro en el tiempo $t+1$ usando la siguiente fórmula:\n",
    "\n",
    "1. **Acumulación del Gradiente Cuadrático:**\n",
    "\n",
    "$$\n",
    "v_{t+1} = \\beta v_t + (1 - \\beta)(\\nabla_\\omega L(\\omega)_t)^2\n",
    "$$\n",
    "\n",
    "2. **Actualización del Parámetro:**\n",
    "\n",
    "$$\n",
    "\\omega_{t+1} = \\omega_t - \\frac{\\lambda}{\\sqrt{v_{t+1} + \\epsilon}} \\nabla_\\omega L(\\omega)_t\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\lambda$ es la tasa de aprendizaje inicial.\n",
    "- $v_{t}$ es la media móvil exponencial del cuadrado de los gradientes para el parámetro $\\omega$ hasta el tiempo $t$.\n",
    "- $\\beta$ es un hiperparámetro que controla la descomposición de la media móvil exponencial, típicamente con un valor cercano a 0.9.\n",
    "- $\\nabla_\\omega L(\\omega)_t$ es el gradiente de la función de pérdida $L$ con respecto al parámetro $\\omega$ en el tiempo $t$.\n",
    "- $\\epsilon$ es un término de suavizado pequeño para evitar la división por cero, generalmente en el orden de $1e-8$.\n",
    "\n",
    "\n",
    "\n",
    "#### **Adam (Adaptive Moment Estimation)**\n",
    "\n",
    "El algoritmo Adam (Adaptive Moment Estimation) combina las ideas de la adaptación del gradiente cuadrático, similar a RMSProp, con el momentum, para ajustar la tasa de aprendizaje de cada parámetro de manera adaptativa. Adam mantiene estimaciones del primer y segundo momento (es decir, el promedio del gradiente y el promedio del cuadrado del gradiente, respectivamente) para cada parámetro, ajustándose a la magnitud y dirección de los gradientes.\n",
    "\n",
    "Para un parámetro $\\omega$ en el tiempo $t$, las actualizaciones de Adam se realizan de la siguiente manera:\n",
    "\n",
    "1. **Cálculo de los Momentos:**\n",
    "\n",
    "   - Primer momento (momentum) del gradiente:\n",
    "     $$\n",
    "     m_{t+1} = \\beta_1 m_t + (1 - \\beta_1) \\nabla_\\omega L(\\omega)_t\n",
    "     $$\n",
    "\n",
    "   - Segundo momento (escala del gradiente) del gradiente:\n",
    "     $$\n",
    "     v_{t+1} = \\beta_2 v_t + (1 - \\beta_2) (\\nabla_\\omega L(\\omega)_t)^2\n",
    "     $$\n",
    "\n",
    "   Donde $m_t$ y $v_t$ son estimaciones del primer y segundo momento del gradiente, respectivamente; $\\beta_1$ y $\\beta_2$ son factores de decaimiento exponencial para los momentos estimados.\n",
    "\n",
    "2. **Corrección de los Momentos:**\n",
    "\n",
    "   Debido a la inicialización de los momentos a cero, se realiza una corrección de sesgo para ambos momentos:\n",
    "   - Primer momento corregido:\n",
    "     $$\n",
    "     \\hat{m}_{t+1} = \\frac{m_{t+1}}{1 - \\beta_1^{t+1}}\n",
    "     $$\n",
    "\n",
    "   - Segundo momento corregido:\n",
    "     $$\n",
    "     \\hat{v}_{t+1} = \\frac{v_{t+1}}{1 - \\beta_2^{t+1}}\n",
    "     $$\n",
    "\n",
    "3. **Actualización del Parámetro:**\n",
    "\n",
    "   Finalmente, el parámetro $\\omega$ se actualiza como:\n",
    "   $$\n",
    "   \\omega_{t+1} = \\omega_t - \\frac{\\lambda}{\\sqrt{\\hat{v}_{t+1}} + \\epsilon} \\hat{m}_{t+1}\n",
    "   $$\n",
    "\n",
    "   Donde:\n",
    "   - $\\lambda$ es la tasa de aprendizaje inicial.\n",
    "   - $\\epsilon$ es un término de suavizado pequeño para evitar la división por cero, típicamente en el orden de $1e-8$.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/opt1.gif\" width=\"40%\">\n",
    "  <img src=\"imgs/opt2.gif\" width=\"40%\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
