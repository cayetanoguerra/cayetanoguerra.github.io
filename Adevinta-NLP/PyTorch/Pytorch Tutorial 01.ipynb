{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/Adevinta-ULPGC-logo.jpg\" width=\"530px\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tutorial de Pytorch 1: Tensores**\n",
    "\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n",
    "\n",
    "## ¿Qué es PyTorch?\n",
    "\n",
    "Es un paquete informático científico basado en Python para ofrecer:\n",
    "\n",
    "- Un reemplazo de NumPy para usar la potencia de las GPU.\n",
    "- Una plataforma de investigación de aprendizaje profundo (*Deep Learning*) que proporciona la máxima flexibilidad y velocidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tensores**\n",
    "\n",
    "En PyTorch, un **tensor** es una estructura de datos central que se utiliza para almacenar y operar sobre datos numéricos. Los tensores son una generalización de matrices y vectores a más dimensiones y son similares en concepto a los arrays en NumPy, pero con capacidades adicionales que los hacen adecuados para el aprendizaje profundo. Aquí están algunas características clave de los tensores en PyTorch:\n",
    "\n",
    "1. **Multidimensionalidad**: Un tensor en PyTorch puede tener varias dimensiones. Por ejemplo, un tensor 0D es un escalar, un tensor 1D es un vector, un tensor 2D es una matriz, y un tensor con tres o más dimensiones puede representar datos más complejos como imágenes (3D: alto, ancho, canal) o secuencias de datos temporales.\n",
    "\n",
    "2. **Tipo de Datos Homogéneos**: Todos los elementos en un tensor PyTorch son del mismo tipo de dato (por ejemplo, `float32`, `int64`, etc.). PyTorch soporta varios tipos de datos que permiten controlar el tamaño y el comportamiento en cuanto a la precisión y el rango.\n",
    "\n",
    "3. **Compatibilidad con GPU**: A diferencia de los arrays de NumPy que generalmente residen en la memoria de la CPU, los tensores de PyTorch pueden ser trasladados a la memoria de una GPU para permitir cálculos de alto rendimiento, lo cual es fundamental en el entrenamiento de modelos de aprendizaje profundo.\n",
    "\n",
    "4. **Diferenciación Automática**: Los tensores en PyTorch pueden llevar un registro de las operaciones realizadas sobre ellos para permitir la diferenciación automática. Esta característica es clave para la implementación de algoritmos de aprendizaje automático, especialmente en la retropropagación en redes neuronales.\n",
    "\n",
    "5. **Interoperabilidad con NumPy**: PyTorch ofrece una buena interoperabilidad con los arrays de NumPy, permitiendo convertir fácilmente entre arrays de NumPy y tensores de PyTorch.\n",
    "\n",
    "6. **Funcionalidades para Aprendizaje Profundo**: PyTorch proporciona una amplia gama de operaciones y métodos predefinidos para manipular tensores, incluyendo operaciones matemáticas, de álgebra lineal, transformaciones, y más, lo que lo hace muy adecuado para tareas de aprendizaje automático y aprendizaje profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo podemos crear y manipular tensores en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, dtype=torch.int)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos declarado una matriz vacía (no inicializada), por tanto, no contiene valores conocidos antes de su uso. Cuando se crea una matriz no inicializada, los valores que estaban en la memoria asignada en ese momento aparecerán como valores iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2860, 0.8601, 0.0864],\n",
      "        [0.3273, 0.2752, 0.7389],\n",
      "        [0.7438, 0.9292, 0.6280],\n",
      "        [0.7182, 0.7319, 0.8711],\n",
      "        [0.8218, 0.8293, 0.7393]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de <code>torch.empty</code>, <code>torch.rand</code> genera unos valores aleatorios entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear un tensor basado en un tensor existente. Estos métodos reutilizarán propiedades del tensor de entrada, p. ej. dtype o device, a menos que el usuario proporcione nuevos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[0.0457, 0.3236, 0.1809],\n",
      "        [0.5337, 0.2979, 0.9751]])\n"
     ]
    }
   ],
   "source": [
    "y1 = torch.ones_like(x)\n",
    "y2 = torch.zeros_like(x, dtype=torch.int)\n",
    "y3 = torch.rand_like(x)\n",
    "print(x)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Operaciones**\n",
    "\n",
    "Hay varias sintaxis para las operaciones. En el siguiente ejemplo, veremos la operación de suma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3) * 2\n",
    "y = torch.ones(2, 3) * 3\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(2, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Operaciones in_place**\n",
    "\n",
    "Operaciones *in_place*. Cuando encontramos el sufijo \"_\" en cualquier método correspondiente a una operación de un objeto, significa que el resultado de la operación es almacenado en el propio objeto, reemplazando al valor anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡OJO! <code>y = y + x</code> no es una operación *in_place*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4728620192\n",
      "6051841424\n",
      "6051841344\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3) * 2\n",
    "y = torch.ones(2, 3) * 3\n",
    "\n",
    "print(id(x))\n",
    "print(id(y))\n",
    "\n",
    "y = y + x\n",
    "\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6051980416\n",
      "6051976576\n",
      "6051976576\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3) * 2\n",
    "y = torch.ones(2, 3) * 3\n",
    "\n",
    "print(id(x))\n",
    "print(id(y))\n",
    "\n",
    "y.add_(x)\n",
    "\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, <code>y += x</code> sí es una operación *in_place* igual a <code>y.add_(x)</code>. Por tanto, <code>+=</code> es el operador sobrecargado de <code>add_()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6051652416\n",
      "5631564576\n",
      "5631564576\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3) * 2\n",
    "y = torch.ones(2, 3) * 3\n",
    "\n",
    "print(id(x))\n",
    "print(id(y))\n",
    "\n",
    "y += x\n",
    "\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python no es así."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4372529392\n",
      "4372529424\n",
      "4372529456\n"
     ]
    }
   ],
   "source": [
    "x=1\n",
    "y=2\n",
    "\n",
    "print(id(x))\n",
    "print(id(y))\n",
    "\n",
    "y += x\n",
    "\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clonación de tensores**\n",
    "\n",
    "Al clonar un tensor se generará un nuevo tensor con los mismos datos que el tensor original, pero en una ubicación de memoria diferente. Esto significa que modificar el tensor clonado no afectará al tensor original, y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "6051978896\n",
      "6048149520\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3) * 2\n",
    "y = x.clone()\n",
    "\n",
    "print(x is y)\n",
    "\n",
    "print(id(x))\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que el siguiente código no funcionaría como se cabría esperar. El cambio de <code>y</code> también cambiará <code>x</code>. Ambos tensores comparten el mismo espacio de memoria. Por tanto, <code>y</code> es un alias de <code>x</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "6051975456\n",
      "6051975456\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3) * 2\n",
    "y = x\n",
    "\n",
    "print(x is y)\n",
    "\n",
    "print(id(x))\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Slicing**\n",
    "\n",
    "El \"slicing\" (segmentación) permite extraer, seleccionar o manipular ciertas partes de los tensores de forma eficiente y conveniente mediante una sintaxis determinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Original:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"Tensor Original:\\n\", tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera Fila: tensor([1, 2, 3])\n",
      "Segunda Columna: tensor([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar la primera fila\n",
    "primera_fila = tensor[0]\n",
    "print(\"Primera Fila:\", primera_fila)\n",
    "\n",
    "# Seleccionar la segunda columna\n",
    "segunda_columna = tensor[:, 1]\n",
    "print(\"Segunda Columna:\", segunda_columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras dos filas:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Últimas dos columnas:\n",
      " tensor([[2, 3],\n",
      "        [5, 6],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las primeras dos filas\n",
    "primeras_dos_filas = tensor[:2]\n",
    "print(\"Primeras dos filas:\\n\", primeras_dos_filas)\n",
    "\n",
    "# Seleccionar las últimas dos columnas\n",
    "ultimas_dos_columnas = tensor[:, -2:]\n",
    "print(\"Últimas dos columnas:\\n\", ultimas_dos_columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos hacer una selección basada en una condición booleana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos mayores que 5: tensor([6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar elementos mayores que 5\n",
    "mayores_que_cinco = tensor[tensor > 5]\n",
    "print(\"Elementos mayores que 5:\", mayores_que_cinco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor modificado:\n",
      " tensor([[1, 0, 3],\n",
      "        [0, 5, 0],\n",
      "        [7, 0, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar elementos pares y cambiar su valor a 0\n",
    "tensor[tensor % 2 == 0] = 0\n",
    "print(\"Tensor modificado:\\n\", tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es útil contar con funciones que nos permitan seleccionar la triangular superior o inferior de una matriz cuadrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor triangular superior:\n",
      " tensor([[1, 2, 3],\n",
      "        [0, 5, 6],\n",
      "        [0, 0, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor triangular superior:\\n\", torch.triu(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Reshaping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View\n",
    "\n",
    "El tensor vista comparte los mismos datos subyacentes que su tensor base. Soportar vistas evita la copia explícita de datos, lo que nos permite realizar cambios de forma, segmentación y operaciones elemento a elemento de manera rápida y eficiente en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[555,   2,   3,   4],\n",
      "        [  5,   6,   7,   8],\n",
      "        [  9,  10,  11,  12]])\n",
      "tensor([[555,   2],\n",
      "        [  3,   4],\n",
      "        [  5,   6],\n",
      "        [  7,   8],\n",
      "        [  9,  10],\n",
      "        [ 11,  12]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9,10,11,12]]).contiguous()\n",
    "y = x.view(6, 2)\n",
    "\n",
    "x[0,0] = 555\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "print(x is y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x is y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape\n",
    "\n",
    "Devuelve un tensor con los mismos datos y la misma cantidad de elementos que la entrada, pero con la forma especificada. Cuando sea posible, el tensor devuelto será una vista de la entrada. De lo contrario, será una copia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[555,   2,   3,   4],\n",
      "        [  5,   6,   7,   8],\n",
      "        [  9,  10,  11,  12]])\n",
      "tensor([[555,   2],\n",
      "        [  3,   4],\n",
      "        [  5,   6],\n",
      "        [  7,   8],\n",
      "        [  9,  10],\n",
      "        [ 11,  12]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9,10,11,12]])\n",
    "y = x.reshape(6, 2)\n",
    "\n",
    "x[0,0] = 555\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "print(x is y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Convirtiendo arrays de Numpy a tensores de PyTorch y viceversa**\n",
    "\n",
    "El tensor de PyTorch y la matriz de NumPy comparten las mismas ubicaciones de memoria subyacentes cuando el tensor está en CPU (recordemos que PyTorch puede ejecutarse tanto en CPU o GPU). Así que, si modificamos los valores del array modificaremos los valores del tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "Tensor pytorch:  tensor([2., 2., 2., 2., 2.])\n",
      "Array numpy:  [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()  # Creamos un array de numpy desde un tensor de pytorch\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(\"Tensor pytorch: \", a)\n",
    "print(\"Array numpy: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) # Creamos un tensor de pytorch desde un array de numpy\n",
    "\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el método <code>.item()</code> para obtener el valor de un tensor de un solo elemento o escalar como un número de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([555])\n",
      "555\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([555])\n",
    "print(a)\n",
    "\n",
    "b = a.item()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensores CUDA\n",
    "\n",
    "Podemos mover tensores a cualquier dispositivo (GPU) mediante el método <code>.to</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2168], device='cuda:0')\n",
      "tensor([0.2168], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
