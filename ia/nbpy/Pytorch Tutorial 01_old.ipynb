{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial de Pytorch 1: Tensores\n",
    "\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n",
    "\n",
    "## ¿Qué es PyTorch?\n",
    "\n",
    "Es un paquete informático científico basado en Python para ofrecer:\n",
    "\n",
    "- Un reemplazo de NumPy para usar la potencia de las GPU.\n",
    "- Una plataforma de investigación de aprendizaje profundo (*Deep Learning*) que proporciona la máxima flexibilidad y velocidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensores\n",
    "\n",
    "Los **tensores** son similares a los *ndarrays* de NumPy, con el añadido de que los tensores también se pueden usar en una GPU para acelerar la computación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9184e-39, 1.0561e-38, 1.0286e-38],\n",
      "        [1.0653e-38, 1.0194e-38, 4.6838e-39],\n",
      "        [8.4489e-39, 9.6429e-39, 8.4490e-39],\n",
      "        [9.6429e-39, 9.2755e-39, 1.0286e-38],\n",
      "        [9.0919e-39, 8.9082e-39, 9.2755e-39]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos declarado una matriz vacía (no inicializada), por tanto, no contiene valores conocidos antes de su uso. Cuando se crea una matriz no inicializada, los valores que estaban en la memoria asignada en ese momento aparecerán como valores iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0063, 0.3046, 0.7965],\n",
      "        [0.3336, 0.2921, 0.4931],\n",
      "        [0.0380, 0.6064, 0.1145],\n",
      "        [0.1354, 0.5938, 0.5662],\n",
      "        [0.7659, 0.0191, 0.0275]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de <code>torch.empty</code>, <code>torch.rand</code> genera unos valores aleatorios entre 0 y 1.\n",
    "\n",
    "Podemos crear un tensor con todos los valores a cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos crear un tensor a partir de una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O crear un tensor basado en un tensor existente. Estos métodos reutilizarán propiedades del tensor de entrada, p. ej. dtype, a menos que el usuario proporcione nuevos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.7828, -0.6446,  0.0941],\n",
      "        [-0.3043, -1.5295,  1.6169],\n",
      "        [-0.4094,  1.6890,  1.0135],\n",
      "        [-1.1487, -1.0286, -0.3093],\n",
      "        [ 0.7408,  1.4012,  0.7433]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones\n",
    "\n",
    "Hay varias sintaxis para las operaciones. En el siguiente ejemplo, veremos la operación de suma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1437, -0.4753,  1.0807],\n",
      "        [ 0.2530, -0.8880,  2.6150],\n",
      "        [-0.3058,  1.7675,  1.3653],\n",
      "        [-1.1100, -0.1143,  0.1803],\n",
      "        [ 1.0973,  1.4709,  1.3769]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1437, -0.4753,  1.0807],\n",
      "        [ 0.2530, -0.8880,  2.6150],\n",
      "        [-0.3058,  1.7675,  1.3653],\n",
      "        [-1.1100, -0.1143,  0.1803],\n",
      "        [ 1.0973,  1.4709,  1.3769]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9265, -1.1198,  1.1749],\n",
      "        [-0.0512, -2.4175,  4.2319],\n",
      "        [-0.7152,  3.4565,  2.3788],\n",
      "        [-2.2587, -1.1428, -0.1291],\n",
      "        [ 1.8381,  2.8721,  2.1202]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *in_place*\n",
    "\n",
    "Suma *in_place*. Cuando encontramos el sufijo \"_\" en cualquier método correspondiente a una operación de un objeto, significa que el resultado de la operación es almacenado en el propio objeto, reemplazando al valor anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1437, -0.4753,  1.0807],\n",
      "        [ 0.2530, -0.8880,  2.6150],\n",
      "        [-0.3058,  1.7675,  1.3653],\n",
      "        [-1.1100, -0.1143,  0.1803],\n",
      "        [ 1.0973,  1.4709,  1.3769]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar la indexación de tensores de la misma forma que la usamos en arrays de tipo NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6446, -1.5295,  1.6890, -1.0286,  1.4012])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "\n",
    "Si necesitamos cambiar la \"forma\" de un tensor, podemos usar <code>torch.view</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size:  torch.Size([4, 4])\n",
      "y size:  torch.Size([16])\n",
      "z size:  torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(\"x size: \", x.size())\n",
    "print(\"y size: \", y.size())\n",
    "print(\"z size: \", z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos un tensor de un solo elemento, usamos <code>.item()</code> para obtener el valor como un número de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7832])\n",
      "-0.7831534743309021\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convirtiendo arrays de Numpy a tensores de PyTorch y viceversa\n",
    "\n",
    "El tensor de PyTorch y la matriz de NumPy comparten las mismas ubicaciones de memoria subyacentes cuando el tensor está en CPU (recordemos que PyTorch puede ejecutarse tanto en CPU o GPU). Así que, si modificamos los valores del array modificaremos los valores del tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "Tensor pytorch:  tensor([2., 2., 2., 2., 2.])\n",
      "Array numpy:  [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()  # Creamos un array de numpy desde un tensor de pytorch\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(\"Tensor pytorch: \", a)\n",
    "print(\"Array numpy: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) # Creamos un tensor de pytorch desde un array de numpy\n",
    "\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensores CUDA\n",
    "\n",
    "Podemos mover tensores a cualquier dispositivo (GPU) mediante el método <code>.to</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2168], device='cuda:0')\n",
      "tensor([0.2168], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
