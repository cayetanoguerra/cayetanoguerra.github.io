{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes Classification\n",
    "\n",
    "## Word vectors from text\n",
    "\n",
    "Transformamos cada oración en un vector de logitud fija. Esta longitud corresponderá al número de palabras de nuestro vocabulario. En nuestro ejemplo clasificaremos frases como ofensivas o no ofensivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    postingList=[['my', 'dog', 'has', 'flea', \\\n",
    "        'problems', 'help', 'please'],\n",
    "        ['maybe', 'not', 'take', 'him', \\\n",
    "        'to', 'dog', 'park', 'stupid'],\n",
    "        ['my', 'dalmation', 'is', 'so', 'cute', \\\n",
    "        'I', 'love', 'him'],\n",
    "        ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "        ['mr', 'licks', 'ate', 'my', 'steak', 'how',\\\n",
    "        'to', 'stop', 'him'],\n",
    "        ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "\n",
    "    classVec = [0,1,0,1,0,1] #1 is abusive, 0 not\n",
    "    return postingList,classVec\n",
    "\n",
    "\n",
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet)\n",
    "\n",
    "\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0]*len(vocabList)  # We create a list of 0's of lenght 'vocabList'\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else: print \"the word: %s is not in my Vocabulary!\" % word\n",
    "    return returnVec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos un ejemplo de frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'] 0\n",
      "['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'] 1\n",
      "['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'] 0\n",
      "['stop', 'posting', 'stupid', 'worthless', 'garbage'] 1\n",
      "['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'] 0\n",
      "['quit', 'buying', 'worthless', 'dog', 'food', 'stupid'] 1\n",
      "\n",
      "Sentence codification:\n",
      "['my', 'dog', 'has', 'flea', 'problems', 'help', 'please']\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "p, c = loadDataSet()\n",
    "for i, e in zip(p, c):\n",
    "    print i, e\n",
    "\n",
    "listOPosts, listClasses = loadDataSet()\n",
    "myVocabList = createVocabList(listOPosts)\n",
    "\n",
    "print \"\\nSentence codification:\"\n",
    "print listOPosts[0]\n",
    "print setOfWords2Vec(myVocabList, listOPosts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trainNB0(trainMatrix, trainCategory):\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    numWords = len(trainMatrix[0])\n",
    "    pAbusive = sum(trainCategory)/float(numTrainDocs)\n",
    "    \n",
    "    p0Num = p0Num = np.ones(numWords) # p0Num = 0\n",
    "    p1Num = p1Num = np.ones(numWords)  # p1Num = 0\n",
    "    p0Denom = len(p0Num) # p0Denom = 0\n",
    "    p1Denom = len(p0Num) # p1Denom = 0\n",
    "\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i] # Number of instances of each word\n",
    "            p1Denom += sum(trainMatrix[i]) # Number of words in class 1\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += sum(trainMatrix[i]) # Number of words in class 0\n",
    "\n",
    "    p1Vect = np.log(p1Num/p1Denom)  # p1Vect = p1Num/p1Denom\n",
    "    p0Vect = np.log(p0Num/p0Denom)  # p0Vect = p0Num/p0Denom\n",
    "    return p0Vect, p1Vect, pAbusive\n",
    "\n",
    "\n",
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    p1 = sum(vec2Classify * p1Vec) + np.log(pClass1)\n",
    "    p0 = sum(vec2Classify * p0Vec) + np.log(1.0 - pClass1)\n",
    "    \n",
    "    #p1 = np.prod(vec2Classify * p1Vec) * pClass1\n",
    "    #p0 = np.prod(vec2Classify * p0Vec) * (1.0 - pClass1)\n",
    "    \n",
    "    print p1, p0\n",
    "    \n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.4308527194 -13.5178939679\n",
      "1\n",
      "-9.82671449373 -7.69484807238\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "trainMat=[]\n",
    "for postinDoc in listOPosts:\n",
    "    trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n",
    "    \n",
    "p0V, p1V, pAb = trainNB0(trainMat,listClasses)\n",
    "\n",
    "s = ['my','stupid', 'dog', 'has',  'help', 'stupid']\n",
    "sw = setOfWords2Vec(myVocabList, s)\n",
    "print classifyNB(sw,p0V,p1V,pAb)\n",
    "\n",
    "s = ['love', 'my', 'dalmation']\n",
    "sw = setOfWords2Vec(myVocabList, s)\n",
    "print classifyNB(sw,p0V,p1V,pAb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
