{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning (Cross Entropy Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica construiremos un sistema basado en aprendizaje por refuerzo para controlar el equilibrio de un péndulo invertido sobre una plataforma móvil, como muestra la animación inferior. Usaremos el framework de experimentación en RL <a href=\"https://gym.openai.com/\">OpenAI Gym</a>, concretamente el entorno <a href=\"https://gym.openai.com/envs/CartPole-v0\">Cart-pole-V0</a>. Y todo ello lo haremos con una simple neurona.\n",
    "\n",
    "OpenAI Gym nos proporciona todo lo necesario para empezar: observación del estado del entorno, las acciones posibles a realizar y una representación gráfica de cómo va yendo el conjunto péndulo-plataforma.\n",
    "\n",
    "<img src=\"imgs/cartpole.gif\" width=\"50%\">\n",
    "\n",
    "Las observaciones que tenemos son: la posición de la plataforma, la velocidad de la plataforma, el ángulo del péndulo y la velocidad de rotación. Y las acciones son mover la plataforma a la derecha o a la izquierda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-11 18:04:47,362] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos ejecutando algunos ejemplos de interacción con el entorno elegiendo acciones al azar. Puedes descomentar la impresión de las observaciones para ver los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_random(env):\n",
    "    for _ in range(20):\n",
    "        observation = env.reset()\n",
    "        for t in range(100):\n",
    "            env.render()\n",
    "            #print(observation)\n",
    "            action = env.action_space.sample()\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            #if done:\n",
    "            #    print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            #    break\n",
    "run_random(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para controlar la plataforma utilizaremos una simple neurona que tendrá como entradas las observaciones y como salida la acción a aplicar: 0 para empujar en una dirección y 1 para la otra dirección. \n",
    "\n",
    "$$r = \\sum_{i=1}^{4}observation_{i} \\cdot w_i$$\n",
    "\n",
    "Si $r<0$ entonces la salida de la neurona será $0$ y si $r\\ge0$ la salida será $1$.\n",
    "\n",
    "<img src=\"imgs/neuron.svg\" width=\"60%\">\n",
    "\n",
    "Nuestro problema ahora es determinar el conjunto de pesos $W$ de la neurona que consigan mantener el péndulo en equilibrio. Y aquí es donde entra en juego el método de entropía cruzada (CEM). *A priori* no tenemos ningún criterio para establecer unos valores iniciales a los pesos, así que podemos asignarlos al azar. Lanzamos unos, por ejemplo, 100 episodios con  pesos aleatorios en cada episodio. Unos pesos funcionarán mejor que otros. Es decir, harán que el péndulo aguante más pasos en equilibiro antes de caerse. De esos 100 conjuntos de pesos escogemos los 10 mejores conjuntos. Con ellos generaremos una <a href=\"https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal\">distribución gaussiana de probabilidad</a>.\n",
    "\n",
    "$$ \\mu = E[X] = \\frac{\\sum_{i=1}^{10}{x_i}}{10} $$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ \\sigma = \\sqrt{E[X - \\mu]^2} = \\sqrt{\\frac{\\sum_{i=1}^{10}{(x_i - \\mu)^2}}{10}} $$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\cdot e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "A partir de esta función generaremos una nueva lista de conjuntos de pesos $(x_1, x_2, \\dots x_{100}) \\sim N(\\mu, \\sigma)$. La diferencia es que ahora este nuevo conjunto estará compuesto por mejores soluciones que la lista anterior. Si repetimos esta operación un número de veces llegaremos a buenas soluciones que logren el objetivo buscado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = [0., 0., 0., 0.]  # first means\n",
    "sigma = [1., 1., 1., 1.]  # first standard deviations\n",
    "episodies = 100\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función que ejecutará cada episodio (desde el momento inicial hasta que llegamos a los `max_reward` pasos o hasta que el péndulo se nos caiga.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episode(env, weights, render=False, max_reward=200):\n",
    "    observation = env.reset()\n",
    "    totalreward = 0\n",
    "    for _ in xrange(max_reward):\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = 0 if np.matmul(weights, observation) < 0 else 1  # this line is our agent (just one neuron!!)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        totalreward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return totalreward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos las iteraciones del método de entropía cruzada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Iteration: 0\n",
      "Mean: [-0.36985362 -0.14822899  0.72377799  0.98717426]\n",
      "Standard deviation: [ 0.82260298  0.66286072  0.58501013  0.39408498]\n",
      "# goals: 2\n",
      "------------\n",
      "Iteration: 1\n",
      "Mean: [-0.23977643 -0.10041071  1.28180171  1.03110944]\n",
      "Standard deviation: [ 0.51610659  0.53550408  0.44852136  0.42317155]\n",
      "# goals: 22\n",
      "------------\n",
      "Iteration: 2\n",
      "Mean: [-0.00332877  0.06113365  1.53675028  0.94866862]\n",
      "Standard deviation: [ 0.26565696  0.32307113  0.37484201  0.40319855]\n",
      "# goals: 31\n",
      "------------\n",
      "Iteration: 3\n",
      "Mean: [ 0.04251544  0.2022577   1.52623168  0.92945207]\n",
      "Standard deviation: [ 0.18123304  0.379544    0.19979383  0.213252  ]\n",
      "# goals: 62\n",
      "------------\n",
      "Iteration: 4\n",
      "Mean: [ 0.12392336  0.28386005  1.629934    0.9189151 ]\n",
      "Standard deviation: [ 0.14054255  0.4080691   0.19662461  0.22923035]\n",
      "# goals: 90\n",
      "------------\n",
      "Iteration: 5\n",
      "Mean: [ 0.04041372  0.23664824  1.47115431  0.9291692 ]\n",
      "Standard deviation: [ 0.11986737  0.39489579  0.12405115  0.22398743]\n",
      "# goals: 85\n",
      "------------\n",
      "Iteration: 6\n",
      "Mean: [ 0.02594185  0.26083691  1.4756004   0.9878746 ]\n",
      "Standard deviation: [ 0.11717854  0.41890499  0.10578672  0.17851627]\n",
      "# goals: 84\n",
      "------------\n",
      "Iteration: 7\n",
      "Mean: [ 0.03396054  0.25223639  1.50126133  0.99625333]\n",
      "Standard deviation: [ 0.13795761  0.40828132  0.09355774  0.15511304]\n",
      "# goals: 93\n",
      "------------\n",
      "Iteration: 8\n",
      "Mean: [ 0.02361878  0.32910758  1.51344029  1.02798995]\n",
      "Standard deviation: [ 0.0652423   0.36218886  0.06885026  0.16725886]\n",
      "# goals: 89\n",
      "------------\n",
      "Iteration: 9\n",
      "Mean: [ 0.04411325  0.25935775  1.54331726  1.00500786]\n",
      "Standard deviation: [ 0.04648671  0.26509399  0.09185551  0.09974668]\n",
      "# goals: 98\n"
     ]
    }
   ],
   "source": [
    "for iteration in xrange(iterations):\n",
    "\n",
    "    weights = []\n",
    "    for m, s in zip(mu, sigma):\n",
    "        weights.append(np.random.normal(m, s, episodies))\n",
    "    weights = np.transpose(weights)\n",
    "\n",
    "    rewards = []\n",
    "    number_of_goals = 0\n",
    "\n",
    "    for w in weights:\n",
    "        r = run_episode(env, w, max_reward=500)\n",
    "        rewards.append(r)\n",
    "        if r == 500:\n",
    "            number_of_goals += 1\n",
    "\n",
    "    # We combine in a list parameteres+rewards and sort it by rewards.\n",
    "    # To do that we use a lambda function\n",
    "    l = sorted(zip(weights, rewards), key=lambda pair: pair[1])\n",
    "    # We get the last ten (they will be those with the higher reward), but\n",
    "    # only first component (parameters) is needed. \n",
    "    l = list(zip(*l[-10:])[0])\n",
    "\n",
    "    mu = np.mean(l, 0)\n",
    "    sigma = np.std(l, 0)\n",
    "\n",
    "    print \"------------\"\n",
    "    print \"Iteration:\", iteration\n",
    "    print \"Mean:\", mu\n",
    "    print \"Standard deviation:\", sigma\n",
    "    print \"# goals:\", number_of_goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos un episodio con 1500 pasos a ver qué tal va."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_episode(env, mu, render=True, max_reward=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
