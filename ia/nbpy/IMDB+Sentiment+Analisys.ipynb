{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analisys\n",
    "\n",
    "En esta práctica realizaremos una clasificación de análisis de opinión (sentiment analisys)  de un dataset de 25.000 comentarios etiquetados de películas extraído de la base de datos cinematográfica IMDB. Para llevarlo a cabo utilizaremos un clasificador bayesiano, y mediremos su rendimiento mediante otro dataset de test con otros 25.000 comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createVocab(dataSet):\n",
    "    vocab = {}\n",
    "    index = 0\n",
    "    for document in dataSet:\n",
    "        for word in document:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = index\n",
    "                index += 1\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def setOfWords2Vec(vocab, inputSet):\n",
    "    words = {}\n",
    "    for word in inputSet:\n",
    "        if word in vocab:\n",
    "            if word not in words:\n",
    "                words[word] = 1\n",
    "            else:\n",
    "                words[word] += 1\n",
    "        else:\n",
    "            print(\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return words\n",
    "\n",
    "\n",
    "def load_data(path_to_dir):\n",
    "    \"\"\"\n",
    "    Loads the train and test set into four different lists.\n",
    "    \"\"\"\n",
    "    train_pos = []\n",
    "    train_neg = []\n",
    "    test_pos = []\n",
    "    test_neg = []\n",
    "\n",
    "    print(\"Reading positive train samples...\")\n",
    "    with open(path_to_dir + \"train-pos.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            words = [w.lower() for w in line.strip().split() if len(w) >= 3]\n",
    "            train_pos.append(words)\n",
    "\n",
    "    print(\"Reading negative train samples...\")\n",
    "    with open(path_to_dir + \"train-neg.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            words = [w.lower() for w in line.strip().split() if len(w) >= 3]\n",
    "            train_neg.append(words)\n",
    "\n",
    "    print(\"Reading positive test samples...\")\n",
    "    with open(path_to_dir + \"test-pos.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            words = [w.lower() for w in line.strip().split() if len(w) >= 3]\n",
    "            test_pos.append(words)\n",
    "\n",
    "    print(\"Reading negative test samples...\")\n",
    "    with open(path_to_dir + \"test-neg.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            words = [w.lower() for w in line.strip().split() if len(w) >= 3]\n",
    "            test_neg.append(words)\n",
    "\n",
    "    return train_pos, train_neg, test_pos, test_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas:\n",
    "1. Construye el clasificador.\n",
    "2. Estudia la influencia de la cantidad de comentarios de entrenamiento en el rendimiento de la clasiciación. Prueba el conjunto de test entero con el clasificador entrenado con 1.000, 2.000, ...y así hasta los 25.000 comentarios. Haz una gráfica de la evolución del rendimiento. \n",
    "3. OPCIONAL: Desarrolla tus propias técnicas de selección del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
