{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales 5\n",
    "\n",
    "En la primera clase práctica de la asignatura, cuando aún podíamos salir a la calle, reflexionamos sobre la complejidad que tiene el proceso de la visión. ¿Cuántas imágenes distintas podríamos formar en una matriz de bytes de $100 \\times 100$? La respuesta es: $2^{80000}$. ¿Son muchas? Muchísimas, a efectos prácticos, infinitas.\n",
    "\n",
    "Sin embargo, vimos una aplicación en el móvil que, sin esfuerzo aparente y de forma casi mágica, podía determinar qué tipo de objeto aparecía delante de la cámara. Nosotros mismos somos capaces de reconocer los objetos que aparecen delante de nuestros ojos sin que nos cueste un dolor de cabeza. \n",
    "\n",
    "¿Cómo es capaz nuestro cerebro de procesar tan rápidamente la enorme cantidad de estímulos luminosos que llegan a nuestra retina? No lo sabemos con exactitud. Sí sabemos que son integrados de forma secuencial en diferentes capas neuronales construyendo en cada paso representaciones más complejas de la información.\n",
    "\n",
    "Esa idea nos sirve de inspiración para construir redes neuronales que sean capaces de “ver”. A continuación, vamos a estudiar qué procesos y técnicas nos permiten pasar de la magia a la ingeniería.\n",
    "\n",
    "\t\n",
    "\n",
    "> Cualquier tecnología lo suficientemente avanzada es indistinguible de la magia. Arthur C. Clarke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolución\n",
    "\n",
    "Antes de meternos de lleno en las redes, necesitamos comprender bien el concepto de **convolución**. La convolución es un operador matemático que se define como la integral del producto de dos funciones donde una de ellas está desplazada una distancia $t$.\n",
    "\n",
    "$$ (f \\ast g)(t) = \\int_{-\\infty}^{\\infty} f(x)g(t-x) dx  $$\n",
    "\n",
    "Nosotros vamos a adaptar este operador a una versión bidimensional y discreta. Esta sería la versión bidimensional:\n",
    "\n",
    "$$ (f \\ast g)(i,j) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x,y)g(i-x,j-y) dx  $$\n",
    "\n",
    "Y esta la versión bidimensional y discreta con paso 1, que es la que nos interesa:\n",
    "\n",
    "$$ (f \\ast g)(i,j) = \\sum_{-\\infty}^{\\infty} \\sum_{-\\infty}^{\\infty} f(x,y)g(i-x,j-y)$$\n",
    "\n",
    "\n",
    "¿Y para qué nos va a servir? Antes habíamos dicho que nuestro cerebro integraba simples estímulos visuales procedentes de cada fotorreceptor de la retina para producir elementos de información cada vez más compleja y elaborada para permitir luego su reconocimiento. Es como decir que para reconocer una cara nuestro sistema visual registra primero fragmentos de la imagen como pupilas, comisuras de labios, lóbulos de orejas… para luego formar ojos, bocas, orejas… para, finalmente, formar caras. Bueno, pues con la operación de convolución vamos a hacer algo así.\n",
    "\n",
    "\n",
    "Partamos de una imagen cualquiera, tomémosla en escala de grises para que sea aún más sencilla. Por ahora solo tenemos pixeles. ¿Cuáles serían las características más sencillas que podríamos encontrar? Quizá serían las características que encontraríamos en regiones de tamaño $3 \\times 3$ de la imagen. ¿Qué cabe en una región tan pequeña? Podríamos encontrar un borde vertical, un borde horizontal, una esquina, un punto… cosas así. \n",
    "\n",
    "Echemos un vistazo de nuevo a la expresión de la convolución en su versión bidimensional  y discreta y hagámosle unas adaptaciones. En primer lugar, démosle sentido a $g$. Esta función va a ser nuestra imagen. La función $f$ va a ser otra imagen, pero en este caso, de tamaño $3 \\times 3$. Además le vamos a cambiar el nombre y, a partir de ahora, la llamaremos **kernel**. Le asignaremos estos valores: \n",
    "\n",
    "\\begin{bmatrix}\n",
    " 1 & 0 & -1\\\\ \n",
    " 1 & 0 & -1\\\\ \n",
    " 1& 0 & -1\n",
    "\\end{bmatrix}\n",
    "\n",
    "Puesto que el kernel es de tamaño $3 \\times 3$ los índices de los sumatorios serán:\n",
    "\n",
    "$$ conv2D(i,j) = \\sum_{y=0}^{2} \\sum_{x=0}^{2} kernel(x,y) \\cdot imagen(i-x,j-y)$$\n",
    "\n",
    "Y para hacerlo un poco más interpretable, simplemente vamos a cambiar la manera en que superponemos el kernel sobre la imagen cambiando restas por sumas:\n",
    "\n",
    "$$ conv2D(i,j) = \\sum_{y=0}^{2} \\sum_{x=0}^{2} kernel(x,y) \\cdot imagen(i+x,j+y)$$\n",
    "\n",
    "Vamos a visualizarlo con un ejemplo. Nuestra imagen es de $6 \\times 6$ y tiene los valores que representa la figura.\n",
    "\n",
    "\n",
    "<img src=\"imgs/Kernel.svg\" width=\"50%\">\n",
    "\n",
    "Queremos calcular el valor de la convolución en las coordenadas (2,1). Gráficamente se vería como la superposición del kernel sobre la imagen en esas coordendas y multiplicar celda a celda sus correspondientes valores para, finalmente, sumarlo todo. El resultado que nos devuelve es 765. Es decir, un valor alto. ¿Qué pasaría si el área de $3 \\times 3$ de la imagen sobre la que superponemos el kernel fuera totalmente homogénea? Efectivamente, el resultado sería 0. *Voilà*, ya tenemos un detector de bordes verticales.\n",
    "\n",
    "<img src=\"imgs/Kernel2.svg\" width=\"30%\">\n",
    "\n",
    "#### Ejercicios\n",
    "\n",
    "- Construye un kernel para detectar bordes horizontales.\n",
    "- En el ejemplo gráfico anterior, si la imagen es de tamaño $6 \\times 6$ y el kernel $3 \\times 3$ ¿Qué tamaño tiene la imagen resultante de haber pasado completamente el kernel por toda la imagen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de la convolución\n",
    "\n",
    "Vamos a llevar todo esto a código para despejar cualquier duda que aún podamos tener. Utilizaremos una imagen de prueba para implementar una versión sencilla de la convolución usando diversos kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la imagen: (32, 32)\n",
      "Máximo valor: 1.0\n",
      "Mínimo valor: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "image=io.imread(\"imgs/figuras.png\")/255.0 # imread lee las imagenes con los pixeles codificados como enteros \n",
    "# en el rango 0-255. Por eso la convertimos a flotante y en el rango 0-1\n",
    "\n",
    "print(\"Dimensiones de la imagen:\", image.shape)\n",
    "print(\"Máximo valor:\", image.max())\n",
    "print(\"Mínimo valor:\", image.min())\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(image)\n",
    "\n",
    "ax = plt.gca();\n",
    "ax.set_xticks(np.arange(-.5, 32, 1), minor=True);\n",
    "ax.set_yticks(np.arange(-.5, 32, 1), minor=True);\n",
    "ax.grid(which='minor', color='k', linestyle='-', linewidth=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la imagen: (32, 32)\n",
      "Máximo valor: 3.0\n",
      "Mínimo valor: -3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b9dc0c2988>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Valores del kernel\n",
    "values = np.array([[-1., 0., 1.],[-1., 0., 1.],[-1., 0., 1.]]) # Detector de bordes verticales\n",
    "#weights = np.array([[-1., -1., -1.],[0., 0., 0.],[1., 1., 1.]]) # Detector de bordes horizontales\n",
    "#weights = np.array([[-2., -1., 0.],[-1., 0., 1.],[0., 1., 2.]]) # Detector de bordes diagonales\n",
    "\n",
    "\n",
    "# Convolución\n",
    "def convolution(image, kernel):\n",
    "    result = np.zeros((image.shape[0],image.shape[1]), dtype=float)\n",
    "    \n",
    "    # Recorrido de la imagen\n",
    "    for j in range(0, image.shape[0]-2):\n",
    "        for i in range(0, image.shape[1]-2):\n",
    "            aux = 0\n",
    "            # Recorrido del kernel\n",
    "            for m in range(0, values.shape[0]):\n",
    "                for n in range(0, values.shape[1]):\n",
    "                    aux += image[j+m][i+n] * values[m][n] \n",
    "            result[j][i] = aux\n",
    "    return result\n",
    "\n",
    "image_result = convolution(image, values)\n",
    "\n",
    "print(\"Dimensiones de la imagen:\", image_result.shape)\n",
    "print(\"Máximo valor:\", image_result.max())\n",
    "print(\"Mínimo valor:\", image_result.min())\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(image_result, vmin=-1,vmax=1)\n",
    "\n",
    "ax = plt.gca();\n",
    "ax.set_xticks(np.arange(-.5, 32, 1), minor=True);\n",
    "ax.set_yticks(np.arange(-.5, 32, 1), minor=True);\n",
    "ax.grid(which='minor', color='k', linestyle='-', linewidth=0.2)\n",
    "\n",
    "plt.imshow(image_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeras conclusiones\n",
    "\n",
    "¿Te has dado cuenta de que la operación de convolución puede ser implementada por una neurona? Los valores del kernel son equivalentes a los pesos de una neurona, la zona de la imagen donde se superpone el kernel son las entradas a la neurona y el sumatorio de la convolución se ejecuta de la misma forma que el sumatorio de la neurona.\n",
    "\n",
    "Todo esto nos lleva a crear nuevos tipos de capas en las redes: las **capas convolutivas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capas convolutivas\n",
    "\n",
    "Las capas de red que hemos visto hasta ahora se denominan *fully connected (fc)* o **totalmente conectadas**. Esto significa que todas las salidas de una capa anterior están conectadas a todas y cada una de las entradas de la capa siguiente. Por ejemplo, si hubiera 25 neuronas en la capa anterior, cada neurona de la capa siguiente tendría 25 entradas (y una más para el *bias*). En las **capas convolutivas** esto ya no es así. Cada neurona de una capa convolutiva está conectada solo a un conjunto de salidas de la capa anterior. Además, las capas convolutivas esperan una disposición bidimensional de las entradas, no lineal. La figura muestra una neurona (esfera azul) con nueve entradas conectada a un grupo local de nueve valores. El cubo azul representa su salida.\n",
    "\n",
    "<img src=\"imgs/NeuronaConv.jpg\" width=\"50%\">\n",
    "\n",
    "\n",
    "Cada neurona de una capa convolutiva comparte el mismo conjunto de pesos, por lo que se podría decir que las neuronas de la capa convolutiva se replican de forma matricial a lo largo y ancho de la entrada. En la figura siguiente vemos la conexión de todas las neuronas de la capa convolutiva.\n",
    "\n",
    "<img src=\"imgs/CapaCompleta.jpg\" width=\"40%\">\n",
    "\n",
    "Vamos a echar cuentas, fíjate que hay $10\\times15 = 150$ entradas distintas, cada neurona tiene un **campo receptivo** de $3\\times3=9$ entradas. Si las alineamos a lo largo y ancho para que se cubran todas las entradas tenemos que hay $8\\times13=104$ neuronas. ¿Cuántos pesos distintos hay? ¿$104\\times9$? ¡¡Nooo!! Solo $9$. Cada neurona comparte el mismo conjunto de pesos, aunque los valores de las entradas son, obviamente, distintos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer un detector de bordes horizontales, verticales, diagonales, detectores de esquinas, puntos, etc. en función del **kernel** que definamos. Cada “pixel” de esta nueva \"imagen\" ya no representa  un simple valor de iluminación aislado, representa una pequeña **característica** local del objeto que contenga. Pero con una sola característica no vamos a ir muy lejos, deberíamos tener más. Supongamos que elegimos bordes horizontales, verticales, diagonales hacia la derecha y diagonales hacia la izquierda. Al aplicar estos cuatro filtros, *kernels* o conjuntos de pesos obtendremos cuatro “imágenes” de características nuevas que, convenientemente apiladas, formarán un **tensor** de $4\\times8\\times13$. Cada arreglo bidimensional de neuronas (representados con un color diferente) posee un conjunto de pesos único y compartido entre todas sus neuronas. Cada arreglo genera un **canal** diferente en la salida (representado por los cubos azules, verdes, rosas y amarillos).\n",
    "\n",
    "<img src=\"imgs/4canales.jpg\" width=\"50%\">\n",
    "\n",
    "\\- *¿Tensor? ¿Qué es un tensor?* - Los informáticos solemos llamar a un arreglo bidimensional de objetos \"*array* bidimensional\" o matriz. Cuando el arreglo es tridimensional lo solemos llamar \"*array* tridimensional\", pero no deberíamos llamarlo matriz tridimensional (eso es una expresión impropia), sino **tensor**. En el argot matemático, físico o ingenieril, cualquier arreglo de valores de tres dimensiones o más se denomina **tensor**.\n",
    "\n",
    "\n",
    "Tenemos por tanto este tensor formado por diferentes características de la imagen. ¿Podríamos repetir de nuevo este proceso, pero ahora sobre este tensor? Rápidamente nos surgen un par de preguntas: ¿Con qué pesos? ¿Cómo se conectarían ahora las neuronas?  Antes, la imagen de partida era bidimensional, ahora tenemos un tensor tridimensional. \n",
    "\n",
    "No olvidemos que estamos utilizando neuronas, y como tales, pueden aprender por ellas mismas su conjunto de pesos, solo se necesita descender por el gradiente de una función de pérdida (ya veremos luego cómo crear esta función). Por tanto, esos pesos que habíamos propuesto para detectar bordes y demás los vamos a dejar libres (“aprendibles”). Esto significa que será la propia red la que se encargue de ver si efectivamente son bordes u otras características las que realmente necesita obtener.\n",
    "\n",
    "En cuanto a la conexión, será muy parecido a lo anterior. Cada neurona se conectará a una región local en cuanto a la dimensión $x$ e $y$, y a todos los valores del tensor  en la dimensión $z$. Como ilustra la figura, la primera neurona estará conectada a su correspondiente campo receptivo de $4\\times3\\times3$. Por lo tanto, cada neurona tendrá 36 entradas.\n",
    "\n",
    "<img src=\"imgs/9x4cr.jpg\" width=\"40%\">\n",
    "\n",
    "Es muy importante ahora reflexionar sobre lo que contiene la salida de la neurona de la ilustración anterior. Es una combinación lineal de 36 valores, pero cada uno de esos valores es, a su vez, otra combinación lineal de valores anteriores correspondientes a la imagen original y cuyo valor dependía de haber encontrado una determinada característica simple o no. Por tanto, el valor de esta neurona representa haber encontrado una característica más compleja. Quizá una combinación de un borde con una esquina, o un borde más largo… Su campo receptivo sobre la imagen original es de $5\\times5$. La imagen siguiente ilustra simplificadamente por qué la última salida depende, en última instancia, de 5 valores de la entrada original.\n",
    "\n",
    "<img src=\"imgs/camporeceptivo.svg\" width=\"30%\">\n",
    "\n",
    "De la misma forma que antes, añadimos más canales y obtenemos un nuevo tensor de salida. Si añadimos 8 canales obtendremos un tensor de dimensión 8 en el eje $z$. Igual que antes, si el tensor de entrada tiene como ancho y alto $(m,n)$ el tensor de salida tendrá unas dimensiones $x$ e $y$ de $(m-2,n-2)$.\n",
    "\n",
    "<img src=\"imgs/tensor8x6x11.jpg\" width=\"60%\">\n",
    "\n",
    "## Clasificación del MNIST con una red convolutiva\n",
    "\n",
    "Vamos a componer una red convolutiva para clasificar el conjunto MNIST. Tenemos como entrada una imagen de $28\\times28$ pixels en escala de grises. Por tanto, esto es un tensor de $1\\times28\\times28$. Pasaremos esta entrada por una primera capa convolutiva de 32 filtros, lo cual nos devolverá un tensor de $32\\times26\\times26$. De nuevo, pasaremos este tensor ahora como entrada a una segunda capa convolutiva con 64 filtros. ¿Por qué 32 y 64 filtros? Bueno, te habrás imaginado ya que son hiperparámetros. El resultado es un tensor de $64\\times24\\times24$. Lo que estamos haciendo con las sucesivas capas convolutivas es ir extrayendo características cada vez más complejas que faciliten luego la labor de clasifición.\n",
    "\n",
    "Llegados a este punto, aplanaremos (*flatten*) este tensor a fin de convertirlo en un vector con una dimensión de $64\\times24\\times24 = 36864$. Ahora podremos alimentar a una capa *fully connected* (FC) de 128 neuronas. Su resultado lo pasaremos finalmente por una última capa *fully connected* de 10 neuronas.\n",
    " \n",
    "\n",
    "<img src=\"imgs/modelConv.svg\" width=\"80%\">\n",
    "\n",
    "Esta es una aproximación correcta a una red convolutiva, pero no es la práctica habitual. Hay un problema de tamaño. Si nos fijamos en la capa *fully connected* de 128 neuronas veremos que cada neurona tiene 36.864 entradas (1 más si contamos el bias). Lo que hace un total de ¡¡4.718.720 pesos para esa capa!! Para aliviar este enorme flujo de datos se emplean diferentes técnicas. Una de las más comunes es el *maxpolling*.\n",
    "\n",
    "### Maxpooling\n",
    "\n",
    "Si interpretamos con detenimiento la información que contiene un tensor, podremos eliminar gran cantidad de datos sin socavar una parte significativa de esta información. Escojamos, por ejemplo, el tensor con dimensión $32 \\times 26 \\times 26$. El valor de cada celda de este tensor corresponde a haber encontrado una determinada característica en una región concreta de la imagen original. Un valor alto significa que esa característica se encontró muy claramente. Un valor bajo o cercano al cero indica que esa característica no está presente en la correspondiente zona de la imagen. También podríamos decir que encontrar esa característica una celda a la derecha, a la izquierda, arriba o abajo no debería representar mayor inconveniente. *Maxpooling* aprovecha este hecho eliminando el 75% de los datos sin reducir excesivamente la información que contiene el tensor. Para ello se toma cada canal del tensor (es decir, se divide a lo largo del eje $z$) y se agrupan en regiones de $2 \\times 2$. De cada grupo se extrae la celda que mayor valor tenga. Al final de este proceso, tendremos un tensor con las dimensiones $x$ e $y$ reducidas a la mitad.\n",
    "\n",
    "<img src=\"imgs/MNISTconvolutional-maxpooling.svg\" width=\"100%\">\n",
    "\n",
    "\n",
    "### Dropout\n",
    "\n",
    "Las redes convolutivas, como todas las demás redes, pueden adolecer de problemas de sobreajuste (*overfitting*). Para solventar esta contrariedad existen varias técnicas que reducen su efecto. Una de las más usadas y efectivas es el <i>**dropout**</i>. Esta técnica consiste en deshabilitar temporalmente un porcentaje aleatorio de las neuronas de una capa. Es decir, durante un cierto tiempo estas neuronas están, pero como si no estuvieran. El conjunto de neuronas que se habilitan y deshabilitan se van alternando aleatoriamente durante el proceso de entrenamiento.  Con esto se consigue que todas las neuronas deban emplearse a fondo para lograr un buen nivel de *accuracy*.\n",
    "\n",
    "<img src=\"imgs/dropout.jpg\" width=\"50%\">\n",
    "\n",
    "<div align=\"center\">\n",
    "<a href=\"http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer\"> Imagen tomada del artículo original</a>\n",
    "</div>\n",
    "\n",
    "Por supuesto, el proceso de *dropout* solo se realiza durante el entrenamiento, no en producción.\n",
    "\n",
    "### ReLU\n",
    "\n",
    "Hemos visto que a la salida de las neuronas se les aplica una función de activación. Hasta ahora, hemos visto las funciones sigmoide y softmax, pero existen más. Una de ellas es la función **ReLU** (*Rectified Linear Unit*), cuya definición es:\n",
    "\n",
    "$$ReLU(x) = max(0, x)$$\n",
    "\n",
    "Lo cual significa que si la entrada es un valor mayor que 0, la salida será ese mismo valor. Pero si la entrada es negativa la salida será 0. Esta es una función predilecta en la composición de redes convolutivas ya que ofrece muy buenos resultados empíricos. Pero, ¿por qué funciona mejor que la función sigmoide? Si observamos el comportamiento de la función sigmoide con valores lejanos al 0 vemos que es una curva casi plana. Esto significa que su derivada en esos puntos es prácticamente 0, con lo que el descenso por el gradiente en esas zonas sería muy lento y, por tanto, el aprendizaje también . Este problema no lo tiene la función ReLU, su derivada en el semieje positivo es siempre 1.  Pero, ¿y qué ocurre con el semieje negativo? Bueno, cuando la salida de la neurona es negativa su paso por la función ReLU la hace 0. Asumimos que la inicialización aleatoria de los pesos hace que, dada una entrada, parte de las neuronas de una capa obtengan salidas negativas y la otra parte positivas. Esto hace que solo las neuronas con salida positiva intervengan en el proceso de representación del resultado, lo cual reduce su complejidad.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código\n",
    "\n",
    "Con todo esto, ya tenemos los elementos necesarios para montar una red convolutiva efectiva. Como ya hemos hecho anteriormente, empezamos cargando y preparando el *dataset* MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Orden en el que se presenta el dataset (num de muestras, canales, filas, columnas) o (num de muestras, filas, columnas, canales) \n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo y entrenamiento\n",
    "\n",
    "A diferencia del modelo básico anterior que utilzamos para clasificar el *dataset* MNIST, este modelo incluirá capas convolutivas <code>Conv2D</code>, dropout <code>Dropout</code> y funciones de activación ReLU <code>activation='relu'</code>. Al entrenarlo vemos cómo el *accuracy* sobre el conjunto de validación es mayor que en el modelo básico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2643 - accuracy: 0.9187 - val_loss: 0.0629 - val_accuracy: 0.9796\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0867 - accuracy: 0.9737 - val_loss: 0.0385 - val_accuracy: 0.9864\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0646 - accuracy: 0.9807 - val_loss: 0.0345 - val_accuracy: 0.9880\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0533 - accuracy: 0.9846 - val_loss: 0.0306 - val_accuracy: 0.9897\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0476 - accuracy: 0.9859 - val_loss: 0.0292 - val_accuracy: 0.9902\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.0310 - val_accuracy: 0.9898\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.0275 - val_accuracy: 0.9919\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 0.0279 - val_accuracy: 0.9904\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.0259 - val_accuracy: 0.9917\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0284 - val_accuracy: 0.9906\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0287 - accuracy: 0.9911 - val_loss: 0.0287 - val_accuracy: 0.9916\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.0263 - val_accuracy: 0.9919\n",
      "Test loss: 0.026326180382099666\n",
      "Test accuracy: 0.9919000267982483\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que el *accuracy* sobre el conjunto de validación es 99% !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusiones\n",
    "\n",
    "Las redes convolutivas se componen de dos partes: las capas convolutivas y las capas *fully connected*. Las primeras llevan a cabo un proceso de extracción de características, donde la información se hace más elaborada y compleja a medida que se pasan capas convolutivas. En la segunda parte se lleva a cabo el proceso de clasificación propiamente dicho, donde se detecta la combinación de características que conforman el objeto a determinar.\n",
    "\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "- Ejecuta este código en Colab o en tu ordenador. Modifica algunos hiperparámetros y observa si hay cambios significativos. Por ejemplo, cambia la función ReLU por una sigmoide, Adadelta por SGD, añade más capas convolutivas o cambia el tamaño del kernel a $5 \\times 5$.\n",
    "\n",
    "\n",
    "- **Obligatorio:** Contesta [este formulario](https://forms.gle/KR3ALmK8TTe9V2QV8) (hora y fecha límite para contestarlo: a las 23:59:59 del 24 de abril del 2020  - hora canaria)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
