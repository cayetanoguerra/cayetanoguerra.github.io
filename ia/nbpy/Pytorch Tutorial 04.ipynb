{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial de Pytorch 4: MNIST\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nn_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Par치metros\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformaci칩n para el dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Cargar el dataset MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar una de las im치genes del dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor (mini-batch) proveniente del DataLoader:  torch.Size([64, 1, 28, 28])\n",
      "Tama침o de la imagen: torch.Size([1, 28, 28])\n",
      "Etiqueta: tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "print(\"Tensor (mini-batch) proveniente del DataLoader: \", next(iter(train_loader))[0].shape)\n",
    "\n",
    "image, label = next(iter(train_loader))\n",
    "\n",
    "pyplot.imshow(image[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(\"Tama침o de la imagen:\", image[0].shape)\n",
    "print(\"Etiqueta:\", label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modelo**\n",
    "\n",
    "Compondremos el modelo como una simple red neuronal feedforward con una sola capa oculta:\n",
    "\n",
    "**Herencia de nn.Module**:\n",
    "\n",
    "La clase Model hereda de nn.Module, que es la clase base para todos los m칩dulos de redes neuronales en PyTorch. Esto proporciona funcionalidades como la gesti칩n de par치metros y utilidades para el entrenamiento y la inferencia.\n",
    "\n",
    "\n",
    "**Constructor __init__**:\n",
    "\n",
    "Aqu칤 es donde se definen las capas y operaciones que componen la red neuronal.\n",
    "\n",
    "- self.fc1 = nn.Linear(input_size, hidden_size): Esta es la primera capa totalmente conectada (o \"dense\") que transforma la entrada de tama침o input_size a un vector de tama침o hidden_size.\n",
    "\n",
    "- self.relu = nn.ReLU(): Esta es la funci칩n de activaci칩n ReLU (Rectified Linear Unit). Se utiliza para a침adir no linealidad al modelo.\n",
    "\n",
    "- self.fc2 = nn.Linear(hidden_size, num_classes): Esta es la segunda capa totalmente conectada que transforma el vector de tama침o hidden_size (salida de la capa oculta) a un vector de tama침o num_classes (probabilidades de las clases en la tarea de clasificaci칩n).\n",
    "\n",
    "**M칠todo forward**:\n",
    "\n",
    "Este m칠todo define c칩mo se deben procesar las entradas (x) a trav칠s de las capas y operaciones definidas en el constructor.\n",
    "\n",
    "- out = self.fc1(x): La entrada x se pasa a trav칠s de la primera capa totalmente conectada.\n",
    "\n",
    "- out = self.relu(out): Luego, la salida de la primera capa pasa por la funci칩n de activaci칩n ReLU.\n",
    "\n",
    "- out = self.fc2(out): Finalmente, la salida activada se pasa a trav칠s de la segunda capa totalmente conectada.\n",
    "    \n",
    "Al final del m칠todo forward, se devuelve la salida de la segunda capa totalmente conectada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici칩n de la red neuronal\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.6474\n",
      "Epoch [1/5], Step [200/938], Loss: 0.3294\n",
      "Epoch [1/5], Step [300/938], Loss: 0.3347\n",
      "Epoch [1/5], Step [400/938], Loss: 0.4023\n",
      "Epoch [1/5], Step [500/938], Loss: 0.2950\n",
      "Epoch [1/5], Step [600/938], Loss: 0.2578\n",
      "Epoch [1/5], Step [700/938], Loss: 0.3363\n",
      "Epoch [1/5], Step [800/938], Loss: 0.2230\n",
      "Epoch [1/5], Step [900/938], Loss: 0.3976\n",
      "Epoch [2/5], Step [100/938], Loss: 0.2263\n",
      "Epoch [2/5], Step [200/938], Loss: 0.3251\n",
      "Epoch [2/5], Step [300/938], Loss: 0.2840\n",
      "Epoch [2/5], Step [400/938], Loss: 0.2660\n",
      "Epoch [2/5], Step [500/938], Loss: 0.3651\n",
      "Epoch [2/5], Step [600/938], Loss: 0.3809\n",
      "Epoch [2/5], Step [700/938], Loss: 0.2726\n",
      "Epoch [2/5], Step [800/938], Loss: 0.2008\n",
      "Epoch [2/5], Step [900/938], Loss: 0.3138\n",
      "Epoch [3/5], Step [100/938], Loss: 0.3711\n",
      "Epoch [3/5], Step [200/938], Loss: 0.3098\n",
      "Epoch [3/5], Step [300/938], Loss: 0.3544\n",
      "Epoch [3/5], Step [400/938], Loss: 0.2417\n",
      "Epoch [3/5], Step [500/938], Loss: 0.1082\n",
      "Epoch [3/5], Step [600/938], Loss: 0.2050\n",
      "Epoch [3/5], Step [700/938], Loss: 0.3000\n",
      "Epoch [3/5], Step [800/938], Loss: 0.2500\n",
      "Epoch [3/5], Step [900/938], Loss: 0.1087\n",
      "Epoch [4/5], Step [100/938], Loss: 0.3259\n",
      "Epoch [4/5], Step [200/938], Loss: 0.2629\n",
      "Epoch [4/5], Step [300/938], Loss: 0.1895\n",
      "Epoch [4/5], Step [400/938], Loss: 0.1460\n",
      "Epoch [4/5], Step [500/938], Loss: 0.1108\n",
      "Epoch [4/5], Step [600/938], Loss: 0.2382\n",
      "Epoch [4/5], Step [700/938], Loss: 0.1172\n",
      "Epoch [4/5], Step [800/938], Loss: 0.1914\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0312\n",
      "Epoch [5/5], Step [100/938], Loss: 0.3349\n",
      "Epoch [5/5], Step [200/938], Loss: 0.1017\n",
      "Epoch [5/5], Step [300/938], Loss: 0.1241\n",
      "Epoch [5/5], Step [400/938], Loss: 0.2252\n",
      "Epoch [5/5], Step [500/938], Loss: 0.1533\n",
      "Epoch [5/5], Step [600/938], Loss: 0.2207\n",
      "Epoch [5/5], Step [700/938], Loss: 0.2126\n",
      "Epoch [5/5], Step [800/938], Loss: 0.2397\n",
      "Epoch [5/5], Step [900/938], Loss: 0.2161\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instanciaci칩n del modelo, funci칩n de p칠rdida y optimizador\n",
    "model = Model(28*28, 50, 10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluaci칩n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 95.60%\n"
     ]
    }
   ],
   "source": [
    "# Test del modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
