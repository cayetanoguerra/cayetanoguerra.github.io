{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales 9\n",
    "---\n",
    "\n",
    "## Arquitecturas de redes\n",
    "\n",
    "\n",
    "\n",
    "### Alexnet\n",
    "\n",
    "Esta arquitectura fue una de las primeras redes profundas en mejorar la precisión de la Clasificación del ImageNet. Constituyó un gran avance en comparación con las metodologías tradicionales. Está compuesta por 5 capas convolutivas seguidas por 3 capas *fully connected*.\n",
    "\n",
    "<img src=\"imgs/alexnet.png\" width=\"80%\">\n",
    "\n",
    "AlexNet, fue propuesta por Alex Krizhevsky, usa ReLU (unidad lineal rectificadora) para la parte no lineal, en lugar de una función tangente hiperbólica o sigmoide, que era el estándar anterior para las redes neuronales tradicionales. La ventaja de la ReLU sobre sigmoide es que se entrena mucho más rápido que esta última porque la derivada del sigmoide se vuelve muy pequeña en la región de saturación y, por lo tanto, las actualizaciones de los pesos casi desaparecen. Esto se conoce como el problema de desvanecimiento del gradiente.\n",
    "\n",
    "Otro problema que resolvió esta arquitectura fue la reducción del sobreajuste mediante el uso de una capa dropout después de cada capa FC.\n",
    "\n",
    "<img src=\"imgs/dropout.png\" width=\"50%\">\n",
    "\n",
    "### VGG16\n",
    "\n",
    "Esta arquitectura es del grupo VGG, Oxford. Lleva a cabo una la mejora con respecto a AlexNet al reemplazar los filtros de tamaño (11 y 5 en la primera y segunda capa convolutiva, respectivamente) con múltiples filtros seguidos de tamaño 3X3. Con un campo receptivo dado, el kernel de tamaño más pequeño apilado resulta mejor que el de tamaño más grande porque varias capas no lineales aumentan la profundidad de la red, lo que le permite que extraiga características más complejas a un costo menor.\n",
    "\n",
    "<img src=\"imgs/vgg16.png\" width=\"25%\">\n",
    "\n",
    "Las capas convolutivas VGG son seguidas por 3 capas *fully connected*. El ancho de la red comienza con un valor de 64 y aumenta en un factor de 2 después de cada capa de *pooling*. Alcanza la precisión del 92.3% en el top-5 en ImageNet.\n",
    "\n",
    "### Inception\n",
    "\n",
    "GoogLeNet ideó un módulo llamado *Inception* que se aproxima a una CNN dispersa mediante una construcción densa normal. Además, utiliza convoluciones de diferentes tamaños para capturar detalles a escalas variadas (5X5, 3X3, 1X1). Otro punto sobresaliente del módulo es que tiene la llamada capa *bottleneck* (1X1), que ayuda en la reducción masiva de los requisitos de cálculo.\n",
    "\n",
    "<img src=\"imgs/inception-v3-model.png\">\n",
    "<img src=\"imgs/inception_module.png\">\n",
    "\n",
    "#### Degeneración de la precisión\n",
    "\n",
    "<img src=\"imgs/performance.png\">\n",
    "\n",
    "\n",
    "### ResNet\n",
    "\n",
    "De acuerdo con lo que hemos visto hasta ahora, aumentar la profundidad debería aumentar la precisión de la red, siempre que se tenga cuidado del sobreajuste. Pero el problema con la mayor profundidad es que la señal requerida para cambiar los pesos, que surge del final de la red al comparar las etiquetas con las predicciones, se vuelve muy pequeña en las capas anteriores, debido a la mayor profundidad. Esencialmente significa que en las capas anteriores el aprendizaje es casi insignificante. Este problema se conoce como **desvanecimiento del gradiente**. El segundo problema con el entrenamiento de las redes más profundas es realizar la optimización en un gran espacio de parámetros. Las redes residuales permiten el desarrollo de redes tan profundas al construir la red a través de módulos llamados **módulos residuales**\n",
    "\n",
    "<img src=\"imgs/residual.png\">\n",
    "\n",
    "<img src=\"imgs/resnet-comp.png\">\n",
    "\n",
    "\n",
    "## GAP Global Average Pooling\n",
    "\n",
    "En los últimos años se ha recurrido a las capas GAP para minimizar el sobreajuste. Al igual que las capas *maxpooling*, las capas GAP se utilizan para reducir las dimensiones espaciales de un tensor tridimensional. Sin embargo, las capas GAP realizan un tipo más extremo de reducción de dimensionalidad, donde un tensor con dimensiones $h×w×d$ se reduce de tamaño para tener dimensiones $1×1×d$. Las capas GAP reducen cada mapa de características a un solo número simplemente tomando el promedio de todos los valores.\n",
    "\n",
    "<img src=\"imgs/gap2.png\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
