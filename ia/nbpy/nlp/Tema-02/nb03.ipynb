{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelos estadísticos del lenguaje**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelos markovianos**\n",
    "\n",
    "Los modelos markovianos del lenguaje, también conocidos como modelos de Markov de lenguaje, son una clase de modelos estadísticos que se utilizan para predecir la probabilidad de una secuencia de palabras en un texto. Estos modelos se basan en la teoría de procesos estocásticos de Markov.\n",
    "\n",
    "#### **1. Proceso de Markov**\n",
    "Un proceso de Markov es un tipo de modelo estadístico que predice el futuro de un proceso estocástico basándose únicamente en su estado actual, y no en cómo llegó a ese estado (esto es, no tiene memoria). Por ejemplo, el tiempo atmosférico de día a día podría ser simulado de esta forma:\n",
    "\n",
    "<img src=\"imgs/markov.svg\" width=\"30%\">\n",
    "\n",
    "Esto quiere decir, por ejemplo, que si el martes está nublado hay un 10% de probabilidades de que el miércoles esté soleado. Las probabilidades las podemos representar también mediante una tabla de probabilidades de transición, donde la suma de cada fila debe ser 1.\n",
    "\n",
    "|          | soleado | nublado | lluvioso |\n",
    "|----------|---------|---------|----------|\n",
    "| **soleado**  | 0\\.6    | 0\\.3    | 0\\.1     |\n",
    "| **nublado**  | 0\\.1    | 0\\.5    | 0\\.4     |\n",
    "| **lluvioso** | 0\\.6    | 0\\.2    | 0\\.2     |\n",
    "\n",
    "Matemáticamente se expresaría así:\n",
    "\n",
    "$$ P[s_{t+1} | s_t] = P[s_{t+1} | s_t, s_{t-1}, \\cdots ,s_1 ] $$\n",
    "\n",
    "#### **2. Cadena de Markov**\n",
    "Una cadena de Markov es una secuencia de eventos, cada uno de los cuales depende solo del evento que lo precedió. En el ejemplo anterior, la cadena de Markov sería:\n",
    "\n",
    "\"soleado→nublado→nublado→lluvioso\"\n",
    "\n",
    "Esta cadena en particular tendría la siguiente probabilidad de aparición:\n",
    "\n",
    "$$ P[soleado→nublado→nublado→lluvioso] = P[soleado] \\cdot P[nublado|soleado] \\cdot P[nublado|nublado] \\cdot P[lluvioso|nublado] $$\n",
    "\n",
    "Lo cual es:\n",
    "\n",
    "$$ P[soleado→nublado→nublado→lluvioso] = 0.43 \\cdot 0.6 \\cdot 0.5 \\cdot 0.4 = 0.0516 $$\n",
    "\n",
    "En el contexto de los modelos de lenguaje, los eventos son palabras o símbolos.\n",
    "\n",
    "\n",
    "### **Modelos de Lenguaje:**\n",
    "\n",
    "Un **modelo de lenguaje** es un modelo matemático y computacional que está diseñado para predecir la probabilidad de una secuencia de palabras en un lenguaje dado. Los modelos de lenguaje pueden generar texto de una manera que sigue las normas gramaticales y estilísticas del lenguaje que están modelando. \n",
    "\n",
    "#### **1. Modelos de Unigramas**\n",
    "Son los modelos markovianos más simples donde cada palabra se modela como un evento independiente, sin tener en cuenta las palabras anteriores.\n",
    "\n",
    "#### **2. Modelos de Bigramas**\n",
    "En estos modelos, la probabilidad de cada palabra solo depende de la palabra que la precede inmediatamente. La probabilidad de una secuencia de palabras se calcula como el producto de las probabilidades de cada bigrama (pares de palabras consecutivas) en la secuencia.\n",
    "\n",
    "#### **3. Modelos de Trigramas**\n",
    "Similar a los modelos de bigramas, pero aquí la probabilidad de cada palabra depende de las dos palabras que la preceden. \n",
    "\n",
    "#### **4. Modelos de n-gramas**\n",
    "Por extensión, se pueden definir modelos de n-gramas como aquellos donde la probabilidad de cada palabra depende de las n palabras que la preceden.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Entrenamiento de los Modelos:\n",
    "Para entrenar estos modelos, se utilizan corpora de texto para calcular las probabilidades condicionales de palabras dado su contexto histórico.\n",
    "\n",
    "### Generación de Texto:\n",
    "Una vez entrenado, un modelo de Markov puede usarse para generar texto nuevo, seleccionando palabras una a una de acuerdo a las probabilidades calculadas a partir del texto de entrenamiento.\n",
    "\n",
    "### Ventajas:\n",
    "1. **Simplicidad**: Los modelos de Markov son relativamente simples de entender y de implementar.\n",
    "2. **Eficiencia**: Pueden ser computacionalmente menos intensivos que otros modelos más complejos.\n",
    "\n",
    "### Desventajas:\n",
    "1. **Memoria Limitada**: Los modelos de Markov no capturan dependencias de largo alcance en el texto debido a su naturaleza de \"memoria corta\".\n",
    "2. **Espacio de Estado Grande**: Para modelos de n-gramas con \\(n\\) grande, el espacio de estados (y, por lo tanto, los requerimientos de memoria) pueden crecer exponencialmente.\n",
    "\n",
    "### Aplicaciones:\n",
    "Los modelos markovianos del lenguaje se utilizan en una variedad de aplicaciones, como reconocimiento de voz, procesamiento de lenguaje natural, generación de texto, entre otros.\n",
    "\n",
    "En resumen, los modelos markovianos del lenguaje son una herramienta fundamental en el campo del procesamiento del lenguaje natural, ofreciendo una forma de modelar y generar lenguaje basada en la estadística y la probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
