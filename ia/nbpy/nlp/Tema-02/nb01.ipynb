{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **Modelos estadísticos del lenguaje**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenización**\n",
    "\n",
    "La **tokenización** es un paso crucial en el procesamiento del lenguaje natural (NLP, por sus siglas en inglés). En este proceso, un texto (que puede ser una oración, un párrafo o un documento completo) se divide en piezas más pequeñas llamadas \"tokens\". Estos tokens pueden ser palabras, conjuntos de palabras, subpalabras o incluso caracteres individuales, dependiendo del nivel de tokenización que se está realizando.\n",
    "\n",
    "Por ejemplo, la frase: \"Este año me voy de vacaciones a la playa\" puede ser dividida en tokens de la siguiente manera:\n",
    "\"Este\", \"año\", \"me\", \"voy\", \"de\", \"vacaciones\", \"a\", \"la\", \"playa\". Aunque la forma más fácil de tokenizar un texto es separarlo en palabras, usando para ello los espacios en blanco entre palabras, recuerda que también es posible tokenizar de otras formas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Este', 'año', 'me', 'voy', 'de', 'vacaciones', 'a', 'la', 'playa']\n"
     ]
    }
   ],
   "source": [
    "txt = \"Este año me voy de vacaciones a la playa\"\n",
    "tokens = txt.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tokens también pueden incluir signos de puntuación. Dependediendo de la aplicación que estemos desarrollando, puede ser útil mantenerlos o eliminarlos. Podemos hacerlo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Este', 'año,', 'como', 'hicimos', 'el', 'anterior,', 'nos', 'iremos', 'a', 'la', 'playa', 'de', 'vacaciones.']\n"
     ]
    }
   ],
   "source": [
    "txt = \"Este año, como hicimos el anterior, nos iremos a la playa de vacaciones.\"\n",
    "tokens = txt.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Este', 'año', 'como', 'hicimos', 'el', 'anterior', 'nos', 'iremos', 'a', 'la', 'playa', 'de', 'vacaciones']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizar eliminando signos de puntuación\n",
    "txt = \"Este año, como hicimos el anterior, nos iremos a la playa de vacaciones.\"\n",
    "\n",
    "txt = txt.replace(',', '')\n",
    "txt = txt.replace('.', '')\n",
    "txt = txt.replace(';', '')\n",
    "txt = txt.replace(':', '')\n",
    "txt = txt.replace('?', '')\n",
    "txt = txt.replace('¿', '')\n",
    "txt = txt.replace('!', '')\n",
    "txt = txt.replace('¡', '')\n",
    "\n",
    "tokens = txt.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "- Crea un script para extraer los símbolos de puntuación como tokens independientes.\n",
    "- ¿Qué ocurre si nos encontramos un texto donde no se han separado correctamente las palabras y los signos de puntuación? Por ejemplo: \"¿Cómo estás?Bien,gracias.\"\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lematización**\n",
    "\n",
    "La **lematización** es un proceso que consiste en reducir las palabras a su forma básica o \"lema\", que es una forma canónica o de diccionario de una palabra. La lematización tiene en cuenta el análisis morfológico de las palabras, es decir, considera el contexto gramatical y sintáctico para convertir una palabra a su forma base.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "\"Corriendo\" → \"correr\"\n",
    "\n",
    "\"Mujeres\" → \"mujer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Derivación o stemming**\n",
    "\n",
    "La derivación o \"stemming\" es un proceso que tiene como objetivo reducir las palabras a su raíz o \"tallo\" (en inglés, \"stem\"). A diferencia de la lematización, que intenta reducir las palabras a su forma base léxica teniendo en cuenta la morfología y el contexto gramatical, el stemming suele ser un proceso más heurístico y rudimentario que simplemente elimina los sufijos (y a veces prefijos) de las palabras.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "\"Corriendo\" → \"corri\"\n",
    "\n",
    "\"Comiendo\" → \"comi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/SpaCy_logo.png\" width=\"25%\">\n",
    "\n",
    "Procesar texto no suele ser una tarea trivial. La mayoría de las palabras son raras y es común que palabras que parecen completamente diferentes signifiquen casi lo mismo. Las mismas palabras en diferente orden pueden significar algo completamente diferente. Incluso dividir el texto en unidades útiles similares a palabras puede resultar difícil en muchos idiomas. Si bien es posible resolver algunos problemas a partir únicamente de los caracteres sin procesar, generalmente es mejor utilizar conocimientos lingüísticos para agregar información útil. Eso es exactamente para lo que está diseñado <a href=\"https://spacy.io/\">spaCy</a>: ingresas texto sin formato y obtienes un objeto <code>Doc</code>, que viene con una variedad de anotaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo tokenizar un texto usando Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este\n",
      "año\n",
      ",\n",
      "como\n",
      "hicimos\n",
      "el\n",
      "anterior\n",
      ",\n",
      "nos\n",
      "iremos\n",
      "a\n",
      "la\n",
      "playa\n",
      "de\n",
      "vacaciones\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "doc = nlp(\"Este año, como hicimos el anterior, nos iremos a la playa de vacaciones.\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de tokenizar, es posible que queramos separar en frases el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esto es una oración.\n",
      "Esto es otra oración.\n",
      "U.S.A. es un país.\n",
      "Esta es un frase final.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "doc = nlp(\"Esto es una oración. Esto es otra oración. U.S.A. es un país. Esta es un frase final.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part-of-speech (POS) tagging**\n",
    "\n",
    "Después de la tokenización, spaCy puede analizar y etiquetar un Doc dado. Aquí es donde entran en juego la cadena de procesamiento (pipeline) y sus modelos estadísticos, que permiten a spaCy hacer predicciones sobre qué etiqueta o marcador es el más probable en este contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Text    Lemma    POS  Tag       Dep  Shape  is_alpha  is_stop\n",
      "0     Apple    Apple  PROPN  NNP     nsubj  Xxxxx      True    False\n",
      "1        is       be    AUX  VBZ       aux     xx      True     True\n",
      "2   looking     look   VERB  VBG      ROOT   xxxx      True    False\n",
      "3        at       at    ADP   IN      prep     xx      True     True\n",
      "4    buying      buy   VERB  VBG     pcomp   xxxx      True    False\n",
      "5      U.K.     U.K.  PROPN  NNP      dobj   X.X.     False    False\n",
      "6   startup  startup   NOUN   NN       dep   xxxx      True    False\n",
      "7       for      for    ADP   IN      prep    xxx      True     True\n",
      "8         $        $    SYM    $  quantmod      $     False    False\n",
      "9         1        1    NUM   CD  compound      d     False    False\n",
      "10  billion  billion    NUM   CD      pobj   xxxx      True    False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Text', 'Lemma', 'POS', 'Tag', 'Dep', 'Shape', 'is_alpha', 'is_stop']) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas de las categorías en las que se divide las partes de la oración son:\n",
    "\n",
    "- **ADJ**: Adjetivo. Por ejemplo, \"feliz\", \"triste\".\n",
    "- **ADP**: Preposición. Por ejemplo, \"en\", \"sobre\".\n",
    "- **ADV**: Adverbio. Por ejemplo, \"rápidamente\", \"lentamente\".\n",
    "- **AUX**: Verbo auxiliar. Por ejemplo, \"ha\", \"está\".\n",
    "- **CONJ**: Conjunción. Por ejemplo, \"y\", \"o\".\n",
    "- **CCONJ**: Conjunción coordinante. Por ejemplo, \"y\", \"ni\".\n",
    "- **DET**: Determinante. Por ejemplo, \"el\", \"un\".\n",
    "- **INTJ**: Interjección. Por ejemplo, \"¡hola!\", \"¡uy!\".\n",
    "- **NOUN**: Sustantivo. Por ejemplo, \"gato\", \"perro\".\n",
    "- **NUM**: Numeral. Por ejemplo, \"uno\", \"dos\".\n",
    "- **PART**: Partícula. Por ejemplo, \"no\", \"sí\".\n",
    "- **PRON**: Pronombre. Por ejemplo, \"él\", \"ella\".\n",
    "- **PROPN**: Nombre propio. Por ejemplo, \"María\", \"Londres\".\n",
    "- **PUNCT**: Puntuación. Por ejemplo, \".\", \",\".\n",
    "- **SCONJ**: Conjunción subordinante. Por ejemplo, \"que\", \"si\".\n",
    "- **SYM**: Símbolo. Por ejemplo, \"@\", \"&\".\n",
    "- **VERB**: Verbo. Por ejemplo, \"correr\", \"saltar\".\n",
    "- **X**: Otro, usado para otras categorías o tokens no clasificables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6d0229816b5040039514765eb07f16e0-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-5\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,266.5 L1273.0,254.5 1257.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6d0229816b5040039514765eb07f16e0-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6d0229816b5040039514765eb07f16e0-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos también las etiquetas \"Dep\" que indica la dependencia o relación sintáctica entre las palabras de una oración. Algunas de estas etiquetas son:\n",
    "\n",
    "- **nsubj**: Sujeto nominal de la cláusula.\n",
    "- **nsubjpass**: Sujeto nominal de una cláusula pasiva.\n",
    "- **csubj**: Sujeto clausal de la cláusula.\n",
    "- **csubjpass**: Sujeto clausal de una cláusula pasiva.\n",
    "- **pobj**: Objeto de una preposición.\n",
    "- **dobj**: Objeto directo.\n",
    "- **iobj**: Objeto indirecto.\n",
    "- **attr**: Atributo, como en \"El cielo está azul\", donde \"azul\" es un atributo de \"cielo\".\n",
    "- **ROOT**: Palabra central de la oración, desde la que se origina la dependencia.\n",
    "- **cc**: Conjunción coordinada.\n",
    "- **conj**: Palabra conectada por una conjunción.\n",
    "- **det**: Determinante.\n",
    "- **amod**: Modificador adjetival.\n",
    "- **advmod**: Modificador adverbial.\n",
    "- **prep**: Preposición.\n",
    "- **mark**: Marcador, generalmente una palabra que introduce una cláusula subordinada.\n",
    "- **aux**: Verbo auxiliar.\n",
    "- **neg**: Negación.\n",
    "- **nummod**: Modificador numeral.\n",
    "- **relcl**: Cláusula relativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La etiqueta \"is_alpha\" significa que el token es una palabra (no un signo de puntuación, número, etc.). La etiqueta \"is_stop\" significa que el token es una \"stop word\". \n",
    "\n",
    "Las \"stop words\" son palabras que se utilizan con mucha frecuencia en un idioma pero que generalmente contienen poca información semántica. En muchas tareas de procesamiento del lenguaje natural, estas palabras se eliminan durante el preprocesamiento de los datos para reducir la cantidad de ruido en el conjunto de datos y hacer que los modelos sean más eficientes y efectivos. Estas palabras generalmente incluyen palabras como \"el\", \"un\", \"y\", \"de\", etc.\n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Esto, is_stop: True\n",
      "Token: es, is_stop: True\n",
      "Token: una, is_stop: True\n",
      "Token: prueba, is_stop: False\n",
      "Token: de, is_stop: True\n",
      "Token: cómo, is_stop: True\n",
      "Token: funciona, is_stop: False\n",
      "Token: el, is_stop: True\n",
      "Token: atributo, is_stop: False\n",
      "Token: is_stop, is_stop: False\n",
      "Token: ., is_stop: False\n",
      "----------------------------------------\n",
      "Palabras con información útil:\n",
      "Token: prueba\n",
      "Token: funcionar\n",
      "Token: atributo\n",
      "Token: is_stop\n",
      "Token: .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar el modelo de spaCy (aquí estoy usando el modelo en inglés, puedes cambiarlo según tus necesidades)\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Procesar un texto con el modelo de spaCy\n",
    "doc = nlp(\"Esto es una prueba de cómo funciona el atributo is_stop.\")\n",
    "\n",
    "# Iterar sobre los tokens en el documento procesado\n",
    "for token in doc:\n",
    "    # Imprimir el texto del token y el valor de su atributo 'is_stop'\n",
    "    print(f\"Token: {token.text}, is_stop: {token.is_stop}\")\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Palabras con información útil:\")\n",
    "\n",
    "for token in doc:\n",
    "    if not token.is_stop:\n",
    "        print(f\"Token: {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Text    Lemma   POS   Tag    Dep   Shape  is_alpha  is_stop\n",
      "0     Estoy    estar   AUX   AUX    aux   Xxxxx      True     True\n",
      "1  pensando   pensar  VERB  VERB   ROOT    xxxx      True    False\n",
      "2        en       en   ADP   ADP   mark      xx      True     True\n",
      "3   comprar  comprar  VERB  VERB  xcomp    xxxx      True    False\n",
      "4        un      uno   DET   DET    det      xx      True     True\n",
      "5     coche    coche  NOUN  NOUN    obj    xxxx      True    False\n",
      "6       que      que  PRON  PRON  nsubj     xxx      True     True\n",
      "7    cuesta   costar  VERB  VERB    acl    xxxx      True    False\n",
      "8      unos      uno  PRON  PRON   nmod    xxxx      True     True\n",
      "9   30000€.  30000€.   NUM   NUM    obl  dddd€.     False    False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "doc = nlp(\"Estoy pensando en comprar un coche que cuesta unos 30000€.\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Text', 'Lemma', 'POS', 'Tag', 'Dep', 'Shape', 'is_alpha', 'is_stop']) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Named Entity Recognition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El reconocimiento de entidades nombradas es una tarea muy común dentro del NLP. Consiste en extraer del texto las entidades que son de interés para el usuario, como por ejemplo nombres de personas, organizaciones, lugares, etc. Vamos a ver cómo hacerlo con la librería spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madrid 0 6 LOC\n",
      "España 24 30 LOC\n",
      "Juan Pérez 53 63 PER\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "doc = nlp(\"Madrid es la capital de España y donde vive mi amigo Juan Pérez.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cayetano/Propio/Notebooks/Machine Learning/RL/env/lib/python3.10/site-packages/spacy/displacy/__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "Carga el archivo de texto con la novela \"Cien años de soledad\" y calcula:\n",
    "\n",
    "- El número de palabras que tiene la novela.\n",
    "- El número de palabras únicas que tiene la novela.\n",
    "- El número de veces que aparece la palabra \"Macondo\" en la novela.\n",
    "- Las 100 palabras más frecuentes de la novela, eliminando las palabras vacías (stopwords).\n",
    "\n",
    "Ten en cuenta no diferenciar entre mayúsculas y minúsculas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Byte Pair Encoding (BPE)**\n",
    "\n",
    "https://github.com/openai/tiktoken\n",
    "\n",
    "\n",
    "El **Byte Pair Encoding** (BPE) es una técnica de compresión de datos que también se ha adaptado para tokenizar texto en el procesamiento del lenguaje natural. Originalmente diseñado para representar datos de manera eficiente, BPE funciona identificando pares de bytes (o caracteres) consecutivos que aparecen con frecuencia y fusionándolos en una sola unidad o token. En el contexto del procesamiento del lenguaje natural, este método ayuda a construir un vocabulario de subpalabras, permitiendo que los modelos de lenguaje manejen palabras raras o desconocidas de manera más eficiente y mitiguen el problema de vocabulario abierto, descomponiendo las palabras en unidades más pequeñas que aún retienen significado semántico.\n",
    "\n",
    "\n",
    "### Paso a Paso:\n",
    "\n",
    "1. **Vocabulario Inicial**: Comienza construyendo un vocabulario inicial. Esto a menudo implica tomar cada palabra en el conjunto de datos y descomponerla en sus caracteres individuales.\n",
    "\n",
    "2. **Conteo de Pares**: En cada iteración, cuenta todos los pares de símbolos/caracteres consecutivos (o pares de byte) en el conjunto de datos.\n",
    "\n",
    "3. **Fusión de Pares más Frecuentes**: Encuentra el par de símbolos más frecuente y los fusiona para formar un nuevo símbolo. Este nuevo símbolo representa ahora una secuencia de caracteres que a menudo aparecen juntos.\n",
    "\n",
    "4. **Iteración**: Se repite el paso 2 y 3 un número predefinido de veces o hasta que se alcance un tamaño de vocabulario deseado. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  token\n",
      "-----  --------\n",
      "69112  'Hola'\n",
      "   11  ','\n",
      "  757  ' me'\n",
      " 9507  ' ll'\n",
      "21781  'amo'\n",
      "29604  ' Juan'\n",
      "   13  '.'\n",
      "29386  ' ¿'\n",
      "96997  'Cómo'\n",
      " 1028  ' te'\n",
      " 9507  ' ll'\n",
      "29189  'amas'\n",
      "90318  ' tú'\n",
      " 4710  '?.'\n",
      " 2206  ' Me'\n",
      " 9507  ' ll'\n",
      "21781  'amo'\n",
      "83305  ' María'\n",
      "   13  '.'\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from tabulate import tabulate\n",
    "\n",
    "txt = \"Hola, me llamo Juan. ¿Cómo te llamas tú?. Me llamo María.\"\n",
    "\n",
    "# Convierte txt en una lista de tokens\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# Convierte tokens en una lista de índices\n",
    "ids = enc.encode(txt)\n",
    "\n",
    "data = []\n",
    "\n",
    "for id in ids:\n",
    "    data.append([id, \"'\" + enc.decode([id]) + \"'\" ])\n",
    "    \n",
    "print(tabulate(data, headers=['id', 'token']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
