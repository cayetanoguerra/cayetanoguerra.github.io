{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **Modelos del lenguaje basados en redes neuronales artificiales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/hf-logo-with-title.svg\" width=\"500\">\n",
    "\n",
    "https://huggingface.co/docs/hub/index\n",
    "\n",
    "Hugging Face es una empresa enfocada en inteligencia artificial y aprendizaje automático, conocida principalmente por su biblioteca \"Transformers\" que proporciona modelos preentrenados para procesamiento de lenguaje natural y otras tareas. Ofrecen una plataforma colaborativa, el Hugging Face Hub, donde los usuarios pueden compartir y trabajar en modelos de IA, conjuntos de datos y aplicaciones. La compañía promueve la democratización y accesibilidad de la IA a través de soluciones de código abierto y ciencia abierta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598050713539124}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, este **pipeline** selecciona un modelo preentrenado específico que ha sido ajustado para el análisis de sentimientos en inglés. El modelo se descarga y almacena en caché cuando creas el objeto clasificador. Si vuelves a ejecutar el comando, se utilizará el modelo almacenado en caché en lugar de descargar el modelo de nuevo. Vamos a cargar un modelo preentrenado para el análisis de sentimientos en multi-idoma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9279075264930725}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_multi = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "classifier(\"Nunca había visto una película tan mala en mi vida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos principales cuando pasas algún texto a un pipeline son:\n",
    "\n",
    "1. El texto se preprocesa en un formato que el modelo puede entender.\n",
    "2. Las entradas preprocesadas se pasan al modelo.\n",
    "3. Las predicciones del modelo se post-procesan, para que puedas entenderlas.\n",
    "\n",
    "Algunas de los pipeline disponibles son:\n",
    "\n",
    "- Extracción de la representación vectorial de un texto\n",
    "- Rellenar-enmascaramientos\n",
    "- Reconocimiento de entidades nombradas (NER)\n",
    "- Preguntas y respuestas\n",
    "- Análisis de sentimientos\n",
    "- Resúmenes\n",
    "- Generación de texto\n",
    "- Traducción\n",
    "- Clasificación \"zero-shot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clasificación *zero-shot***\n",
    "\n",
    "Esta tarea puede ser muy desafiante ya que necesitamos clasificar textos que no han sido etiquetados. Este es un escenario común en proyectos del mundo real porque anotar texto suele ser un proceso que consume mucho tiempo y requiere experiencia en el dominio. Para este caso de uso, el *pipeline* de clasificación *zero-shot* es muy útil: te permite especificar qué etiquetas usar para la clasificación, por lo que no tienes que depender de las etiquetas del modelo preentrenado. Ya has visto cómo el modelo puede clasificar una oración como positiva o negativa, pero también puede clasificar el texto usando cualquier otro conjunto de etiquetas que consideres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library in Natural Language Processing',\n",
       " 'labels': ['artificial intelligence', 'education', 'business', 'politics'],\n",
       " 'scores': [0.5782651901245117,\n",
       "  0.3659741282463074,\n",
       "  0.040319617837667465,\n",
       "  0.015441046096384525]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library in Natural Language Processing\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\", \"artificial intelligence\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reconocimiento de entidades nombradas**\n",
    "\n",
    "El reconocimiento de entidades nombradas (NER) es una tarea donde el modelo tiene que encontrar qué partes del texto de entrada corresponden a entidades como personas, ubicaciones u organizaciones. Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cayetano/Propio/Notebooks/Machine Learning/RL/env/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9991522,\n",
       "  'word': 'Juan Pérez',\n",
       "  'start': 11,\n",
       "  'end': 21},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.80377835,\n",
       "  'word': 'University of Las Palmas',\n",
       "  'start': 40,\n",
       "  'end': 64},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.7861865,\n",
       "  'word': 'of Gran Canaria',\n",
       "  'start': 65,\n",
       "  'end': 80},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9997646,\n",
       "  'word': 'Spain',\n",
       "  'start': 84,\n",
       "  'end': 89}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Juan Pérez and I work at the University of Las Palmas of Gran Canaria in Spain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preguntas y respuestas**\n",
    "\n",
    "El *pipeline* de preguntas y respuestas responde preguntas utilizando información de un contexto dado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9590848684310913,\n",
       " 'start': 0,\n",
       " 'end': 26,\n",
       " 'answer': 'Juan Pérez and María Pérez'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Who work at the University of Las Palmas of Gran Canaria?\",\n",
    "    context=\"Juan Pérez and María Pérez work at the University of Las Palmas of Gran Canaria in Spain. They are colleagues. María Pérez is 32 years old and Juan Pérez is 45.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resúmenes**\n",
    "\n",
    "El resumen es la tarea de reducir un texto a un texto más corto mientras se mantienen todos (o la mayoría) de los aspectos importantes mencionados en el texto. Aquí hay un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae178c74648d45c2934b3ab97097a6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b6ef20af0c49f283cc557de744061d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1aadbf621f4a5792f67b571590ac0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c82086ab7f64e87a0264a070879bfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ad18e5ae1946dabf5aca0b014733da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Speech to text**\n",
    "\n",
    "Conversión del habla en texto escrito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': ' Bueno, esto es solamente una prueba a ver qué tal funciona el traductor de... bueno, no es un traductor realmente, es recoger el audio del ordenador y traducirlo a texto. Vamos a ver qué tal.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "t2s = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\")\n",
    "t2s(\"/Users/cayetano/Desktop/ScreenFlow.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
