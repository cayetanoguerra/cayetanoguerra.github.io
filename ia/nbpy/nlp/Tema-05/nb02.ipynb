{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **Modelos del lenguaje basados en redes neuronales artificiales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Redes neuronales recurrentes (RNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una **RNN** es un tipo de red neuronal diseñada para reconocer patrones en secuencias de datos, como series temporales o textos. Se caracterizan por tener conexiones que retroceden en la estructura de la red, lo que les permite mantener información de estados anteriores en la secuencia.\n",
    "\n",
    "#### **Definición formal:**\n",
    "\n",
    "- $ x_t $: Entrada en el paso de tiempo $ t $.\n",
    "- $ h_t $: Estado oculto en el paso de tiempo $ t $. Es la \"memoria\" de la RNN, que guarda información sobre los pasos anteriores.\n",
    "\n",
    "La relación recurrente es:\n",
    "\n",
    "$$ h_t = \\sigma(W \\cdot [h_{t-1}, x_t] + b) $$\n",
    "\n",
    "Donde:\n",
    "- $ \\sigma $ es una función de activación, comúnmente la función tanh o sigmoide.\n",
    "- $ W $ es la matriz de pesos que opera sobre la concatenación del estado oculto anterior y la entrada actual.\n",
    "- $ b $ es el vector de sesgo.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"imgs/RNN.svg\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Vamos a visualizar la misma red pero desenrollada en el tiempo, es decir, como una red neuronal profunda con una capa por paso de tiempo.\n",
    "<p align=\"center\">\n",
    "<img src=\"imgs/RNNdesenrollada.svg\">\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "#### **Características:**\n",
    "\n",
    "1. **Memoria a corto plazo**: La información puede ser transmitida de un paso en el tiempo a otro a través del estado oculto $ h_t $, lo que permite a las RNNs mantener una \"memoria\" de los datos anteriores en la secuencia.\n",
    "\n",
    "2. **Desenrollado en el tiempo**: Aunque las RNNs se definen de manera recursiva, a menudo se \"desenrollan\" en el tiempo para su entrenamiento y visualización, tratándolas como una red neuronal profunda con una capa por paso de tiempo.\n",
    "\n",
    "3. **Dificultades en el entrenamiento**: Las RNNs simples tienen dificultades para mantener información a largo plazo debido a los problemas como el desvanecimiento o la explosión del gradiente. Estos problemas son abordados por variantes más avanzadas, como las LSTMs y las GRUs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
