{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **Modelos del lenguaje basados en redes neuronales artificiales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Redes neuronales recurrentes (RNN)**\n",
    "\n",
    "### **LSTM**\n",
    "\n",
    "El conjunto de datos \"AG_NEWS\" es un conjunto de datos de clasificación de texto ampliamente utilizado en el campo del procesamiento de lenguaje natural (NLP). Contiene noticias de diferentes categorías y se utiliza comúnmente para tareas de clasificación de texto. El conjunto de datos AG_NEWS consta de noticias de cuatro categorías principales, que son:\n",
    "\n",
    "1. **World**: Noticias sobre eventos y acontecimientos globales, como política internacional, relaciones internacionales y noticias mundiales en general.\n",
    "\n",
    "2. **Sports**: Noticias relacionadas con eventos deportivos, resultados de partidos, eventos deportivos nacionales e internacionales, etc.\n",
    "\n",
    "3. **Business**: Noticias relacionadas con el mundo de los negocios, finanzas, economía, empresas, informes de ganancias y otros temas económicos.\n",
    "\n",
    "4. **Sci/Tech**: Noticias relacionadas con ciencia y tecnología, incluyendo avances científicos, novedades tecnológicas, gadgets, investigaciones científicas y más.\n",
    "\n",
    "Cada instancia del conjunto de datos AG_NEWS generalmente consiste en un título y un cuerpo de una noticia, junto con una etiqueta que indica la categoría a la que pertenece. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "from torchtext.data import to_map_style_dataset\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "train_iter, test_iter = datasets.AG_NEWS(split=('train', 'test'))\n",
    "\n",
    "train_ds = to_map_style_dataset(train_iter)\n",
    "test_ds = to_map_style_dataset(test_iter)\n",
    "\n",
    "train = np.array(train_ds)\n",
    "test = np.array(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary and embedding\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "vocab = build_vocab_from_iterator(map(lambda x: tokenizer(x[1]), train_iter), specials=['<pad>','<unk>'])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 95812 tokens\n",
      "Tokenización de la frase 'Here is an example sentence': ['here', 'is', 'an', 'example', 'sentence']\n",
      "Índices de las palabras 'here', 'is', 'an', 'example', 'supercalifragilisticexpialidocious': [476, 22, 31, 5298, 1]\n",
      "Palabras correspondientes a los índices 475, 21, 30, 5297, 0: ['version', 'at', 'from', 'establish', '<pad>']\n",
      "Las diez primeras palabras del vocabulario: ['<pad>', '<unk>', '.', 'the', ',', 'to', 'a', 'of', 'in', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño del vocabulario:\", len(vocab), \"tokens\")\n",
    "print(\"Tokenización de la frase 'Here is an example sentence':\", tokenizer(\"Here is an example sentence\"))\n",
    "print(\"Índices de las palabras 'here', 'is', 'an', 'example', 'supercalifragilisticexpialidocious':\", vocab(['here', 'is', 'an', 'example', 'supercalifragilisticexpialidocious']))\n",
    "print(\"Palabras correspondientes a los índices 475, 21, 30, 5297, 0:\", vocab.lookup_tokens([475, 21, 30, 5297, 0]))\n",
    "print(\"Las diez primeras palabras del vocabulario:\", vocab.get_itos()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenización de la frase 'Here is an example sentence': [476, 22, 31, 5298, 2994]\n"
     ]
    }
   ],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "print(\"Tokenización de la frase 'Here is an example sentence':\", text_pipeline(\"Here is an example sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for sample in batch:\n",
    "        label, text = sample\n",
    "        text_list.append(torch.tensor(text_pipeline(text), dtype=torch.long))\n",
    "        label_list.append(label_pipeline(label))\n",
    "\n",
    "        \n",
    "    return torch.tensor(label_list, dtype=torch.long), torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_iter, batch_size=64, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_iter, batch_size=64, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar que estamos creando correctamente los lotes, vamos a imprimir las primeras cuatro instancias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  152,    44,    11,  1618,   483,   343,   149,    24,    74,    14,\n",
      "            32,    15,    16,     6,   669,     8,   483,    93,     9,     6,\n",
      "          1194,     8,   453,    59,  1242,    58,  1878,   361,     5,   431,\n",
      "          2777,  1272,    69,  1417,     4,    21,   202,    12,     3,   950,\n",
      "          1315,     4,     9,    68,  1015,   152,  6540,   281,     2,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [ 6090,  1510, 10335,   414,    12, 41858,   237,    14,    32,    15,\n",
      "           189,   191,  6090,  1696,  2795,    23,    48, 27190,     8,     3,\n",
      "            37,   483,  1829,   127,    57,     4,   604,    26,    96,   275,\n",
      "         16502,    55, 10335,   414,    88,     2,    30,   365,  8933,   191,\n",
      "             7,  2240,    12, 19579,    83,     8,   707,     2,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [11302,   145,  1024,     5,   466,    14,    32,    15,    32,    16,\n",
      "          8863,   300,    35,   257,  3535,   748,  1177,   257,   482,    91,\n",
      "           257,   835,  2905,     4, 47140,  6865,    27,    58,   569,   155,\n",
      "             5,   326,   337,   910,    12,   145,     8,     3,  7516,   120,\n",
      "             2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [ 8064,     5,   276,    69,   261,     4,  1565,   330,  8152,   219,\n",
      "             2,    14, 12475,    15,    34,   276,    69,   261,     4,  1565,\n",
      "           330,     9,   415,     6,   192,     7,    23,  3628,   268,     6,\n",
      "           471,   886,    21,   830,   917,   532,     9,  6054,    11, 72656,\n",
      "          1898,   560,    20, 14537,  1351,     4,     3,    55,    27,    11,\n",
      "            58,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n",
      "\n",
      "\n",
      "tensor([2, 2, 1, 2])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch[1][:4])\n",
    "    print(\"\\n\")\n",
    "    print(batch[0][:4])\n",
    "    print(\"\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMTextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class):\n",
    "        super(LSTMTextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Tomar la última salida de la secuencia LSTM\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        output = self.fc(last_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  203,    85,  1644,  1605,    29,  1480,    24,    74,    14,    28,\n",
      "            15,    16,   203,    65,     2,    27,    11,    57,    18,     3,\n",
      "          1605,    29,  1480,    12,    23,  1385,   385,   727,     2,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  754, 19257, 18337,    39,    17,  2675,   136, 13709,    17,   352,\n",
      "            14,    28,    15,    16,     8,    62,     7,     3,   144,  8149,\n",
      "         21035,     5, 10132,    21,     3,   352,   754,     4,     3,   425,\n",
      "           510,    17,    10,   631,  7911,  1485,    80, 18337,    11,    58,\n",
      "            12,  9978,     8,     5,  2675,   136, 13709,     2,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 5060,    13,    10, 28480,  2172,   314,   146,     5,   110, 25803,\n",
      "           277,  5060,    13,    10,  2222, 28480,   193,     3, 25803,    19,\n",
      "            31, 21424,  7328,     7, 25181,  3382,     4,   442,  6282,    14,\n",
      "          2381,     2,  7938,  3440,    15,    11,    56,     4,  1323,     3,\n",
      "           354,    49,   277, 19075,     2,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 2206,     4,  8035,  1658,     8,  1284,  5530,   352,     4,  1148,\n",
      "            16,   579,  2206,   444,  1351,     7,  1852,    12,     3,   314,\n",
      "          8243,  5530,  2588,    92,     4,     9,   892,   327,    60,    50,\n",
      "            87,    82,  1121,     5,     3,   176,   112,    12,     3,  2435,\n",
      "            17,    10,  1565,  5530,  3761,   217,     2,  2206,    17,   920,\n",
      "          4487,  8035,     9, 18271,  2129, 10498, 17318,     9,  4329, 24249,\n",
      "         14464,    80,  1908,    73,     3,  4036,     8,     3,  1284,   379,\n",
      "         14564,     2,     2,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "tensor([[ 0.1983,  0.0697, -0.0783,  0.0542],\n",
      "        [ 0.1983,  0.0697, -0.0783,  0.0542],\n",
      "        [ 0.1983,  0.0697, -0.0783,  0.0542],\n",
      "        [ 0.1983,  0.0697, -0.0783,  0.0542]], grad_fn=<SliceBackward0>)\n",
      "tensor([2, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMTextClassificationModel(len(vocab), 32, 64, 4).to(device)\n",
    "model.train()\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    predicted_label = model(batch[1])\n",
    "    label = batch[0]\n",
    "    break\n",
    "\n",
    "print(batch[1][:4])\n",
    "print(predicted_label[:4])\n",
    "print(label[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10  # epoch\n",
    "LR = 5  # learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count, max_acc = 0, 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            #print(total_acc / total_count)\n",
    "\n",
    "            print('| {:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(idx, total_acc / total_count))\n",
    "\n",
    "            if max_acc < total_acc / total_count:\n",
    "                max_acc = total_acc / total_count\n",
    "                \n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "    return max_acc\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   500 batches | accuracy    0.254\n",
      "|  1000 batches | accuracy    0.256\n",
      "|  1500 batches | accuracy    0.257\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 59.81s | valid accuracy    0.252 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.259\n",
      "|  1000 batches | accuracy    0.256\n",
      "|  1500 batches | accuracy    0.255\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 60.92s | valid accuracy    0.253 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.352\n",
      "|  1000 batches | accuracy    0.464\n",
      "|  1500 batches | accuracy    0.532\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 61.16s | valid accuracy    0.567 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.588\n",
      "|  1000 batches | accuracy    0.671\n",
      "|  1500 batches | accuracy    0.741\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 61.33s | valid accuracy    0.759 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.781\n",
      "|  1000 batches | accuracy    0.812\n",
      "|  1500 batches | accuracy    0.833\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 61.38s | valid accuracy    0.822 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.838\n",
      "|  1000 batches | accuracy    0.852\n",
      "|  1500 batches | accuracy    0.867\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 61.69s | valid accuracy    0.848 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.861\n",
      "|  1000 batches | accuracy    0.874\n",
      "|  1500 batches | accuracy    0.886\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 61.59s | valid accuracy    0.856 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.875\n",
      "|  1000 batches | accuracy    0.889\n",
      "|  1500 batches | accuracy    0.899\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 61.54s | valid accuracy    0.873 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.889\n",
      "|  1000 batches | accuracy    0.900\n",
      "|  1500 batches | accuracy    0.911\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 61.79s | valid accuracy    0.877 \n",
      "-----------------------------------------------------------\n",
      "|   500 batches | accuracy    0.900\n",
      "|  1000 batches | accuracy    0.908\n",
      "|  1500 batches | accuracy    0.919\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 61.90s | valid accuracy    0.874 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10  # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64  # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    accu_train = train(train_dataloader)\n",
    "    accu_val = evaluate(test_dataloader)\n",
    "\n",
    "    #if accu_train > accu_val:\n",
    "    #    scheduler.step()\n",
    "    \n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ejercicio 1\n",
    "\n",
    "Modifica el código anterior para adaptar el modelo LSTM al uso de *embeddings* preentrenados. Para ello, usa <code>from torchtext.vocab import GloVe</code> y elige el conjunto de *embeddings* GloVe que prefieras. Puedes encontrar más información en https://pytorch.org/text/stable/vocab.html#torchtext.vocab.GloVe\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
