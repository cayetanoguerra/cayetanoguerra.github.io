{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **Modelos del lenguaje basados en redes neuronales artificiales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Redes neuronales recurrentes (RNN)**\n",
    "\n",
    "### **Seq2seq**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import torch\n",
    "\n",
    "allowed_chars = string.digits + '+'\n",
    "\n",
    "class Generator():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # Método para crear un ejemplo de entrenamiento\n",
    "    def sample(self):\n",
    "        s1 = random.randint(0, 999)\n",
    "        s2 = random.randint(0, 999)\n",
    "        r = s1 + s2\n",
    "        s1_string = str(s1).zfill(3)\n",
    "        s2_string = str(s2).zfill(3)\n",
    "        output = str(r).zfill(4)\n",
    "        input = s1_string + \"+\" + s2_string\n",
    "        return input, output\n",
    "    \n",
    "    # Método para crear un lote de ejemplos de entrenamiento\n",
    "    def batch(self, n):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for _ in range(n):\n",
    "            input, output = self.sample()\n",
    "            inputs.append(input)\n",
    "            outputs.append(output)\n",
    "        return inputs, outputs\n",
    "    \n",
    "    # Método para codificar una cadena de caracteres en un tensor one-hot\n",
    "    def string_to_tensor(self, s):\n",
    "        tensor = torch.zeros(len(s), len(allowed_chars))\n",
    "        for i, char in enumerate(s):\n",
    "            tensor[i, allowed_chars.index(char)] = 1\n",
    "        return tensor\n",
    "\n",
    "    # Método para decodificar un tensor one-hot en una cadena de caracteres\n",
    "    def tensor_to_string(self, tensor):\n",
    "        _, max_idx = tensor.max(1)\n",
    "        return ''.join([allowed_chars[i] for i in max_idx])\n",
    "    \n",
    "    # Método para generar un lote de ejemplos de entrenamiento codificados\n",
    "    def batch_to_tensor(self, n):\n",
    "        seq_in = []\n",
    "        seq_out = []\n",
    "        inputs, outputs = self.batch(n)\n",
    "        # print(inputs, outputs)\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            seq_in.append(self.string_to_tensor(input))\n",
    "            seq_out.append(self.string_to_tensor(output))\n",
    "        return torch.stack(seq_in), torch.stack(seq_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Definir la arquitectura del modelo seq2seq\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        out_enc, (hn_enc, cn_enc) = self.encoder(input, hidden)\n",
    "        \n",
    "        latent_tensor = hn_enc[0].unsqueeze(1).repeat(1, 4, 1)\n",
    "        # print(latent_tensor.shape)\n",
    "\n",
    "        out_dec, (hn_dec, cn_dec) = self.decoder(latent_tensor, (hn_enc, cn_enc))\n",
    "        out = F.softmax(self.output(out_dec), dim=2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = Seq2Seq(input_size=len(allowed_chars), hidden_size=128, output_size=len(allowed_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.08257734030485153\n",
      "Epoch: 100, Loss: 0.06488753110170364\n",
      "Epoch: 200, Loss: 0.04948587715625763\n",
      "Epoch: 300, Loss: 0.04897153005003929\n",
      "Epoch: 400, Loss: 0.04792485386133194\n",
      "Epoch: 500, Loss: 0.04817119613289833\n",
      "Epoch: 600, Loss: 0.0436558872461319\n",
      "Epoch: 700, Loss: 0.04369232431054115\n",
      "Epoch: 800, Loss: 0.04253627359867096\n",
      "Epoch: 900, Loss: 0.04441256821155548\n",
      "Epoch: 1000, Loss: 0.045851930975914\n",
      "Epoch: 1100, Loss: 0.04189189523458481\n",
      "Epoch: 1200, Loss: 0.04303479939699173\n",
      "Epoch: 1300, Loss: 0.04052378237247467\n",
      "Epoch: 1400, Loss: 0.04200179502367973\n",
      "Epoch: 1500, Loss: 0.04290764033794403\n",
      "Epoch: 1600, Loss: 0.036842744797468185\n",
      "Epoch: 1700, Loss: 0.03484726324677467\n",
      "Epoch: 1800, Loss: 0.034859251230955124\n",
      "Epoch: 1900, Loss: 0.03147902712225914\n",
      "Epoch: 2000, Loss: 0.032323453575372696\n",
      "Epoch: 2100, Loss: 0.029674706980586052\n",
      "Epoch: 2200, Loss: 0.02693380042910576\n",
      "Epoch: 2300, Loss: 0.02868812158703804\n",
      "Epoch: 2400, Loss: 0.027323616668581963\n",
      "Epoch: 2500, Loss: 0.026440024375915527\n",
      "Epoch: 2600, Loss: 0.02916288562119007\n",
      "Epoch: 2700, Loss: 0.027077270671725273\n",
      "Epoch: 2800, Loss: 0.02564370073378086\n",
      "Epoch: 2900, Loss: 0.026506004855036736\n",
      "Epoch: 3000, Loss: 0.024377422407269478\n",
      "Epoch: 3100, Loss: 0.02658388763666153\n",
      "Epoch: 3200, Loss: 0.02441558800637722\n",
      "Epoch: 3300, Loss: 0.0234074704349041\n",
      "Epoch: 3400, Loss: 0.022027354687452316\n",
      "Epoch: 3500, Loss: 0.017265262082219124\n",
      "Epoch: 3600, Loss: 0.010643445886671543\n",
      "Epoch: 3700, Loss: 0.006523265969008207\n",
      "Epoch: 3800, Loss: 0.004496955778449774\n",
      "Epoch: 3900, Loss: 0.0024002285208553076\n",
      "Epoch: 4000, Loss: 0.0010335325496271253\n",
      "Epoch: 4100, Loss: 0.0008587779593653977\n",
      "Epoch: 4200, Loss: 0.0016859647585079074\n",
      "Epoch: 4300, Loss: 0.0003824773302767426\n",
      "Epoch: 4400, Loss: 0.00046783534344285727\n",
      "Epoch: 4500, Loss: 0.0005616018897853792\n",
      "Epoch: 4600, Loss: 0.0010908952681347728\n",
      "Epoch: 4700, Loss: 0.0013079564087092876\n",
      "Epoch: 4800, Loss: 0.0004449590342119336\n",
      "Epoch: 4900, Loss: 0.0005664007039740682\n"
     ]
    }
   ],
   "source": [
    "# Bucle de entrenamiento\n",
    "def train(model, optimizer, loss_fn, n_epochs, batch_size):\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        x, y = dg.batch_to_tensor(batch_size)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # Print the loss every 10 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss))\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Entrenar el modelo\n",
    "dg = Generator()\n",
    "train(model, optimizer, loss_fn, 5000, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549+666 1215 1215\n",
      "486+380 0866 0866\n",
      "190+960 1150 1150\n",
      "563+508 1071 1071\n",
      "954+089 1043 1043\n",
      "582+751 1333 1333\n",
      "075+027 0502 0102\n",
      "376+499 0875 0875\n",
      "884+665 1549 1549\n",
      "677+614 1291 1291\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "def evaluate(model, n):\n",
    "    x, y = dg.batch_to_tensor(n)\n",
    "    y_pred = model(x)\n",
    "    for i in range(n):\n",
    "        print(dg.tensor_to_string(x[i]), dg.tensor_to_string(y_pred[i]), dg.tensor_to_string(y[i]))\n",
    "\n",
    "evaluate(model, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
