{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<img src=\"../imgs/EII-ULPGC-logo.jpeg\" width=\"430px\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NOTEBOOK 8.1**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function Calling**\n",
    "\n",
    "Las function calling son una capacidad de los modelos de lenguaje que les permite identificar cuándo una consulta del usuario requiere ejecutar una función externa, generar automáticamente los argumentos estructurados para esa función y devolverlos en un formato que el modelo los pueda interpretar. De este modo, el modelo no solo produce texto, sino que actúa como un orquestador: decide si usar una herramienta, construye los parámetros adecuados y permite que el sistema ejecute la función real (por ejemplo, consultar una API, acceder a una base de datos o realizar un cálculo), integrando después el resultado en la conversación.\n",
    "\n",
    "https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"imgs/function-calling-diagram-steps.png\" width=\"500px\">\n",
    "</div>\n",
    "  \n",
    "### **Ejemplo básico de Function Calling con la API de OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final input:\n",
      "[{'role': 'user', 'content': 'What is my horoscope? I am an Aquarius.'}, ResponseReasoningItem(id='rs_05de88ec025a636800691f8fdf650881a08d4d0b8860b9d6b0', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseFunctionToolCall(arguments='{\"sign\":\"Aquarius\"}', call_id='call_TeW9yCYRkLnuU47ATHljEum9', name='get_horoscope', type='function_call', id='fc_05de88ec025a636800691f8fe39a8c81a081a526c55d7d4090', status='completed'), {'type': 'function_call_output', 'call_id': 'call_TeW9yCYRkLnuU47ATHljEum9', 'output': '{\"horoscope\": \"{\\'sign\\': \\'Aquarius\\'}: Next Tuesday you will befriend a baby otter.\"}'}]\n",
      "Final output:\n",
      "{\n",
      "  \"id\": \"resp_05de88ec025a636800691f8fe474f481a0bcaf7bce6da9d25e\",\n",
      "  \"created_at\": 1763676132.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"Respond only with a horoscope generated by a tool.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-2025-08-07\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_05de88ec025a636800691f8fe4eb7481a08df3d2a096e390b8\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"content\": null,\n",
      "      \"encrypted_content\": null,\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_05de88ec025a636800691f8fe7695481a0a921a4611dc58125\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"{'sign': 'Aquarius'}: Next Tuesday you will befriend a baby otter.\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_horoscope\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"sign\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"An astrological sign like Taurus or Aquarius\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"sign\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get today's horoscope for an astrological sign.\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"prompt_cache_retention\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 279,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 153,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 128\n",
      "    },\n",
      "    \"total_tokens\": 432\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"store\": true\n",
      "}\n",
      "\n",
      "{'sign': 'Aquarius'}: Next Tuesday you will befriend a baby otter.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 1. Define a list of callable tools for the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_horoscope\",\n",
    "        \"description\": \"Get today's horoscope for an astrological sign.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sign\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"An astrological sign like Taurus or Aquarius\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sign\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "def get_horoscope(sign):\n",
    "    return f\"{sign}: Next Tuesday you will befriend a baby otter.\"\n",
    "\n",
    "# Create a running input list we will add to over time\n",
    "input_list = [\n",
    "    {\"role\": \"user\", \"content\": \"What is my horoscope? I am an Aquarius.\"}\n",
    "]\n",
    "\n",
    "# 2. Prompt the model with tools defined\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")\n",
    "\n",
    "# Save function call outputs for subsequent requests\n",
    "input_list += response.output\n",
    "\n",
    "for item in response.output:\n",
    "    if item.type == \"function_call\":\n",
    "        if item.name == \"get_horoscope\":\n",
    "            # 3. Execute the function logic for get_horoscope\n",
    "            horoscope = get_horoscope(json.loads(item.arguments))\n",
    "            \n",
    "            # 4. Provide function call results to the model\n",
    "            input_list.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": json.dumps({\n",
    "                  \"horoscope\": horoscope\n",
    "                })\n",
    "            })\n",
    "\n",
    "print(\"Final input:\")\n",
    "print(input_list)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    instructions=\"Respond only with a horoscope generated by a tool.\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")\n",
    "\n",
    "# 5. The model should be able to give a response!\n",
    "print(\"Final output:\")\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(\"\\n\" + response.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCP-PLN",
   "language": "python",
   "name": "mcp-pln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
