{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<img src=\"../imgs/EII-ULPGC-logo.jpeg\" width=\"430px\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NOTEBOOK 6**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Indexación y recuperación de información**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TF-IDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (en inglés \"Term Frequency – Inverse Document Frequency\") es una técnica utilizada en procesamiento de lenguaje natural (NLP) y recuperación de información (IR) para representar documentos como vectores numéricos. Está diseñada para reflejar la importancia de una palabra en un documento en relación con un conjunto de documentos o corpus.\n",
    "\n",
    "Sus dos componentes son:\n",
    "\n",
    "1. **Frecuencia de Término (TF)**:\n",
    "   - Representa la frecuencia de una palabra en un documento específico.\n",
    "   - Se calcula como el número de veces que una palabra aparece en un documento dividido por el número total de palabras en ese documento.\n",
    "   - $ \\text{TF}(t, d) = \\frac{\\text{número de veces que el término } t \\text{ aparece en el documento } d}{\\text{número total de palabras en el documento } d} $\n",
    "\n",
    "2. **Inversa de la Frecuencia del Documento (IDF)**:\n",
    "   - Mide lo común o raro que es un término en todo el corpus.\n",
    "   - Se calcula como el logaritmo natural del número total de documentos dividido por el número de documentos que contienen el término de interés.\n",
    "   - $ \\text{IDF}(t, D) = \\log \\frac{\\text{número total de documentos en el corpus } D}{\\text{número de documentos que contienen el término } t} $\n",
    "   - Este valor será mayor para palabras que son raras en el corpus y más pequeño para palabras que son comunes.\n",
    "\n",
    "El valor TF-IDF para un término en un documento es simplemente el producto de TF e IDF:\n",
    "\n",
    "$$ \\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D) $$\n",
    "\n",
    "¿Por qué es útil? Palabras como \"y\", \"de\", \"en\", etc., aparecerán con mucha frecuencia en muchos documentos (alto TF), pero no son únicas o relevantes para un documento en particular, por lo que su IDF será bajo, reduciendo su relevancia. Por otro lado, si una palabra aparece frecuentemente en un documento, pero raramente en otros documentos del corpus, tendrá un alto valor TF-IDF, indicando que es una palabra clave importante para ese documento en particular.\n",
    "\n",
    "En la práctica, TF-IDF es utilizado para tareas como la recuperación de información (por ejemplo, motores de búsqueda) y clasificación de documentos, entre otras. Permite que se pueda hacer una distinción entre los términos comunes y los términos relevantes en grandes conjuntos de datos textuales.\n",
    "\n",
    "Veamos un ejemplo de cómo calcular el valor TF-IDF para una palabra dentro de un documento en un corpus de documentos sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 0.0\n",
      "IDF: 1.0986122886681098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Ejemplo de documentos\n",
    "documents = [\n",
    "    \"El sol brilla en el cielo\",\n",
    "    \"La lluvia cae sobre la ciudad\",\n",
    "    \"El gato duerme en el sofá\"\n",
    "]\n",
    "\n",
    "# Calcular TF-IDF\n",
    "def tf_idf(term, document, documents):\n",
    "    # TF\n",
    "    words = document.split()  # Dividir el documento en palabras\n",
    "    tf = words.count(term) / len(words)  # Calcular TF\n",
    "    print(\"TF:\", tf)\n",
    "    \n",
    "    # IDF\n",
    "    n_documents_with_term = 0  # Contador de documentos con el término\n",
    "    for document in documents:\n",
    "        words = document.split()  # Dividir el documento en palabras\n",
    "        if term in words:  # Si el término está en el documento\n",
    "            n_documents_with_term += 1  # Incrementar el contador\n",
    "    if n_documents_with_term != 0:\n",
    "        idf = math.log(len(documents) / n_documents_with_term)  # Calcular IDF\n",
    "    else:\n",
    "        idf = 0\n",
    "    print(\"IDF:\", idf)\n",
    "\n",
    "    # TF-IDF\n",
    "    tf_idf = tf * idf  # Calcular TF-IDF\n",
    "\n",
    "    return tf_idf\n",
    "        \n",
    "tf_idf(\"gato\", documents[1], documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PageRank**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PageRank es un algoritmo de clasificación de páginas web que fue introducido por Larry Page y Sergey Brin, los cofundadores de Google, mientras estaban en la Universidad de Stanford. Se convirtió en la base de la tecnología de búsqueda inicial de Google y representa uno de los primeros esfuerzos efectivos para clasificar y ordenar páginas web basadas en su importancia y relevancia, más allá de solo coincidencias de palabras clave.\n",
    "\n",
    "El principio detrás de PageRank es que la importancia de una página web puede ser determinada por las páginas que enlazan a ella.\n",
    "\n",
    "Vemos el concepto básico y cómo funciona:\n",
    "\n",
    "1. **Modelo de Navegación Aleatoria**:\n",
    "   PageRank se basa en la idea de un \"navegante aleatorio\". Imagina que un usuario comienza en una página web y selecciona aleatoriamente enlaces para saltar a otras páginas. Eventualmente, este usuario visitaría más a menudo algunas páginas que otras, basado en la cantidad y calidad de los enlaces a esas páginas. PageRank intenta modelar esta probabilidad.\n",
    "\n",
    "2. **Enlaces como Votos**:\n",
    "   Cada enlace de una página \\(A\\) a una página \\(B\\) se considera como un \"voto\" de \\(A\\) a \\(B\\). Sin embargo, no todos los votos tienen el mismo peso. Los votos de sitios que son ellos mismos \"importantes\" tienen más peso y contribuyen más a la clasificación de las páginas enlazadas.\n",
    "\n",
    "3. **Fórmula Básica**:\n",
    "   La fórmula básica para el PageRank de una página \\(P\\) es:\n",
    "   $$ PR(P) = \\frac{1-d}{N} + d \\sum_{i=1}^{n} \\frac{PR(P_i)}{L(P_i)} $$\n",
    "   - $ PR(P) $ es el PageRank de la página $ P $.\n",
    "   - $ d $ es un factor de amortiguación, generalmente establecido en alrededor de 0.85.\n",
    "   - $ N $ es el número total de páginas.\n",
    "   - $ P_i $ son las páginas que enlazan a $ P $.\n",
    "   - La suma se realiza sobre las páginas $ P_i $ que enlazan a $ P $.\n",
    "   - $ L(P_i) $ es el número de enlaces salientes de la página $ P_i $.\n",
    "\n",
    "4. **Iteración**:\n",
    "   El algoritmo se inicia asignando a cada página un PageRank inicial, a menudo $ 1/N $ donde $ N $ es el número total de páginas. Luego, se aplica repetidamente la fórmula de PageRank a través de múltiples iteraciones hasta que los valores de PageRank converjan (es decir, no cambien significativamente entre iteraciones).\n",
    "\n",
    "5. **Teletransportación**:\n",
    "   El término $ \\frac{1-d}{N} $ en la fórmula anterior representa la probabilidad de que el \"navegante aleatorio\" salte a una página al azar en lugar de seguir un enlace. Esto ayuda a asegurar que todas las páginas tengan un PageRank mínimo y soluciona el problema de \"callejones sin salida\" (páginas sin enlaces salientes).\n",
    "\n",
    "6. **Manipulaciones y Evolución**:\n",
    "   Dado que PageRank jugó un papel importante en la clasificación de resultados de búsqueda, hubo muchos intentos para manipular los rankings (por ejemplo, creando granjas de enlaces). Google ha implementado muchas actualizaciones y modificaciones para combatir el spam y asegurar resultados de calidad. Si bien PageRank es solo uno de los muchos algoritmos y señales que Google utiliza ahora, su introducción marcó un punto de inflexión en la búsqueda en la web. \n",
    "\n",
    "Es importante señalar que, aunque la idea central de PageRank es simple, en la práctica, implementar y escalar el algoritmo para la vasta web es un desafío técnico considerable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
