<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Cayetanoguerra.GitHub.io : Cayetano Guerra">

    <link rel="stylesheet" type="text/css" media="screen" href="../stylesheets/stylesheet.css">

    <title>Cayetanoguerra.GitHub.io</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title">Inteligencia Artificial</h1>
          <h2 id="project_tagline">Universidad de Las Palmas de Gran Canaria</h2>

        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
   
   
<h3>
Python
</h3>    
<p>Python será nuestro lenguaje en esta asigntura. Es un lenguaje que sigue el paradigma imperativo, es de sintaxis sencilla y legible, interpretado, multiplataforma y de tipado dinámico. Si tienes Linux o Mac OS ya lo tienes por defecto en tu ordenador. Si usas Windows puedes descargarlo desde <a href="https://www.python.org/">www.python.org</a>. Hay muchos libros y tutoriales en Internet para aprender Python, <a href="http://mundogeek.net/tutorial-python/">éste</a> está muy bien.</p>

<p>
Como editor de código usaremos <a href="https://www.jetbrains.com/pycharm/">PyCharm</a>. 
</p>
    
<hr>

<h3>
Redes neuronales
</h3>    
<p>Las <a href="https://es.wikipedia.org/wiki/Red_neuronal_artificial">redes neuronales artificiales</a> son un paradigma de aprendizaje y procesamiento automático inspirado en la forma en que funciona el sistema nervioso biológico. Se trata de un sistema de interconexión de neuronas que colaboran entre sí para producir un estímulo de salida.
    
    
<h4>Prácticas</h4>
<ul>
<li><a href="./nn/Ejercicio_RN.pdf">Cálculo manual de una red neuronal.</a></li>
<li><a href="http://nbviewer.jupyter.org/url/cayetanoguerra.github.io/ia/nbpy/learning-perceptron.ipynb">Algoritmo de aprendizaje del perceptrón en Python.</a></li>
</ul> 
    
<h4>Referencias</h4>

<ul>
<li><a href="http://blog.manfredas.com/backpropagation-tutorial/">Backpropagation Tutorial</a></li>

<li><a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/">A Step by Step Backpropagation Example</a></li>

<li><a href="http://neuralnetworksanddeeplearning.com/chap2.html">How the backpropagation algorithm works</a></li>
</ul>
    
    
<hr> 
    
<h3>
Aprendizaje por refuerzo
</h3>    
<p>El <a href="https://es.wikipedia.org/wiki/Aprendizaje_por_refuerzo">aprendizaje por refuerzo</a> es un área del aprendizaje automático inspirada en la psicología conductista, cuya ocupación es determinar qué acciones debe escoger un agente en un entorno dado con el fin de maximizar alguna noción de "recompensa" o premio acumulado.</p>

<h4>Apuntes</h4>

<a href="rl/Aprendizaje_por_refuerzo_apuntes.pdf">Transparencias de la asignatura</a>

<h4>Prácticas</h4>
<ul>
<li><a href="http://nbviewer.jupyter.org/url/cayetanoguerra.github.io/ia/nbpy/qlbasic.ipynb">Q-Learning básico</a></li>

<li><a href="http://nbviewer.jupyter.org/url/cayetanoguerra.github.io/ia/nbpy/Reinforcement-Learning-CEM.ipynb">Cart pole (CEM)</a></li>
</ul>

<h4>Referencias</h4>

<ul>
<li><a href="http://mnemstudio.org/path-finding-q-learning-tutorial.htm">A Painless Q-Learning Tutorial</a></li>

<li><a href="https://webdocs.cs.ualberta.ca/~sutton/book/bookdraft2016sep.pdf">Sutton & Barto Book - Reinforcement Learning: An Introduction</a></li>

<li><a href="http://cs.stanford.edu/people/karpathy/reinforcejs/index.html">REINFORCEjs</a> is a Reinforcement Learning library that implements several common RL algorithms supported with fun web demos</li>

<li><a href="http://karpathy.github.io/2016/05/31/rl/">Deep Reinforcement Learning: Pong from Pixels</a></li>

<li><a href="https://gym.openai.com">OpenAI Gym</a> A toolkit for developing and comparing reinforcement learning algorithms. It supports teaching agents everything from walking to playing games like Pong or Go.</li>
</ul>

<hr>

<h3>
    Sistemas basados en reglas
</h3>

<p>Los <a href="https://es.wikipedia.org/wiki/Sistema_basado_en_reglas">sistemas basados en reglas</a> trabajan mediante la aplicación de reglas, comparación de resultados y aplicación de las nuevas reglas basadas en situación modificada. También pueden trabajar por inferencia lógica dirigida, bien empezando con una evidencia inicial en una determinada situación y dirigiéndose hacia la obtención de una solución, o bien con hipótesis sobre las posibles soluciones y volviendo hacia atrás para encontrar una evidencia existente (o una deducción de una evidencia existente) que apoye una hipótesis en particular.</p>

<h4>Apuntes</h4>

<a href="sbr/CLIPS_I-Tutorial.pdf">Transparencias de la asignatura</a>

<h4>Práctica</h4>

<p>Entorno de desarrollo <a href="http://clipsrules.sourceforge.net/">CLIPS</a>.</p>

<p><a href="http://www.swi-prolog.org/">Prolog</a>.</p>


      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
