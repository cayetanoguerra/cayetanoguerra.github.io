{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/logo-spegc.svg\" width=30%>\n",
    "\n",
    "# Sistemas de recomendación\n",
    "\n",
    "Los algoritmos de machine learning en los sistemas de recomendación se clasifican generalmente en dos categorías: los **métodos basados en contenido** y los **métodos de filtrado colaborativo**, aunque los recomendadores modernos combinan ambos enfoques.\n",
    "\n",
    "Los métodos basados en el contenido hacen uso de la similitud de los atributos de los elementos vistos por el usuario anteriormente para recomendar unos parecidos. Los métodos de colaborativos calculan la similitud entre usuarios para recomendar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas basados en contenidos\n",
    "\n",
    "Se recomiendan contenidos similares a los que el usuario ha consumido anteriormente. Pero, ¿cómo saber la similitud que existe entre dos productos? Supongamos una base de datos de películas. Estas tienen género, año, director, actores... y demás propiedades que pueden conformar un vector de caraterísticas. Por tanto, sería posible establecer métricas. Entre ellas podemos tener:\n",
    "\n",
    "#### Distancia euclídea\n",
    "\n",
    "$$ similitud(\\textbf{a},\\textbf{b}) = \\sqrt{\\sum_i {(a_i - b_i)^2}}$$\n",
    "\n",
    "\n",
    "#### Coseno del ángulo\n",
    "\n",
    "$$ similitud(\\textbf{a},\\textbf{b}) = cos(\\theta) = \\frac {\\textbf{a} \\cdot \\textbf{b}}{  \\left\\| \\textbf{a} \\right\\| \\cdot \\left\\| \\textbf{b} \\right\\|    }$$\n",
    "\n",
    "Es relativamente fácil establecer similitudes entre vectores de características, pero ¿cómo hallar, por ejemplo, similitudes entre descripciones textuales de un artículo? \n",
    "\n",
    "### TF-IDF\n",
    "\n",
    "Tf-idf (del inglés Term frequency – Inverse document frequency), **frecuencia de término – frecuencia inversa de documento** (o sea, la frecuencia de ocurrencia del término en la colección de documentos), es una medida numérica que expresa cuán relevante es una palabra para un documento en una colección.\n",
    "\n",
    "Para la **frecuencia de término** $tf(t, d)$, la opción más sencilla es usar la frecuencia bruta del término $t$ en el documento $d$, o sea, el número de veces que el término $t$ ocurre en el documento $d$, aunque hay variantes, como la frecuencia de término normalizada.\n",
    "\n",
    "$${\\displaystyle \\mathrm {tf} (t,d)={\\frac {\\mathrm {f} (t,d)}{\\max\\{\\mathrm {f} (t,d):t\\in d\\}}}}$$\n",
    "\n",
    "La **frecuencia inversa de documento** es una medida de si el término es común o no, en la colección de documentos. Se obtiene dividiendo el número total de documentos por el número de documentos que contienen el término, y se toma el logaritmo de ese cociente:\n",
    "\n",
    "$${\\displaystyle \\mathrm {idf} (t,D)=\\log {\\frac {|D|}{|\\{d\\in D:t\\in d\\}|}}}$$\n",
    "\n",
    "El índice **tf-idf** se calcula como el producto de los dos factores anteriores.\n",
    "\n",
    "$${\\displaystyle \\mathrm {tfidf} (t,d,D)=\\mathrm {tf} (t,d)\\times \\mathrm {idf} (t,D)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "  (0, 8)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 1)\t0.46979138557992045\n",
      "  (1, 8)\t0.281088674033753\n",
      "  (1, 3)\t0.281088674033753\n",
      "  (1, 6)\t0.281088674033753\n",
      "  (1, 1)\t0.6876235979836938\n",
      "  (1, 5)\t0.5386476208856763\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (2, 3)\t0.267103787642168\n",
      "  (2, 6)\t0.267103787642168\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 7)\t0.511848512707169\n",
      "  (2, 4)\t0.511848512707169\n",
      "  (3, 8)\t0.38408524091481483\n",
      "  (3, 3)\t0.38408524091481483\n",
      "  (3, 6)\t0.38408524091481483\n",
      "  (3, 2)\t0.5802858236844359\n",
      "  (3, 1)\t0.46979138557992045\n",
      "(4, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud basada descripciones textuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el fichero de metadatos de las películas, de donde extraeremos sus sinopsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "md = pd.read_csv('data/the-movies-dataset/movies_metadata.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el fichero de tags y nos quedamos solo con las películas que tienen tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movieId' 'imdbId' 'tmdbId']\n",
      "Tenemos 9099 películas y 24 variables.\n"
     ]
    }
   ],
   "source": [
    "links_small = pd.read_csv('data/the-movies-dataset/links_small.csv')\n",
    "print(links_small.columns.values)\n",
    "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int') # Tags \n",
    "\n",
    "md = md.drop([19730, 29503, 35587]) # We have to remove several rows without id\n",
    "\n",
    "md['id'] = md['id'].astype('int')\n",
    "smd = md[md['id'].isin(links_small)] # We'll work only with a subset of rows, just for the sake of speed\n",
    "#smd = md\n",
    "print(\"Tenemos \" + str(smd.shape[0]) + \" películas y \" + str(smd.shape[1]) + \" variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos 'overwiew' y 'tagline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smd['tagline'] = smd['tagline'].fillna('')\n",
    "smd['description'] = smd['overview'] + smd['tagline']\n",
    "smd['description'] = smd['description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friends are the people who let you be yourself... and never let you forget it.\n"
     ]
    }
   ],
   "source": [
    "print(smd['tagline'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(smd['description'])\n",
    "\n",
    "print(tfidf_matrix.shape)\n",
    "\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "print(cosine_sim[:5,:5])\n",
    "print(cosine_sim.shape)\n",
    "\n",
    "smd = smd.reset_index()\n",
    "titles = smd['title']\n",
    "indices = pd.Series(smd.index, index=smd['title'])\n",
    "\n",
    "\n",
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos nuestro recomendador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8431                  The Hobbit: The Desolation of Smaug\n",
       "8188                    The Hobbit: An Unexpected Journey\n",
       "8723            The Hobbit: The Battle of the Five Armies\n",
       "3865    The Lord of the Rings: The Fellowship of the Ring\n",
       "8016                                        Mirror Mirror\n",
       "3896                                         Dragonslayer\n",
       "5135                                 The Ten Commandments\n",
       "4993                                            Foul Play\n",
       "7809                                        Your Highness\n",
       "737                                      The Wizard of Oz\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Hobbit').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas colaborativos\n",
    "\n",
    "Computan la similitud entre usuarios. Por ejemplo, si vamos a recomendar un grupo musical al usuario U, buscaremos sus $k$ vecinos más próximos y, de los grupos que les hayan gustado a esos $k$ vecinos, recomendaremos los que U aún no haya escuchado.\n",
    "\n",
    "|           | Pink Floyd | The Who | U2 | Aerosmith | Manu Carrasco | Bisbal | Miles Davis | John Coltrane |   |   |\n",
    "|-----------|------------|---------|----|-----------|---------------|--------|-------------|---------------|---|---|\n",
    "| Usuario 1 | 1          | 1       | 0  | 1         | 0             | 0      | 0           | 0             |   |   |\n",
    "| Usuario 2 | 0          | 0       | 0  | 0         | 1             | 1      | 0           | 0             |   |   |\n",
    "| Usuario 3 | 1          | 0       | 1  | 1         | 0             | 0      | 0           | 1             |   |   |\n",
    "\n",
    "El algoritmo más simple calcula la similitud de coseno o correlación de filas (usuarios) y recomienda elementos que hayan gustado a los $k$ vecinos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de filtrado colaborativo\n",
    "\n",
    "Tenemos un conjunto de usuarios y valoraciones que hacen esos usuarios sobre películas que han visto. Lo expresamos en forma de diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A dictionary of movie critics and their ratings of a small\n",
    "# set of movies\n",
    "\n",
    "critics={'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5,\n",
    "'Just My Luck': 3.0, 'Superman Returns': 3.5, 'You, Me and Dupree': 2.5,\n",
    "'The Night Listener': 3.0},\n",
    "         \n",
    "'Gene Seymour': {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5,\n",
    "'Just My Luck': 1.5, 'Superman Returns': 5.0, 'The Night Listener': 3.0,\n",
    "'You, Me and Dupree': 3.5},\n",
    "         \n",
    "'Michael Phillips': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.0,\n",
    "'Superman Returns': 3.5, 'The Night Listener': 4.0},\n",
    "         \n",
    "'Claudia Puig': {'Snakes on a Plane': 3.5, 'Just My Luck': 3.0,\n",
    "'The Night Listener': 4.5, 'Superman Returns': 4.0,\n",
    "'You, Me and Dupree': 2.5},\n",
    "         \n",
    "'Mick LaSalle': {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0,\n",
    "'Just My Luck': 2.0, 'Superman Returns': 3.0, 'The Night Listener': 3.0,\n",
    "'You, Me and Dupree': 2.0},\n",
    "         \n",
    "'Jack Matthews': {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0,\n",
    "'The Night Listener': 3.0, 'Superman Returns': 5.0, 'You, Me and Dupree': 3.5},\n",
    "         \n",
    "'Toby': {'Snakes on a Plane':4.5,'You, Me and Dupree':1.0,'Superman Returns':4.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando similitudes entre usuarios\n",
    "\n",
    "Tenemos principalmente dos formas de definir la similitud entre dos personas: distancia euclídea y correlación de Pearson (https://es.wikipedia.org/wiki/Coeficiente_de_correlaci%C3%B3n_de_Pearson)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distancia euclídea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14814814814814814"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a distance-based similarity score for person1 and person2\n",
    "def sim_distance(prefs,person1,person2):\n",
    "    # Get the list of shared_items\n",
    "    si={}\n",
    "    for item in prefs[person1]:\n",
    "        if item in prefs[person2]:\n",
    "            si[item]=1\n",
    "    # if they have no ratings in common, return 0\n",
    "    if len(si)==0: return 0\n",
    "    \n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares=sum([pow(prefs[person1][item]-prefs[person2][item],2)\n",
    "        for item in prefs[person1] if item in prefs[person2]])\n",
    "    return 1/(1+sum_of_squares)\n",
    "\n",
    "sim_distance(critics,'Lisa Rose','Gene Seymour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlación de Pearson\n",
    "\n",
    "Con la correlación de Pearson tratamos de evitar que la \"generosidad\" de la puntuación dada por uno y otro usuario afecte a la medida de sus gustos.\n",
    "\n",
    "$${\\displaystyle \\rho _{X,Y}={\\sigma _{XY} \\over \\sigma _{X}\\sigma _{Y}}={E[(X-\\mu _{X})(Y-\\mu _{Y})] \\over \\sigma _{X}\\sigma _{Y}},}$$\n",
    "\n",
    "- ${\\sigma _{XY}}$ es la covarianza de ${(X,Y)}$\n",
    "- ${\\sigma _{X}}$ es la desviación estándar de la variable ${X}$.\n",
    "- ${\\sigma _{Y}}$ es la desviación estándar de la variable ${Y}$.\n",
    "\n",
    "<img src=\"images/pearson.png\" width=50%>\n",
    "\n",
    "La fórmula alternativa que usaremos para calcular esta correlación será:\n",
    "\n",
    "$${\\displaystyle r_{xy}={\\frac {\\sum x_{i}y_{i}-n{\\bar {x}}{\\bar {y}}}{(n-1)s_{x}s_{y}}}={\\frac {n\\sum x_{i}y_{i}-\\sum x_{i}\\sum y_{i}}{{\\sqrt {n\\sum x_{i}^{2}-(\\sum x_{i})^{2}}}~{\\sqrt {n\\sum y_{i}^{2}-(\\sum y_{i})^{2}}}}}.}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39605901719066977\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt \n",
    "\n",
    "# Returns the Pearson correlation coefficient for p1 and p2\n",
    "def sim_pearson(prefs,p1,p2):\n",
    "    # Get the list of mutually rated items\n",
    "    si={}\n",
    "    for item in prefs[p1]:\n",
    "        if item in prefs[p2]: si[item]=1\n",
    "\n",
    "    # Find the number of elements\n",
    "    n=len(si)\n",
    "    \n",
    "    # if they are no ratings in common, return 0\n",
    "    if n==0: return 0\n",
    "\n",
    "    # Add up all the preferences\n",
    "    sum1=sum([prefs[p1][it] for it in si])\n",
    "    sum2=sum([prefs[p2][it] for it in si])\n",
    "\n",
    "    # Sum up the squares\n",
    "    sum1Sq=sum([pow(prefs[p1][it],2) for it in si])\n",
    "    sum2Sq=sum([pow(prefs[p2][it],2) for it in si])\n",
    "    \n",
    "    # Sum up the products\n",
    "    pSum=sum([prefs[p1][it]*prefs[p2][it] for it in si])\n",
    "    \n",
    "    # Calculate Pearson score\n",
    "    num=pSum-(sum1*sum2/n)\n",
    "    den=sqrt((sum1Sq-pow(sum1,2)/n)*(sum2Sq-pow(sum2,2)/n))\n",
    "    if den==0: return 0\n",
    "    r=num/den\n",
    "    return r\n",
    "\n",
    "print(sim_pearson(critics,'Lisa Rose','Gene Seymour'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos quienes son los usuarios más parecidos a Toby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9912407071619299, 'Lisa Rose'),\n",
       " (0.9244734516419049, 'Mick LaSalle'),\n",
       " (0.8934051474415647, 'Claudia Puig')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the best matches for person from the prefs dictionary.\n",
    "# Number of results and similarity function are optional params.\n",
    "def topMatches(prefs,person,n=5,similarity=sim_pearson):\n",
    "    scores=[(similarity(prefs,person,other),other) for other in prefs if other!=person]\n",
    "        \n",
    "    # Sort the list so the highest scores appear at the top\n",
    "    scores.sort( )\n",
    "    scores.reverse( )\n",
    "    return scores[0:n]\n",
    "\n",
    "topMatches(critics,'Toby',n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking items\n",
    "\n",
    "Aunque tuviéramos una persona con gustos muy parecidos a los nuestros, no deberíamos fijarnos solamente en sus recomendaciones, estaríamos muy limitados a sus gustos. Deberíamos pesar sus opiniones con los demás usuarios que pudieran recomendarme otras cosas.\n",
    "\n",
    "<img src=\"images/rank-items.png\" width=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.3477895267131017, 'The Night Listener'),\n",
       " (2.8325499182641614, 'Lady in the Water'),\n",
       " (2.530980703765565, 'Just My Luck')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets recommendations for a person by using a weighted average\n",
    "# of every other user's rankings\n",
    "def getRecommendations(prefs,person,similarity=sim_pearson):\n",
    "    totals={}\n",
    "    simSums={}\n",
    "    for other in prefs:\n",
    "        # don't compare me to myself\n",
    "        if other==person: continue\n",
    "        sim=similarity(prefs,person,other)\n",
    "        \n",
    "        # ignore scores of zero or lower\n",
    "        if sim<=0: continue\n",
    "        for item in prefs[other]:\n",
    "        \n",
    "            # only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item]==0:\n",
    "\n",
    "                # Similarity * Score\n",
    "                totals.setdefault(item,0)\n",
    "                totals[item]+=prefs[other][item]*sim\n",
    "\n",
    "                # Sum of similarities\n",
    "                simSums.setdefault(item,0)\n",
    "                simSums[item]+=sim\n",
    "\n",
    "    # Create the normalized list\n",
    "    rankings=[(total/simSums[item],item) for item,total in totals.items( )]\n",
    "\n",
    "    # Return the sorted list\n",
    "    rankings.sort( )\n",
    "    rankings.reverse( )\n",
    "    return rankings\n",
    "\n",
    "getRecommendations(critics,'Toby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
