{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras import optimizers\n",
    "import sampledata\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 8, 5)              160       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8, 1)              6         \n",
      "=================================================================\n",
      "Total params: 166\n",
      "Trainable params: 166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2472 - acc: 0.5116\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 934us/step - loss: 0.2404 - acc: 0.5630\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 939us/step - loss: 0.2227 - acc: 0.6647\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 936us/step - loss: 0.2009 - acc: 0.7221\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1580 - acc: 0.8031\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 947us/step - loss: 0.0993 - acc: 0.8916\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 934us/step - loss: 0.0630 - acc: 0.9260\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0378 - acc: 0.9661\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0231 - acc: 0.9879\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 988us/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 987us/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 977us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 976us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 931us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 970us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 961us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 1s 942us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 1s 965us/step - loss: 0.0012 - acc: 1.0000\n",
      "data:\n",
      "  [0. 0. 1. 1. 1. 1. 0. 1.]\n",
      "+ [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "------------------------------\n",
      "  [0. 1. 0. 0. 1. 1. 0. 1.] result\n",
      "  [0. 1. 0. 0. 1. 1. 0. 1.] label\n",
      "\n",
      "\n",
      "data:\n",
      "  [0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "+ [0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "------------------------------\n",
      "  [1. 0. 0. 0. 0. 0. 0. 1.] result\n",
      "  [1. 0. 0. 0. 0. 0. 0. 1.] label\n",
      "\n",
      "\n",
      "data:\n",
      "  [0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "+ [0. 0. 1. 1. 1. 1. 0. 1.]\n",
      "------------------------------\n",
      "  [0. 1. 0. 0. 0. 1. 1. 1.] result\n",
      "  [0. 1. 0. 0. 0. 1. 1. 1.] label\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "digits = num_steps = 8\n",
    "inputs = 2\n",
    "num_hidden = 5\n",
    "n_epoch = 10\n",
    "\n",
    "X = np.zeros(shape=(10, 8, 2))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(num_hidden, input_shape=(num_steps, inputs), return_sequences=True))\n",
    "#model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "sgd = optimizers.SGD(lr=2)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "#train LSTM\n",
    "for _ in range(n_epoch):\n",
    "    data, label = sampledata.create_data(1000)\n",
    "    data = data.reshape(1000, digits, inputs)\n",
    "    label = label.reshape(1000, digits, 1)\n",
    "    model.fit(x=data, y=label, epochs=2, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Test ----------------------------------------------------\n",
    "\n",
    "data, label = sampledata.create_data(3)\n",
    "p = model.predict(x=data.reshape(3, digits, inputs))\n",
    "\n",
    "for d, l, r in zip(data, label, p):\n",
    "    print(\"data:\")\n",
    "    print(\" \", np.transpose(d)[0][::-1])\n",
    "    print(\"+\", np.transpose(d)[1][::-1])\n",
    "    print(\"------------------------------\")\n",
    "    print(\" \", np.round(r[::-1])[:, 0], \"result\")\n",
    "    print(\" \", l[::-1], \"label\")\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
