{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs and cats dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Con el objeto de aumentar el conjunto de imágenes disponibles, se realizan diferentes transformaciones a las imágenes originales. Para ello utilizamos la función `ImageDataGenerator()`.\n",
    "\n",
    "<img src=\"images/perro.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# DATA SOURCE --------------------------------------------------\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        #shear_range=0.2,\n",
    "        zoom_range=[1, 0.9],\n",
    "        rotation_range = 10, \n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './datasets/dogs_and_cats/train_small',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=12,\n",
    "        shuffle=False,\n",
    "        class_mode='binary')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "for i, data in enumerate(train_generator):\n",
    "    images = data[0]\n",
    "    labels = data[1]\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)\n",
    "    print(data[1])\n",
    "    for image, label in zip(images, labels): \n",
    "        plt.imshow(image, interpolation='nearest')\n",
    "        plt.show()\n",
    "        print(label)\n",
    "    if i>=0:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera red convolutiva\n",
    "\n",
    "En este dataset tenemos que diferenciar entre imágenes de perros y gatos. Intentémoslo primero creando nuestra red convolutiva desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from time import time\n",
    "\n",
    "\n",
    "# DATA SOURCE --------------------------------------------------\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data_dir = 'datasets/dogs_and_cats/train'\n",
    "validation_data_dir = 'datasets/dogs_and_cats/validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "# MODEL --------------------------------------------------\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# TRAINING --------------------------------------------------\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./datasets/dogs_and_cats/logs/{}'.format(time()), \n",
    "                            histogram_freq=0, \n",
    "                            batch_size=32, \n",
    "                            write_graph=True, \n",
    "                            write_grads=False, \n",
    "                            write_images=False, \n",
    "                            embeddings_freq=0, \n",
    "                            embeddings_layer_names=None, \n",
    "                            embeddings_metadata=None, \n",
    "                            embeddings_data=None, \n",
    "                            update_freq='batch')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800,\n",
    "        callbacks = [tbCallBack]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "**Transfer learning** consiste en reutilizar la parte convolutiva de redes ya entrenadas para reducir drásticamente el tiempo de entrenamiento. La intución detrás de esta técnica es asumir que una red convolutiva ya entrenada con muchas imágenes y clases, como puede ser por ejemplo el conjunto Imagenet, posee suficiente variedad de caracterísiticas como para poder ser empleada por otra red, a la que se le cambia solamente la parte clasificadora o *fully connected*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "# img_width, img_height = 299, 299\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "\n",
    "train_data_dir = 'datasets/dogs_and_cats/train'\n",
    "validation_data_dir = 'datasets/dogs_and_cats/validation'\n",
    "\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "# DATA SOURCE --------------------------------------------------\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=[1, 0.9],\n",
    "    horizontal_flip=True)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# PRETRAINED MODEL --------------------------------------------------\n",
    "\n",
    "# Let's try different networks\n",
    "conv_model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "#conv_model = applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "#conv_model = applications.Xception(include_top=False, weights='imagenet')\n",
    "#conv_model = applications.InceptionResNetV2(include_top=False, weights='imagenet')\n",
    "\n",
    "\n",
    "# We generate the outputs of the selected convolutional net\n",
    "bottleneck_features_train = conv_model.predict_generator(\n",
    "    generator, nb_train_samples // batch_size)\n",
    "\n",
    "np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "        bottleneck_features_train)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "bottleneck_features_validation = conv_model.predict_generator(\n",
    "    generator, nb_validation_samples // batch_size)\n",
    "\n",
    "np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "        bottleneck_features_validation)\n",
    "\n",
    "print(\"Train feature maps shape:\", bottleneck_features_train.shape)\n",
    "print(\"Validation feature maps shape:\", bottleneck_features_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya tenemos generados los mapas de características o *features* de todas las imágenges podemos empezar con el entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy', 'rb'))\n",
    "train_labels = np.array(\n",
    "    [0] * int(train_data.shape[0] / 2) + [1] * int(train_data.shape[0] / 2))\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "validation_labels = np.array(\n",
    "    [0] * int(validation_data.shape[0] / 2) + [1] * int(validation_data.shape[0] / 2))\n",
    "\n",
    "# MODEL --------------------------------------------------\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# TRAINING --------------------------------------------------\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "\n",
    "model.save_weights(top_model_weights_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "\n",
    "#print(\"Estructura:\", conv_model.summary())\n",
    "#print(\"Estructura:\", model.summary())\n",
    "\n",
    "base_model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu', name=\"Classification\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid', name=\"Predictions\")(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name, layer.trainable)\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# TRAINING --------------------------------------------------\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./datasets/dogs_and_cats/logs/{}'.format(time()), \n",
    "                            histogram_freq=0, \n",
    "                            batch_size=32, \n",
    "                            write_graph=True, \n",
    "                            write_grads=False, \n",
    "                            write_images=False, \n",
    "                            embeddings_freq=0, \n",
    "                            embeddings_layer_names=None, \n",
    "                            embeddings_metadata=None, \n",
    "                            embeddings_data=None, \n",
    "                            update_freq='batch')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800,\n",
    "        callbacks = [tbCallBack]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
