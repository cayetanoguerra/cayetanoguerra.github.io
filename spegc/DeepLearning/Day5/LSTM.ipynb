{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Recurrentes\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "Los humanos no comenzamos a comprender desde cero en cada momento. Comprendes el sentido de cada palabra basándote en lo que has leído anteriormente. No haces borrón y cuenta nueva a cada segundo. Tus pensamientos tienen persistencia.\n",
    "Las redes MLP no hacen esto. Por ejemplo, imagina que quieres clasificar qué clase de evento está ocurriendo en cada momento de una película. No está claro cómo una red neuronal tradicional podría usar su razonamiento acerca de los eventos previos de la película para clasificar los de después.\n",
    "Las redes neuronales recurrentes abordan este problema. Estas redes poseen bucles en su interior, permitiendo que la información persista.\n",
    "\n",
    "\n",
    "La característica principal y más atractiva de las RNN es que nos permiten operar sobre secuencias de vectores, a la entrada, a la salida, o en ambas.\n",
    "\n",
    "<img src=\"images/image3.png\" width=\"60%\">\n",
    "\n",
    "Vectores de entrada en rojo, vectores de salida en azul y en verde vectores de estado. 1) NN. 2) \"image captioning\" toma una imagen de entrada y genera una secuencia de palabras. 3) Sentiment analysis. 4) Traducción automática. 5) Clasificación de vídeo, donde se desea etiquetar cada frame del vídeo.\n",
    "\n",
    "\n",
    "Esta figura representa una red neuronal recurrente que recibe una entrada $x_i$ y devuelve una salida $h_i$. Su bucle permite que la información sea enviada de un paso de la red al siguiente. Los bucles dentro de una red neuronal recurrente las hacen algo misteriosas a la hora de imaginar su comportamiento. Sin embargo, uno puede pensar en ellas como en una red normal si la visualizamos de forma “desenrrollada”. \n",
    "\n",
    "<img src=\"images/RNN-unrolled.png\" width=\"60%\">\n",
    "\n",
    "En los últimos años, estas redes han sido utilizadas con gran éxito en tareas como: reconocimiento del habla, modelado del lenguaje, traducción, descripción de imágenes… \n",
    "\n",
    "## LSTM (Long Short Term Memory)\n",
    "\n",
    "Esencial para estos éxitos ha sido el uso de la variante LSTM, un tipo especial de red neuronal recurrente que funciona, en muchas tareas, mucho mejor que la versión estándar. Casi todos los mejores resultados basados en redes neuronales recurrentes se han conseguido con estas versiones LSTM.\n",
    "\n",
    "Uno de los principales atractivos de las RNN es la idea de que pueden conectar información previa o pasada con la tarea actual, como, por ejemplo, usar la información de frames previos para entender el frame actual.\n",
    "\n",
    "A veces, necesitamos solo mirar la información reciente para para realizar la tarea actual. Por ejemplo, consideremos un \"modelo del lenguaje\" donde estamos intentando predecir la siguiente palabra de la frase: \"el cielo es… azul\". No necesitamos ir mucho más atrás en el contexto.\n",
    "\n",
    "<img src=\"images/RNN-shorttermdepdencies.png\" width=\"60%\">\n",
    "\n",
    "Hay situaciones donde necesitamos ir más atrás en el contexto. Consideremos ahora la frase: \"Yo crecí en Francia… así que hablo un perfecto francés\". Es posible manejar un \"gap\" lo suficientemente grande como para tener presente dónde se encontraba la información relevante. Sin embargo, a medida que ese “gap” crece puede llegar a ser imposible conectar con la información relevante.\n",
    "\n",
    "<img src=\"images/RNN-longtermdependencies.png\" width=\"60%\">\n",
    "\n",
    "Todas las redes recurrentes tienen la forma de una cadena de módulos de red neuronal. En las RNN estándar este módulo tiene una estructura simple consistente en una capa tanh.\n",
    "\n",
    "<img src=\"images/LSTM3-SimpleRNN.png\" width=\"60%\">\n",
    "\n",
    "En una red LSTM también tenemos esta estructura en cadena, pero los módulos son diferentes. En lugar de tener una simple capa de red neuronal, hay cuatro, interactuando de una forma especial.\n",
    "\n",
    "<img src=\"images/LSTM3-chain.png\" width=\"60%\">\n",
    "\n",
    "<img src=\"images/LSTM2-notation.png\" width=\"60%\">\n",
    "\n",
    "La idea central de las LSTM es la cell state (célula de estado). Es una especie de cinta transportadora donde la LSTM tiene la posibilidad de añadir o retirar información, cuidadosamente regulado por las gates (puertas).\n",
    "\n",
    "<img src=\"images/LSTM3-C-line.png\" width=\"60%\">\n",
    "\n",
    "Las gates son una forma de, opcionalmente, dejar pasar la información. Están compuestas por una capa de red neuronal y una operación de multiplicación (element-wise) sobre cada elemento. La capa sigmoide genera números entre 0 y 1, describiendo cuánto de cada componente debe pasar.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/LSTM3-focus-C.png\" width=\"60%\">\n",
    "\n",
    "### La puerta del olvido\n",
    "\n",
    "El primer paso en la LSTM es decidir qué información vamos a dejar pasar desde la cell state. Esta decisión es tomada por la capa sigmoide llamada \"forget gate layer\". Suponiendo que tenemos un modelo del lenguaje, la cell state podría incluir el género del sujeto para usar el pronombre correcto. Cuando vemos un nuevo sujeto querremos \"olvidar\" el género del anterior.\n",
    "\n",
    "<img src=\"images/LSTM3-focus-f.png\" width=\"60%\">\n",
    "\n",
    "### La puerta del recuerdo\n",
    "\n",
    "El siguiente paso es decidir qué vamos a guardar (recordar) en la cell state. Esto conlleva dos partes. Primero, una capa sigmoide, llamada “input gate layer” decide qué valores se actualizarán. Después, una capa tanh creará un vector de nuevos valores candidatos, $\\tilde{C}_t$, que podrían ser añadidos al estado. En nuestro ejemplo, aquí añadiríamos el género de nuestro nuevo sujeto.\n",
    "\n",
    "<img src=\"images/LSTM3-focus-i.png\" width=\"60%\">\n",
    "\n",
    "Ahora es el momento de actualizar la cell state antigua por la nueva. Multiplicamos el antiguo estado por ft, olvidando las cosas que hemos decidido olvidar y añadiendo la información nueva $\\tilde{C}_t$. \n",
    "\n",
    "<img src=\"images/LSTM3-focus-C.png\" width=\"60%\">\n",
    "\n",
    "### La salida\n",
    "\n",
    "Finalmente, necesitamos decidir lo que vamos a devolver como salida. Esta salida estará basada en nuestra cell state, pero con una versión filtrada. Primero, una capa sigmoide decide qué partes de la cell state devolverá. Después, pasamos la cell state por la función tanh para pasar los valores al intervalo [-1,1].\n",
    "\n",
    "<img src=\"images/LSTM3-focus-o.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
