{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Fashion\n",
    "\n",
    "Fashion MNIST es un dataset de similares características que el MNIST, pero en este caso con imágenes de prendas de ropa. Lo cual lo hace un poco más complicado.\n",
    "\n",
    "<img src=\"images/fashion_mnist.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Perceptrón Multicapa (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.5536 - acc: 0.7974 - val_loss: 0.4659 - val_acc: 0.8275\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4040 - acc: 0.8522 - val_loss: 0.3995 - val_acc: 0.8530\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3714 - acc: 0.8672 - val_loss: 0.3746 - val_acc: 0.8682\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3520 - acc: 0.8733 - val_loss: 0.3742 - val_acc: 0.8697\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3360 - acc: 0.8794 - val_loss: 0.3826 - val_acc: 0.8668\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3271 - acc: 0.8823 - val_loss: 0.3887 - val_acc: 0.8716\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3226 - acc: 0.8854 - val_loss: 0.3858 - val_acc: 0.8707\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3122 - acc: 0.8889 - val_loss: 0.3546 - val_acc: 0.8792\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3072 - acc: 0.8895 - val_loss: 0.3849 - val_acc: 0.8744\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3032 - acc: 0.8928 - val_loss: 0.3610 - val_acc: 0.8755\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3013 - acc: 0.8929 - val_loss: 0.3963 - val_acc: 0.8743\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2967 - acc: 0.8959 - val_loss: 0.4120 - val_acc: 0.8688\n",
      "Test loss: 0.4119559980750084\n",
      "Test accuracy: 0.8688\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Convolutiva\n",
    "\n",
    "Probemos ahora con capas convolutivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.5745 - acc: 0.7968 - val_loss: 0.3550 - val_acc: 0.8742\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3638 - acc: 0.8712 - val_loss: 0.3407 - val_acc: 0.8742\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3140 - acc: 0.8872 - val_loss: 0.2805 - val_acc: 0.8999\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2809 - acc: 0.8998 - val_loss: 0.2611 - val_acc: 0.9051\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2589 - acc: 0.9072 - val_loss: 0.2538 - val_acc: 0.9057\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2402 - acc: 0.9131 - val_loss: 0.2433 - val_acc: 0.9104\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2224 - acc: 0.9195 - val_loss: 0.2438 - val_acc: 0.9135\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2111 - acc: 0.9244 - val_loss: 0.2280 - val_acc: 0.9167\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1949 - acc: 0.9285 - val_loss: 0.2253 - val_acc: 0.9211\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1875 - acc: 0.9325 - val_loss: 0.2213 - val_acc: 0.9202\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1780 - acc: 0.9357 - val_loss: 0.2177 - val_acc: 0.9204\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1688 - acc: 0.9392 - val_loss: 0.2257 - val_acc: 0.9227\n",
      "Test loss: 0.22565262379050255\n",
      "Test accuracy: 0.9227\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
