{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras CIFAR 10\n",
    "\n",
    "El conjunto de datos CIFAR-10 (Instituto Canadiense de Investigación Avanzada) es una colección de imágenes que se utiliza comúnmente para entrenar algoritmos de visión artificial. Es uno de los conjuntos de datos más utilizados para la investigación en machine learning. Contiene 60.000 imágenes en color de 32x32 divididas en 10 clases diferentes (aviones, automóviles, aves, gatos, venados, perros, ranas, caballos, barcos y camiones). Hay 6.000 imágenes de cada clase.\n",
    "\n",
    "<img src=\"images/cifar10.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/24\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.7917 - acc: 0.3532 - val_loss: 1.4731 - val_acc: 0.4840\n",
      "Epoch 2/24\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.3671 - acc: 0.5140 - val_loss: 1.1760 - val_acc: 0.5881\n",
      "Epoch 3/24\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.1919 - acc: 0.5805 - val_loss: 1.0582 - val_acc: 0.6264\n",
      "Epoch 4/24\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.0803 - acc: 0.6225 - val_loss: 1.0537 - val_acc: 0.6296\n",
      "Epoch 5/24\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0012 - acc: 0.6504 - val_loss: 0.9393 - val_acc: 0.6718\n",
      "Epoch 6/24\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.9402 - acc: 0.6694 - val_loss: 0.9390 - val_acc: 0.6733\n",
      "Epoch 7/24\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.8805 - acc: 0.6916 - val_loss: 0.9167 - val_acc: 0.6784\n",
      "Epoch 8/24\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.8272 - acc: 0.7109 - val_loss: 0.9334 - val_acc: 0.6766\n",
      "Epoch 9/24\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.7832 - acc: 0.7264 - val_loss: 0.8856 - val_acc: 0.6917\n",
      "Epoch 10/24\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.7366 - acc: 0.7437 - val_loss: 0.8688 - val_acc: 0.7047\n",
      "Epoch 11/24\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.6975 - acc: 0.7552 - val_loss: 0.8666 - val_acc: 0.7065\n",
      "Epoch 12/24\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.6659 - acc: 0.7665 - val_loss: 0.9032 - val_acc: 0.7059\n",
      "Epoch 13/24\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.6228 - acc: 0.7799 - val_loss: 0.8570 - val_acc: 0.7143\n",
      "Epoch 14/24\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.5928 - acc: 0.7905 - val_loss: 0.8878 - val_acc: 0.7109\n",
      "Epoch 15/24\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.5622 - acc: 0.7990 - val_loss: 0.8500 - val_acc: 0.7199\n",
      "Epoch 16/24\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.5367 - acc: 0.8110 - val_loss: 0.9251 - val_acc: 0.7107\n",
      "Epoch 17/24\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.5093 - acc: 0.8197 - val_loss: 0.9652 - val_acc: 0.7066\n",
      "Epoch 18/24\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.4956 - acc: 0.8246 - val_loss: 0.9372 - val_acc: 0.6899\n",
      "Epoch 19/24\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.4661 - acc: 0.8346 - val_loss: 0.8858 - val_acc: 0.7190\n",
      "Epoch 20/24\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.4544 - acc: 0.8384 - val_loss: 0.9660 - val_acc: 0.7197\n",
      "Epoch 21/24\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4423 - acc: 0.8430 - val_loss: 0.9357 - val_acc: 0.7203\n",
      "Epoch 22/24\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4273 - acc: 0.8490 - val_loss: 1.0178 - val_acc: 0.7141\n",
      "Epoch 23/24\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.4177 - acc: 0.8526 - val_loss: 0.9815 - val_acc: 0.7219\n",
      "Epoch 24/24\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.3996 - acc: 0.8589 - val_loss: 1.0336 - val_acc: 0.7208\n",
      "Test loss: 1.0336169943332671\n",
      "Test accuracy: 0.7208\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 24\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a intentar mejorar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 28s 566us/step - loss: 1.9003 - acc: 0.3094 - val_loss: 1.4560 - val_acc: 0.4705\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.4214 - acc: 0.4912 - val_loss: 1.2033 - val_acc: 0.5622\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.1972 - acc: 0.5744 - val_loss: 1.1060 - val_acc: 0.6054\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0511 - acc: 0.6288 - val_loss: 0.9703 - val_acc: 0.6636\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.9483 - acc: 0.6678 - val_loss: 0.8768 - val_acc: 0.6968\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.8615 - acc: 0.6975 - val_loss: 0.8182 - val_acc: 0.7152\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.7989 - acc: 0.7203 - val_loss: 0.7806 - val_acc: 0.7276\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.7405 - acc: 0.7410 - val_loss: 0.8490 - val_acc: 0.7111\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.6911 - acc: 0.7574 - val_loss: 0.7078 - val_acc: 0.7533\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.6555 - acc: 0.7699 - val_loss: 0.7014 - val_acc: 0.7589\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.6186 - acc: 0.7809 - val_loss: 0.6549 - val_acc: 0.7781\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.5846 - acc: 0.7947 - val_loss: 0.7361 - val_acc: 0.7523\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.5553 - acc: 0.8064 - val_loss: 0.6391 - val_acc: 0.7830\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.5368 - acc: 0.8122 - val_loss: 0.6438 - val_acc: 0.7813\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.5028 - acc: 0.8224 - val_loss: 0.7211 - val_acc: 0.7639\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.4905 - acc: 0.8259 - val_loss: 0.6351 - val_acc: 0.7826\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.4669 - acc: 0.8357 - val_loss: 0.6109 - val_acc: 0.7994\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.4461 - acc: 0.8439 - val_loss: 0.6027 - val_acc: 0.7975\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.4295 - acc: 0.8492 - val_loss: 0.6533 - val_acc: 0.7886\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.4133 - acc: 0.8553 - val_loss: 0.6046 - val_acc: 0.8001\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.4043 - acc: 0.8577 - val_loss: 0.6289 - val_acc: 0.7947\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.3920 - acc: 0.8622 - val_loss: 0.6293 - val_acc: 0.8003\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.3712 - acc: 0.8685 - val_loss: 0.6424 - val_acc: 0.7941\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.3616 - acc: 0.8718 - val_loss: 0.6133 - val_acc: 0.8062\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.3519 - acc: 0.8749 - val_loss: 0.6278 - val_acc: 0.8005\n",
      "Test loss: 0.62778226852417\n",
      "Test accuracy: 0.8005\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 25\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
